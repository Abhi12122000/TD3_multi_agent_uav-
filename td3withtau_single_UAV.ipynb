{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Abhi12122000/TD3_multi_agent_uav-/blob/main/td3withtau_single_UAV.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1BM_H0vpCoiL"
      },
      "outputs": [],
      "source": [
        "# !pip3 install box2d-py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9zPegbAptLM6",
        "outputId": "328634c1-a351-46f4-ae44-602b2cfd8b2d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting gym==0.15.3\n",
            "  Downloading gym-0.15.3.tar.gz (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m51.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from gym==0.15.3) (1.7.3)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.8/dist-packages (from gym==0.15.3) (1.21.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from gym==0.15.3) (1.15.0)\n",
            "Collecting pyglet<=1.3.2,>=1.2.0\n",
            "  Downloading pyglet-1.3.2-py2.py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m33.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cloudpickle~=1.2.0\n",
            "  Downloading cloudpickle-1.2.2-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.8/dist-packages (from pyglet<=1.3.2,>=1.2.0->gym==0.15.3) (0.16.0)\n",
            "Building wheels for collected packages: gym\n",
            "  Building wheel for gym (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gym: filename=gym-0.15.3-py3-none-any.whl size=1644968 sha256=7e2e992a4d3594cd191ab5451a51b71a462f61ea79fc70853854a93120b64bd8\n",
            "  Stored in directory: /root/.cache/pip/wheels/9b/b4/52/f4cce4bdc360a2289a3433deaa062ceb13dbe429c342866e97\n",
            "Successfully built gym\n",
            "Installing collected packages: cloudpickle, pyglet, gym\n",
            "  Attempting uninstall: cloudpickle\n",
            "    Found existing installation: cloudpickle 2.2.1\n",
            "    Uninstalling cloudpickle-2.2.1:\n",
            "      Successfully uninstalled cloudpickle-2.2.1\n",
            "  Attempting uninstall: gym\n",
            "    Found existing installation: gym 0.25.2\n",
            "    Uninstalling gym-0.25.2:\n",
            "      Successfully uninstalled gym-0.25.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-probability 0.19.0 requires cloudpickle>=1.3, but you have cloudpickle 1.2.2 which is incompatible.\n",
            "distributed 2022.2.1 requires cloudpickle>=1.5.0, but you have cloudpickle 1.2.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed cloudpickle-1.2.2 gym-0.15.3 pyglet-1.3.2\n"
          ]
        }
      ],
      "source": [
        "!pip install gym==0.15.3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "XgwPUfrXpFPo"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import gym\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "import os\n",
        "import time\n",
        "import math\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from gym import wrappers, Env, spaces\n",
        "from torch.autograd import Variable\n",
        "from collections import deque"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "yL30jpP5pBXB"
      },
      "outputs": [],
      "source": [
        "# # Environment Class\n",
        "\n",
        "# class Single_Agent_UAV(Env):\n",
        "#     def __init__(self, initial_UAV_state = None):\n",
        "#         '''\n",
        "#         Initializes necessary parameters of environment (UE_positions, UAV_initial_position, EC_positions, D_array, C_array, etc.) \n",
        "#         '''\n",
        "#         super(Single_Agent_UAV, self).__init__()\n",
        "#         # Environment Parameters\n",
        "\n",
        "#         self.UE_seed = 1\n",
        "#         self.UE_count = 50\n",
        "#         self.EC_count = 1\n",
        "#         self.C_min = 100\n",
        "#         self.C_max = 200\n",
        "#         self.D_m_min = 1e6 # in bits\n",
        "#         self.D_m_max = 5e6 # in bits\n",
        "#         self.Z_max = 40\n",
        "#         self.Z_min = 20\n",
        "#         self.L_h_max = 49\n",
        "#         self.L_v_max = 12\n",
        "#         self.D_min = 100\n",
        "#         self.lambda_m = 1\n",
        "#         self.phi_n = np.radians(42.44)  # in degrees\n",
        "#         self.g_0 = 1e-5 # in power gain # -50 in dB\n",
        "#         self.B_u = 10 * 1e6  # in Hz\n",
        "#         self.B_k = 0.5 * 1e6  # in Hz\n",
        "#         self.P_max = 5\n",
        "#         self.P_m = 0.1\n",
        "#         self.P_r_n = 0.1\n",
        "#         self.F_u = 3e9 # in Hz\n",
        "#         self.F_e_k_max = 9e9 # in Hz\n",
        "#         self.F_e_k_min = 6e9 # in Hz\n",
        "#         self.kappa = (1e-28) # check if float maintains this precision\n",
        "#         self.sigma_squared_u = (1e-13) # in watt # -100 in dBm\n",
        "#         self.sigma_squared_e = (1e-13) # in watt # -100 in dBm\n",
        "#         self.w1 = self.w2 = 1\n",
        "#         self.eta_1 = 25\n",
        "#         self.eta_2 = 25\n",
        "#         self.eta_3 = 25\n",
        "#         self.boundary_x = self.boundary_y = 150.\n",
        "#         self.reward_bias = int(self.UE_count * 0.5 * self.eta_3)\n",
        "#         self.max_episode_steps = 10 # Maximum number of steps in a single episode, after which environment returns done = True\n",
        "\n",
        "\n",
        "#         # plotting parameters\n",
        "#         self.plotting_boundary_buffer = 5.\n",
        "#         self.UAV_coverage_circle_color = 'lavender'\n",
        "#         self.EC_concentrated_region_color = 'mistyrose'\n",
        "#         self.UAV_path_color = 'green'\n",
        "\n",
        "#         # Environment Bounds\n",
        "\n",
        "#         self.action_space_coversion_lb = np.zeros(4 + (self.EC_count * self.UE_count))\n",
        "#         self.action_space_coversion_lb[2] = -self.L_v_max\n",
        "#         self.action_space_coversion_lb[3] = 1e-2\n",
        "#         self.action_space_coversion_ub = np.ones(4 + (self.EC_count * self.UE_count))\n",
        "#         self.action_space_coversion_ub[0:4] = np.array([self.L_h_max, 2 * math.pi, self.L_v_max, self.P_max]) \n",
        "\n",
        "#         self.action_space_lb = -1 * np.ones(4 + (self.EC_count * self.UE_count))\n",
        "#         self.action_space_ub = np.ones(4 + (self.EC_count * self.UE_count))\n",
        "#         self.state_space_lb = np.array([0, 0, self.Z_min])\n",
        "#         self.state_space_ub = np.array([self.boundary_x, self.boundary_y, self.Z_max])\n",
        "\n",
        "\n",
        "# #         self.state_shape = \n",
        "# #         defining action space\n",
        "#         self.state_space = gym.spaces.box.Box(low = self.state_space_lb, high = self.state_space_ub)\n",
        "# #         defining observation space\n",
        "#         self.action_space = gym.spaces.box.Box(low = self.action_space_lb, high = self.action_space_ub)\n",
        "        \n",
        "#         self.timesteps_in_episode = 0\n",
        "#         self.done = False\n",
        "#         self.last_action = self.action_space.sample()\n",
        "\n",
        "#         self.UE_positions = []\n",
        "#         self.EC_positions = []\n",
        "#         self.EC_F_e_k = []\n",
        "#         self.D_array = []\n",
        "#         self.C_array = []\n",
        "# #         initialize grid dimensions (400 x 400) \n",
        "#         if initial_UAV_state is not None:\n",
        "#           self.current_state = np.array(initial_UAV_state)\n",
        "#         else:\n",
        "#           self.current_state = self.select_random_state()\n",
        "        \n",
        "#         self.initial_UAV_state = self.current_state\n",
        "        \n",
        "#         self.previous_state = self.current_state\n",
        "#         print(\"initial state of UAV: \", self.current_state)\n",
        "    \n",
        "# #         call function to place UEs on the grid and specify (D_m, C_m, lambda_m) for UAVs\n",
        "#         self.place_UEs(position=\"centered\", desired_z_coord = (self.Z_min + self.Z_max) / 2, center = None)\n",
        "#         self.place_ECs_randomly()\n",
        "\n",
        "\n",
        "#     def get_count_of_UEs_covered(self):\n",
        "#         '''\n",
        "#         Returns count of UEs covered under UAV's current configuration\n",
        "#         '''\n",
        "\n",
        "#         C_max_t = (self.current_state[2] / np.tan(self.phi_n))\n",
        "        \n",
        "#         ground_UAV_state = np.zeros(3)\n",
        "#         ground_UAV_state[:2] = self.current_state[:2]\n",
        "#         horizontal_dist_UE_UAV = np.linalg.norm(self.UE_positions - ground_UAV_state, axis = 1)\n",
        "#         dist_UE_UAV = np.linalg.norm(self.UE_positions - self.current_state, axis = 1)\n",
        "#         # print(\"horizontal distance b/w UEs and UAV: \", horizontal_dist_UE_UAV)\n",
        "#         # print(\"distance b/w UEs and UAV: \", dist_UE_UAV)\n",
        "#         rho_array = (horizontal_dist_UE_UAV <= (C_max_t)) * 1  # binary association vector\n",
        "#         M_t = rho_array.sum()\n",
        "\n",
        "#         return M_t\n",
        "\n",
        "\n",
        "#     def render_UAV_movement_through_episode(self, **kwargs):\n",
        "#         '''\n",
        "#         Helper function to visualize UAV movement through an episode\n",
        "#         Arguments: A list specifying UAV positions throughout the episode\n",
        "#         '''\n",
        "\n",
        "#         if 'reward' not in kwargs:\n",
        "#             kwargs['reward'] = 'Not known'\n",
        "        \n",
        "#         C_max_t = (kwargs['UAV_positions_list'][-1][2] / np.tan(self.phi_n))\n",
        "#         buffer = 5.\n",
        "#         fig, ax = plt.subplots(1, figsize=(10,10))\n",
        "#         ax.set_xlim(-buffer, self.boundary_x+buffer)\n",
        "#         ax.set_ylim(-buffer, self.boundary_y+buffer)\n",
        "#         ax.grid()\n",
        "#         UE_x = self.UE_positions[:, 0]\n",
        "#         UE_y = self.UE_positions[:, 1]\n",
        "#         ax.plot(UE_x, UE_y, color='black', marker='o', markersize=6, linestyle = '', label = \"UE\")\n",
        "        \n",
        "#         EC_x = self.EC_positions[:, 0]\n",
        "#         EC_y = self.EC_positions[:, 1]\n",
        "#         ax.plot(EC_x, EC_y, color='red', marker='D', markersize=7, linestyle = '', label = \"EC\")\n",
        "        \n",
        "#         ax.plot(np.array(kwargs['UAV_positions_list'])[:, 0] , np.array(kwargs['UAV_positions_list'])[:, 1], color=self.UAV_path_color, markersize=6, linestyle = '-', label = \"UAV Path Color\")\n",
        "#         ax.plot(kwargs['UAV_positions_list'][-1][0], kwargs['UAV_positions_list'][-1][1], color='blue', marker='x', markersize=9, linestyle = '', label = \"UAV ending position\")\n",
        "        \n",
        "#         UAV_coverage_area = plt.Circle((kwargs['UAV_positions_list'][-1][0], kwargs['UAV_positions_list'][-1][1]), C_max_t, color = self.UAV_coverage_circle_color)\n",
        "#         ax.add_artist(UAV_coverage_area)\n",
        "      \n",
        "#       # For testing: To plot the circle and visualize UE points inside it\n",
        "#         if self.UE_center is not None:\n",
        "#             Test_UE_allotment_circle = plt.Circle((self.UE_center[0] , self.UE_center[1]), self.UE_radius, color = self.EC_concentrated_region_color)\n",
        "#             ax.add_artist(Test_UE_allotment_circle)\n",
        "#       # End\n",
        "\n",
        "#         ax.set_aspect(1)\n",
        "#         # naming the x axis\n",
        "#         ax.set_xlabel('X pos (m)')\n",
        "#         # naming the y axis\n",
        "#         ax.set_ylabel('Y pos (m)')\n",
        "#         ax.set_title('UAV movement through episode')\n",
        "#         # giving a title to my graph\n",
        "#         # plt.title('Visually Appealing!')\n",
        "\n",
        "#         # show a legend on the plot\n",
        "#         ax.legend()\n",
        "#         # plt.show()\n",
        "#         return\n",
        "\n",
        "\n",
        "#     def render_bar_plot(self, ax, plot_number, idx):\n",
        "#         '''\n",
        "#         Plotting bar graph of each UE's fraction of tasks assigned to UAV and to EC, by the last action input given to step() function\n",
        "#         '''\n",
        "#         x_indices = np.arange(self.UE_count)\n",
        "#         width = 0.5\n",
        "\n",
        "#         gamma_array = (np.array(self.last_action[4:])).reshape((self.UE_count, self.EC_count))\n",
        "#         gamma_zeros = (1 - gamma_array.sum(axis = 1))\n",
        "        \n",
        "#         ax[plot_number, idx].bar(x_indices, gamma_zeros, width=width)\n",
        "#         for i in range(self.EC_count):\n",
        "#             ax[plot_number, idx].bar(x_indices, gamma_array[:, i], width=width)\n",
        "        \n",
        "    \n",
        "#     def render_position_plot(self, ax, plot_number, idx, reward):\n",
        "#         '''\n",
        "#         Helper function to render(), plots the current position plot on given axes. \n",
        "#         Plotting position plot of UAV's current position and coverage\n",
        "#         '''\n",
        "\n",
        "#         C_max_t = (self.current_state[2] / np.tan(self.phi_n))\n",
        "#         buffer = 5.\n",
        "#         ax[plot_number, idx].set_xlim(-buffer, self.boundary_x+buffer)\n",
        "#         ax[plot_number, idx].set_ylim(-buffer, self.boundary_y+buffer)\n",
        "#         ax[plot_number, idx].grid()\n",
        "#         UE_x = self.UE_positions[:, 0]\n",
        "#         UE_y = self.UE_positions[:, 1]\n",
        "#         ax[plot_number, idx].plot(UE_x, UE_y, color='black', marker='o', markersize=6, linestyle = '', label = \"UE\")\n",
        "        \n",
        "#         EC_x = self.EC_positions[:, 0]\n",
        "#         EC_y = self.EC_positions[:, 1]\n",
        "#         ax[plot_number, idx].plot(EC_x, EC_y, color='red', marker='D', markersize=7, linestyle = '', label = \"EC\")\n",
        "        \n",
        "#         ax[plot_number, idx].plot(self.current_state[0], self.current_state[1], color='blue', marker='x', markersize=9, linestyle = '', label = \"UAV\")\n",
        "        \n",
        "#         UAV_coverage_area = plt.Circle((self.current_state[0] , self.current_state[1] ), C_max_t, color = self.UAV_coverage_circle_color)\n",
        "#         ax[plot_number, idx].add_artist(UAV_coverage_area)\n",
        "      \n",
        "#       # For testing: To plot the circle and visualize UE points inside it\n",
        "#         if self.UE_center is not None:\n",
        "#             Test_UE_allotment_circle = plt.Circle((self.UE_center[0] , self.UE_center[1]), self.UE_radius, color = self.EC_concentrated_region_color)\n",
        "#             ax[plot_number, idx].add_artist(Test_UE_allotment_circle)\n",
        "#       # End\n",
        "\n",
        "#         ax[plot_number, idx].set_aspect(1)\n",
        "#         # naming the x axis\n",
        "#         ax[plot_number, idx].set_xlabel('X pos (m)')\n",
        "#         # naming the y axis\n",
        "#         ax[plot_number, idx].set_ylabel('Y pos (m)')\n",
        "#         ax[plot_number, idx].set_title('reward: ' + str(reward))\n",
        "#         # giving a title to my graph\n",
        "#         # plt.title('Visually Appealing!')\n",
        "\n",
        "#         # show a legend on the plot\n",
        "#         ax[plot_number, idx].legend()\n",
        "#         # plt.show()\n",
        "\n",
        "\n",
        "#     def render(self, **kwargs):\n",
        "#         '''\n",
        "#         Function to visualize UAV position\n",
        "#         (this function has different configurations for different use cases)\n",
        "#         '''\n",
        "\n",
        "#         if 'UAV_positions_list' in kwargs:\n",
        "#             self.render_UAV_movement_through_episode(UAV_positions_list = kwargs['UAV_positions_list'])\n",
        "\n",
        "#         if 'fig' not in kwargs:\n",
        "#             fig, ax = plt.subplots(1, 2, figsize=(20,10))\n",
        "#             ax = np.array([ax])\n",
        "#             kwargs['fig'] = fig\n",
        "#             kwargs['ax'] = ax\n",
        "#             kwargs['i'] = 0\n",
        "        \n",
        "#         if 'reward' not in kwargs:\n",
        "#             kwargs['reward'] = 'Not known'\n",
        "#         self.render_position_plot(kwargs['ax'], kwargs['i'], 0, kwargs['reward'])\n",
        "#         if(self.timesteps_in_episode != 0):\n",
        "#             self.render_bar_plot(kwargs['ax'], kwargs['i'], 1)\n",
        "\n",
        "\n",
        "#     def reset(self):\n",
        "#         '''\n",
        "#         Resets the environment paramters to some initial values\n",
        "#         '''\n",
        "# #         we should only reassign the position of UAV here\n",
        "#         # Commenting for TESTING\n",
        "#         self.current_state = self.select_random_state()\n",
        "#         # Commenting for TESTING done\n",
        "#         self.this_episode_UAV_positions_list = []\n",
        "#         # self.current_state = self.initial_UAV_state\n",
        "#         print(\"new initial state of UAV (after resetting): \", self.current_state)\n",
        "\n",
        "#         self.timesteps_in_episode = 0\n",
        "#         self.done = False\n",
        "#         return self.current_state\n",
        "    \n",
        "    \n",
        "#     def step(self, action):\n",
        "#         '''\n",
        "#         Takes action moving environment from current_state to next_state\n",
        "#         Arguments: `action` to be taken\n",
        "#         Returns: new_state, reward, done, info(=None)\n",
        "#         '''\n",
        "#         # print(\"printing action in step function: \", action)\n",
        "#         action = np.array(action).flatten()\n",
        "#         action = np.clip(action, self.action_space_lb, self.action_space_ub)\n",
        "#         # print(\"clipped action inside Environment: \", action)\n",
        "#         action = (((self.action_space_coversion_ub - self.action_space_coversion_lb) * (action + 1)) / 2) + self.action_space_coversion_lb\n",
        "#         # print(\"scaled action: \", action)\n",
        "# #         action is of the form [l_n(t), v_n(t), del_z_n(t), P_t_n(t), gamma_0_1(t), ..., gamma_0_k(t), gamma_1_1(t), ..., gamma_1_k(t), ..., gamma_m_k(t)]\n",
        "# #         What happens if (sum of gamma_n_m_k != 1) ?\n",
        "# #         The above problem has been dealt by not including gamma_i_0(t) in predicted action.\n",
        "# #         Rather, we evaluate it as:- gamma_i_0(t) = 1 - summation(gamma_i_k(t))\n",
        "#         # print(\"action just before moving: \", action.shape[0])\n",
        "#         self.timesteps_in_episode += 1\n",
        "#         # print(\"P_t of action: \", action[3])\n",
        "#         action = self.move(action)\n",
        "#         print(\"UAV position: \", self.current_state)\n",
        "#         self.last_action = action\n",
        "#         # print(\"action after moving: \", action)\n",
        "        \n",
        "#         gamma_array = (np.array(action[4:])).reshape((self.UE_count, self.EC_count))\n",
        "#         gamma_zeros = (1 - gamma_array.sum(axis = 1))\n",
        "#         # print(\"gamma zeros: \", gamma_zeros)\n",
        "        \n",
        "# # REMOVED CODE\n",
        "# #         gamma_array = []\n",
        "# #         gamma_zeros = []\n",
        "# #         for i in range(len(self.UE_positions)):\n",
        "# #             base = 4\n",
        "# #             sum_gamma_i = 0\n",
        "# #             gamma_i_array = []\n",
        "# #             for j in range(EC_count):\n",
        "# #                 gamma_i_array.append(action[base + (i * EC_count) + j])\n",
        "# #                 sum_gamma_i += gamma_i_array[-1]\n",
        "# #             gamma_array.append(np.array(gamma_i_array))\n",
        "# #             gamma_zeros.append(1 - sum_gamma_i)\n",
        "    \n",
        "# #         gamma_zeros = np.array(gamma_zeros)\n",
        "# #         gamma_array = np.array(gamma_array)\n",
        "# # END OF REMOVED CODE\n",
        "        \n",
        "# #         calculate C_max_t for UAV (using correct formula)\n",
        "#         C_max_t = (self.current_state[2] / np.tan(self.phi_n))\n",
        "        \n",
        "#         ground_UAV_state = np.zeros(3)\n",
        "#         ground_UAV_state[:2] = self.current_state[:2]\n",
        "#         horizontal_dist_UE_UAV = np.linalg.norm(self.UE_positions - ground_UAV_state, axis = 1)\n",
        "#         dist_UE_UAV = np.linalg.norm(self.UE_positions - self.current_state, axis = 1)\n",
        "#         # print(\"horizontal distance b/w UEs and UAV: \", horizontal_dist_UE_UAV)\n",
        "#         # print(\"distance b/w UEs and UAV: \", dist_UE_UAV)\n",
        "#         rho_array = (horizontal_dist_UE_UAV <= (C_max_t)) * 1  # binary association vector\n",
        "#         M_t = rho_array.sum()  # no. of UEs served by the agent\n",
        "#         # print(\"UEs covered: \", M_t)\n",
        "#         # print(\"M_t: \", M_t, \" C_max_t: \", C_max_t)\n",
        "        \n",
        "#         try:\n",
        "#             if(M_t==0):\n",
        "#                 raise ValueError(\"-----UAV serves no UEs in its present state-----\")\n",
        "        \n",
        "#         except ValueError:\n",
        "#             #Reward: \n",
        "#             reward = coverage_penalty = -1 * (self.UE_count - M_t) * self.eta_3  # coverage constraint penalty\n",
        "#             reward += self.reward_bias\n",
        "#             # print(\"coverage penalty = reward:- \", coverage_penalty)\n",
        "#             self.is_done()\n",
        "    \n",
        "#             # if(self.done):\n",
        "#             #   print(\"------------------------\", \"reward in episode's last step: \", reward, \"------------------------\")\n",
        "    \n",
        "\n",
        "#             return self.current_state, reward, self.done, None\n",
        "            \n",
        "        \n",
        "#         dist_EC_UAV = np.linalg.norm(self.EC_positions - self.current_state, axis = 1)\n",
        "#         # print(\"distance b/w ECs and UAV: \", dist_EC_UAV)\n",
        "\n",
        "# # REMOVED CODE\n",
        "# #         for current_UE in self.UE_positions:\n",
        "# #             dist_i = np.linalg.norm(current_UE - self.current_state)\n",
        "# #             dist_UE_UAV.append(dist_i)\n",
        "# #             if(np.square(C_max_t) >= dist_i):\n",
        "# #                 M_t += 1\n",
        "        \n",
        "# #         for current_EC in self.EC_positions:\n",
        "# #             dist_i = np.linalg.norm(current_EC - self.current_state) \n",
        "# #             dist_EC_UAV.append(dist_i)\n",
        "        \n",
        "# #         dist_UE_UAV = np.array(dist_UE_UAV)\n",
        "# #         dist_EC_UAV = np.array(dist_EC_UAV)\n",
        "# # END OF REMOVED CODE\n",
        "\n",
        "        \n",
        "# # Calculating Reward here\n",
        "        \n",
        "# #     A.) G2A Transmission from UEs to UAVs\n",
        "\n",
        "#         # print(\"-------displaying stats for UAV-1:------- \")\n",
        "#         h_m = self.g_0 / np.square(dist_UE_UAV)\n",
        "#         # print(\"h_m: \", h_m[0])\n",
        "#         R_m = (self.B_u * np.log2(1 + ((h_m * self.P_m) / self.sigma_squared_u))) / M_t   # shannon channel capacity equation\n",
        "#         # print(\"R_m: \", R_m[0])\n",
        "#         # print(\"D_array: \", self.D_array[0], self.D_array.shape)\n",
        "#         # print(\"R_m: \", R_m[0], R_m.shape)\n",
        "#         T_G2A_t_list = (self.D_array / R_m)\n",
        "#         # print(\"printing array division: \", (self.D_array / R_m))\n",
        "#         # print(\"T_G2A_t: \", T_G2A_t_list[0])\n",
        "#         E_G2A_t_list = (self.P_r_n * T_G2A_t_list)\n",
        "        \n",
        "    \n",
        "# #     B.) Computation at UAVs\n",
        "        \n",
        "#         f_i = self.F_u / M_t\n",
        "#         # print(\"f_i: \", f_i)\n",
        "#         E_UAV_helper_constant = self.kappa * (f_i ** 3)\n",
        "#         T_UAV_t_list = ((gamma_zeros * self.D_array * self.C_array) / f_i)\n",
        "#         E_UAV_t_list = (E_UAV_helper_constant * T_UAV_t_list)\n",
        "            \n",
        "    \n",
        "# #     C.) A2G Transmission from UAVs to ECs\n",
        "        \n",
        "#         h_k = self.g_0 / (np.square(dist_EC_UAV))\n",
        "#         R_k = (self.B_k * np.log2(1 + ((h_k * action[3]) / self.sigma_squared_e)))\n",
        "#         # print(\"power P_t: \", action[3])\n",
        "#         # print(\"R_k for A2G Transmission: \", R_k)\n",
        "#         T_A2G_t_list = (gamma_array * (self.D_array)[:, np.newaxis]) / R_k  #each element of the list is an numpy array describing each UE\n",
        "#         E_A2G_t_list = (T_A2G_t_list * action[3])\n",
        "    \n",
        "    \n",
        "# #     D.) Computation at the ECs\n",
        "#         T_EC_t_list = ((gamma_array * (self.D_array)[:, np.newaxis]) * (self.C_array)[:, np.newaxis]) / (self.EC_F_e_k / self.UE_count)\n",
        "    \n",
        "    \n",
        "\n",
        "#         # print(\"rho_array: \", rho_array)\n",
        "#         # print(\"T_G2A_t_list\", T_G2A_t_list)\n",
        "#         # print(\"E_G2A_t_list\", E_G2A_t_list)\n",
        "#         # print(\"T_UAV_t_list\", T_UAV_t_list)\n",
        "#         # print(\"E_UAV_t_list\", E_UAV_t_list)\n",
        "#         # print(\"T_A2G_t_list\", T_A2G_t_list)\n",
        "#         # print(\"E_A2G_t_list\", E_A2G_t_list)\n",
        "        \n",
        "#         E_t = (rho_array * self.lambda_m * (E_G2A_t_list + E_UAV_t_list + (E_A2G_t_list.sum(axis = 1)))).sum()\n",
        "#         T_t = (rho_array * (T_G2A_t_list + np.maximum(T_UAV_t_list, (T_A2G_t_list + T_EC_t_list).max(axis = 1)))).sum()\n",
        "        \n",
        "#         U_t = (self.w1 * E_t) + (self.w2 * T_t)  # objective function\n",
        "#         # print(\"U_t: \", U_t)\n",
        "        \n",
        "#     #Reward: \n",
        "#         coverage_penalty = -1 * (self.UE_count - M_t) * self.eta_3  # coverage constraint penalty\n",
        "#         # print(\"coverage penalty: \", coverage_penalty)\n",
        "    \n",
        "#         #TODO for multi-agent:\n",
        "#         overlapping_penalty = 0  # overlapping constraint penalty\n",
        "#         collision_penalty = 0  # collision constraint penalty\n",
        "        \n",
        "        \n",
        "#         if(M_t != self.UE_count):\n",
        "#             reward = coverage_penalty + overlapping_penalty + collision_penalty  # complete this\n",
        "#         else:\n",
        "#             reward = -1 * U_t\n",
        "            \n",
        "#         reward += self.reward_bias\n",
        "#         # print(\"reward: \", reward)\n",
        "            \n",
        "#         self.is_done()\n",
        "\n",
        "#         # if(self.done):\n",
        "#         #   print(\"------------------------\", \"reward in episode's last step: \", reward, \"------------------------\")\n",
        "        \n",
        "#         return self.current_state, reward, self.done, None\n",
        "    \n",
        "    \n",
        "#     def is_done(self):\n",
        "#         '''\n",
        "#         Helper function to check if episode needs to be terminated\n",
        "#         '''\n",
        "#         if(self.timesteps_in_episode >= self.max_episode_steps):\n",
        "#             self.done = True\n",
        "    \n",
        "    \n",
        "#     def select_random_state(self):\n",
        "#         '''\n",
        "#         Selects and assigns random initial state (within bounds) to the UAV\n",
        "#         '''\n",
        "#         new_x = np.random.uniform(0.0, self.boundary_x)\n",
        "#         new_y = np.random.uniform(0.0, self.boundary_y)\n",
        "#         new_z = np.random.uniform(self.Z_min, self.Z_max)\n",
        "# #         new_x = math.floor(np.random.uniform(0.0, boundary_x) * 100) / 100\n",
        "# #         new_y = math.floor(np.random.uniform(0.0, boundary_y) * 100) / 100\n",
        "# #         new_z = math.floor(np.random.uniform(Z_min, Z_max) * 100) / 100\n",
        "        \n",
        "#         return np.array([new_x, new_y, new_z])\n",
        "    \n",
        "    \n",
        "#     def move(self, action):\n",
        "#         '''\n",
        "#         Helper function to step() function.\n",
        "#         Clips the passed action to fit within action space bounds.\n",
        "#         Calculates new state after performing the passed action, and updates UAV position accordingly. \n",
        "#         '''\n",
        "# #         evaluates new state reached upon performing the move and saves it in self.current_state\n",
        "# #         returns the clamped action\n",
        "\n",
        "#         # print(\"action length after move 1: \", action.shape[0])\n",
        "#         self.previous_state = self.current_state\n",
        "#         # print(\"current state before moving: \", self.previous_state)\n",
        "#     # updating vertical flight new state:\n",
        "#         delta_z = action[2] = np.clip(action[2], -self.L_v_max, self.L_v_max)\n",
        "#         z_next = np.clip(self.current_state[2] + delta_z, self.Z_min, self.Z_max)\n",
        "#         # print(\"action length after move 2: \", action.shape[0])\n",
        "#     # updating gamma parameters in action:\n",
        "#         action[3] = np.clip(action[3], 0, self.P_max)\n",
        "#         # print(\"action length after move 3: \", action.shape[0])\n",
        "#         gamma_remaining = np.ones(self.UE_count, dtype = np.float32)\n",
        "#         gamma_array = np.clip((np.array(action[4:])).reshape((self.UE_count, self.EC_count)), 0.0, 1.0)\n",
        "#         for m in range(self.UE_count):\n",
        "#             for k in range(self.EC_count):\n",
        "#                 gamma_array[m][k] = np.clip(gamma_array[m][k], 0.0, gamma_remaining[m])\n",
        "#                 gamma_remaining[m] -= gamma_array[m][k]    \n",
        "#         action[4:] = gamma_array.flatten()\n",
        "    \n",
        "#         # print(\"action length after move 4: \", action.shape[0])\n",
        "    \n",
        "#     # updating horizontal_fly_distance and horizontal_direction_angle\n",
        "#         action[0] = horizontal_fly_distance = np.clip(action[0], 0, self.L_h_max)\n",
        "#         action[1] = horizontal_direction_angle = np.clip(action[1], 0, 2 * math.pi)\n",
        "#         # print(\"action length after move 5: \", action.shape[0])    \n",
        "#         # print(\"horizontal direction angle: \", horizontal_direction_angle)\n",
        "#         x_next_dash = self.current_state[0] + (horizontal_fly_distance * np.cos(horizontal_direction_angle)) \n",
        "#         y_next_dash = self.current_state[1] + (horizontal_fly_distance * np.sin(horizontal_direction_angle))\n",
        "    \n",
        "#     # updating horizontal_direction_angle if the new move is out of boundary\n",
        "#         if((x_next_dash < 0) or (x_next_dash > self.boundary_x) or (y_next_dash < 0) or (y_next_dash > self.boundary_y)):\n",
        "#             action[1] = horizontal_direction_angle = np.random.uniform(0, 2 * math.pi)\n",
        "        \n",
        "#     # updating new planar co-ordinates (x_next, y_next)\n",
        "#         x_next = np.clip(self.current_state[0] + (horizontal_fly_distance * np.cos(horizontal_direction_angle)), 0., self.boundary_x)\n",
        "#         y_next = np.clip(self.current_state[1] + (horizontal_fly_distance * np.sin(horizontal_direction_angle)), 0., self.boundary_y)\n",
        "        \n",
        "#         self.current_state = np.array([x_next, y_next, z_next])\n",
        "        \n",
        "#         # print(\"new state after move: \", self.current_state)\n",
        "        \n",
        "#         # print(\"action: \", action)\n",
        "#         return action\n",
        "        \n",
        "\n",
        "#     def helper_assign_Dm_Cm_to_UEs(self):\n",
        "#         '''\n",
        "#         Initializes D_array and C_array (denoting D_m and C_m values for each UE)\n",
        "#         '''\n",
        "#         for _ in range(self.UE_count):\n",
        "#             D_m = np.random.randint(self.D_m_min, self.D_m_max)\n",
        "#             self.D_array.append(D_m)\n",
        "#             C_m = np.random.randint(100, 200)\n",
        "#             self.C_array.append(C_m)\n",
        "#         self.D_array = np.array(self.D_array)\n",
        "#         self.C_array = np.array(self.C_array)\n",
        "#         # W = [D_m, C_m, lambda_m]\n",
        "#         return\n",
        "\n",
        "    \n",
        "#     def place_UEs_centered(self, desired_z_coord = None, center = None, centered_UE_count = None):\n",
        "#         '''\n",
        "#         Helper function to place_UEs\n",
        "#         Places `centered_UE_count` UEs within a circle with center `center` and radius `C_max_t`.\n",
        "#         Places remaining UEs (UE_count - centered_UE_count) randomly inside the area barring the above circular region\n",
        "#         Arguments: \n",
        "#             desired_z_coord: Z coordinate with which to calculate radius C_max_t for centering UEs\n",
        "#             center: Provides center of circular region in which UEs will be scattered\n",
        "#             centered_UE_count: Number of UEs to be placed within the circular region created using previous arguments\n",
        "#         '''\n",
        "\n",
        "#         if centered_UE_count is None:\n",
        "#           centered_UE_count = self.UE_count\n",
        "#         # focuses the UEs inside the circular region\n",
        "#         if(desired_z_coord == None): \n",
        "#           height_ = self.Z_max\n",
        "#         else:\n",
        "#           height_ = desired_z_coord\n",
        "#         radius = C_max_t = (height_ / np.tan(self.phi_n))\n",
        "#         if(center == None):\n",
        "#             # (x, y) co-ordinates\n",
        "#             x = np.random.uniform(0, self.boundary_x)\n",
        "# #             x = math.ceil(x*100)/100\n",
        "#             y = np.random.uniform(0, self.boundary_y)\n",
        "# #             y = math.ceil(y*100)/100\n",
        "#             center = np.array([x, y, 0.])\n",
        "\n",
        "#         r = radius * np.sqrt(np.random.uniform(size = centered_UE_count))\n",
        "#         theta = np.random.uniform(size = centered_UE_count) * 2 * math.pi\n",
        "\n",
        "#       # For testing: To plot the circle and visualize UE points inside it\n",
        "#         self.UE_center = center\n",
        "#         self.UE_radius = radius\n",
        "#         # print(\"self.UE_center: \", self.UE_center, \" self.UE_radius: \", self.UE_radius)\n",
        "#       # End\n",
        "\n",
        "#         self.UE_positions = np.zeros((centered_UE_count, 3))\n",
        "#         self.UE_positions[:, 0] = np.clip(center[0] + r * np.cos(theta), 0., self.boundary_x) \n",
        "#         self.UE_positions[:, 1] = np.clip(center[1] + r * np.sin(theta), 0., self.boundary_y)\n",
        "#         return\n",
        "\n",
        "\n",
        "#     def place_UEs_randomly(self, random_UE_count = None, **kwargs):\n",
        "#         '''\n",
        "#         Helper function to place_UEs\n",
        "#         places `random_UE_count` UEs randomly onto the rectangular region\n",
        "#         if kwargs has the key `exclude_center`, then the circular region spanned by `exclude_center` \\\n",
        "#         and `exclude_radius` is excluded\n",
        "\n",
        "#         '''\n",
        "\n",
        "#         if random_UE_count is None:\n",
        "#           random_UE_count = self.UE_count\n",
        "\n",
        "#         # places UE_count UEs on grid randomly\n",
        "#         if type(self.UE_positions) == np.ndarray:\n",
        "#             self.UE_positions = self.UE_positions.tolist()\n",
        "\n",
        "#         randomly_placed_count = 0\n",
        "#         while(randomly_placed_count < random_UE_count):\n",
        "#             #(x, y) co-ordinates\n",
        "#             x = np.random.uniform(0, self.boundary_x)\n",
        "# #             x = math.ceil(x*100)/100\n",
        "#             y = np.random.uniform(0, self.boundary_y)\n",
        "# #             y = math.ceil(y*100)/100\n",
        "#             coords = np.array((x, y, 0.))\n",
        "#             if 'exclude_center' in kwargs:\n",
        "#                 if (np.linalg.norm(coords - kwargs['exclude_center']) <= kwargs['exclude_radius']):\n",
        "#                     continue\n",
        "#             self.UE_positions.append(coords)\n",
        "#             randomly_placed_count += 1\n",
        "\n",
        "#         self.UE_positions = np.array(self.UE_positions)\n",
        "\n",
        "\n",
        "#     def place_UEs(self, position=\"random\", desired_z_coord = None, center = None):\n",
        "#         '''\n",
        "#         Function to place UEs onto the rectangular region\n",
        "#         Arguments:\n",
        "#             position: has 2 modes, \"random\" and \"centered\", representing the two configuration for scattering UEs\n",
        "#             desired_z_coord: if position=\"centered\", this argument gives height with which to calculate radius of circular region\n",
        "#             center: if position=\"centered\", this argument provides center of circular region\n",
        "#         '''\n",
        "\n",
        "#         self.UE_center = None  # initializing for non-centered generation algorithms\n",
        "\n",
        "#         if(position==\"centered\"):\n",
        "#             ratio = 0.65\n",
        "#             centered_count = int(ratio * self.UE_count)\n",
        "#             self.place_UEs_centered(desired_z_coord, center, centered_count)\n",
        "#             if(self.UE_count - centered_count > 0):\n",
        "#                 self.place_UEs_randomly(self.UE_count - centered_count, exclude_center = self.UE_center, exclude_radius = self.UE_radius)\n",
        "#         elif(position==\"random\"):\n",
        "#             self.place_UEs_randomly()\n",
        "\n",
        "#         # saves in self.UE_coord_list, assigns (D_m, C_m, lambda_m) to them\n",
        "#         self.UE_positions = np.array(self.UE_positions)\n",
        "#         self.helper_assign_Dm_Cm_to_UEs()\n",
        "#         # print(\"UE positions: \", self.UE_positions)\n",
        "#         # print(\"D_m array: \", self.D_array)\n",
        "#         # print(\"C_m array: \", self.C_array)\n",
        "#         return\n",
        "\n",
        "\n",
        "#     def place_ECs_randomly(self):\n",
        "#         '''\n",
        "#         Function to scatter EC_count ECs throughout rectangular region\n",
        "#         '''\n",
        "\n",
        "# #         places EC_count ECs in random locations\n",
        "# #         randomly assigns F_e_k for all ECs\n",
        "#         for _ in range(self.EC_count):\n",
        "#             x = np.random.uniform(0, self.boundary_x)\n",
        "# #             x = math.ceil(x*100)/100\n",
        "#             y = np.random.uniform(0, self.boundary_y)\n",
        "# #             y = math.ceil(y*100)/100\n",
        "#             coords = np.array((x, y, 0.))\n",
        "#             # coords[:2] = self.UE_center\n",
        "\n",
        "#             #TESTING CODE\n",
        "#             self.EC_positions.append(coords)\n",
        "#             #END\n",
        "\n",
        "#             self.EC_F_e_k.append(np.random.randint(self.F_e_k_min, self.F_e_k_max, dtype = np.int64))\n",
        "#         self.EC_F_e_k = np.array(self.EC_F_e_k)\n",
        "#         self.EC_positions = np.array(self.EC_positions)\n",
        "        \n",
        "#         # print(\"EC positions: \", self.EC_positions)\n",
        "#         # print(\"Computation resource at ECs F^e_k: \", self.EC_F_e_k)\n",
        "        \n",
        "#         return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "6cyqd-YGouS6"
      },
      "outputs": [],
      "source": [
        "# # Environment Class\n",
        "\n",
        "# class Single_Agent_UAV(Env):\n",
        "#     def __init__(self, initial_UAV_state = None):\n",
        "#         '''\n",
        "#         Initializes necessary parameters of environment (UE_positions, UAV_initial_position, EC_positions, D_array, C_array, etc.) \n",
        "#         '''\n",
        "#         super(Single_Agent_UAV, self).__init__()\n",
        "#         # Environment Parameters\n",
        "\n",
        "#         self.UE_seed = 1\n",
        "#         self.UE_count = 60\n",
        "#         self.EC_count = 1\n",
        "#         self.C_min = 100\n",
        "#         self.C_max = 200\n",
        "#         self.D_m_min = 1e6 # in bits\n",
        "#         self.D_m_max = 5e6 # in bits\n",
        "#         self.Z_max = 40\n",
        "#         self.Z_min = 20\n",
        "#         self.L_h_max = 49\n",
        "#         self.L_v_max = 12\n",
        "#         self.D_min = 100\n",
        "#         self.lambda_m = 1\n",
        "#         self.phi_n = np.radians(42.44)  # in degrees\n",
        "#         self.g_0 = 1e-5 # in power gain # -50 in dB\n",
        "#         self.B_u = 10 * 1e6  # in Hz\n",
        "#         self.B_k = 0.5 * 1e6  # in Hz\n",
        "#         self.P_max = 5\n",
        "#         self.P_m = 0.1\n",
        "#         self.P_r_n = 0.1\n",
        "#         self.F_u = 3e9 # in Hz\n",
        "#         self.F_e_k_max = 9e9 # in Hz\n",
        "#         self.F_e_k_min = 6e9 # in Hz\n",
        "#         self.kappa = (1e-28) # check if float maintains this precision\n",
        "#         self.sigma_squared_u = (1e-13) # in watt # -100 in dBm\n",
        "#         self.sigma_squared_e = (1e-13) # in watt # -100 in dBm\n",
        "#         self.w1 = self.w2 = 1\n",
        "#         self.eta_1 = 25\n",
        "#         self.eta_2 = 25\n",
        "#         self.eta_3 = 25\n",
        "#         self.boundary_x = self.boundary_y = 150.\n",
        "#         self.reward_bias = int(self.UE_count * 0.5 * self.eta_3)\n",
        "#         self.max_episode_steps = 10 # Maximum number of steps in a single episode, after which environment returns done = True\n",
        "\n",
        "\n",
        "#         # plotting parameters\n",
        "#         self.plotting_boundary_buffer = 5.\n",
        "#         self.UAV_coverage_circle_color = 'lavender'\n",
        "#         self.EC_concentrated_region_color = 'mistyrose'\n",
        "#         self.UAV_path_color = 'green'\n",
        "\n",
        "#         # Environment Bounds\n",
        "\n",
        "#         self.action_space_coversion_lb = np.zeros(3)\n",
        "#         self.action_space_coversion_lb[2] = -self.L_v_max\n",
        "#         self.action_space_coversion_ub = np.ones(3)\n",
        "#         self.action_space_coversion_ub[0:3] = np.array([self.L_h_max, 2 * math.pi, self.L_v_max]) \n",
        "\n",
        "#         self.action_space_lb = -1 * np.ones(3)\n",
        "#         self.action_space_ub = np.ones(3)\n",
        "#         self.state_space_lb = np.array([0, 0, self.Z_min])\n",
        "#         self.state_space_ub = np.array([self.boundary_x, self.boundary_y, self.Z_max])\n",
        "\n",
        "\n",
        "# #         self.state_shape = \n",
        "# #         defining action space\n",
        "#         self.state_space = gym.spaces.box.Box(low = self.state_space_lb, high = self.state_space_ub)\n",
        "# #         defining observation space\n",
        "#         self.action_space = gym.spaces.box.Box(low = self.action_space_lb, high = self.action_space_ub)\n",
        "        \n",
        "#         self.timesteps_in_episode = 0\n",
        "#         self.done = False\n",
        "#         self.last_action = self.action_space.sample()\n",
        "\n",
        "#         self.UE_positions = []\n",
        "#         self.EC_positions = []\n",
        "#         self.EC_F_e_k = []\n",
        "#         self.D_array = []\n",
        "#         self.C_array = []\n",
        "# #         initialize grid dimensions (400 x 400) \n",
        "#         if initial_UAV_state is not None:\n",
        "#           self.current_state = np.array(initial_UAV_state)\n",
        "#         else:\n",
        "#           self.current_state = self.select_random_state()\n",
        "        \n",
        "#         self.initial_UAV_state = self.current_state\n",
        "        \n",
        "#         self.previous_state = self.current_state\n",
        "#         print(\"initial state of UAV: \", self.current_state)\n",
        "    \n",
        "# #         call function to place UEs on the grid and specify (D_m, C_m, lambda_m) for UAVs\n",
        "#         self.place_UEs(position=\"centered\", desired_z_coord = (self.Z_min + self.Z_max) / 2, center = None)\n",
        "#         self.place_ECs_randomly()\n",
        "\n",
        "\n",
        "#     def get_count_of_UEs_covered(self):\n",
        "#         '''\n",
        "#         Returns count of UEs covered under UAV's current configuration\n",
        "#         '''\n",
        "\n",
        "#         C_max_t = (self.current_state[2] / np.tan(self.phi_n))\n",
        "        \n",
        "#         ground_UAV_state = np.zeros(3)\n",
        "#         ground_UAV_state[:2] = self.current_state[:2]\n",
        "#         horizontal_dist_UE_UAV = np.linalg.norm(self.UE_positions - ground_UAV_state, axis = 1)\n",
        "#         dist_UE_UAV = np.linalg.norm(self.UE_positions - self.current_state, axis = 1)\n",
        "#         # print(\"horizontal distance b/w UEs and UAV: \", horizontal_dist_UE_UAV)\n",
        "#         # print(\"distance b/w UEs and UAV: \", dist_UE_UAV)\n",
        "#         rho_array = (horizontal_dist_UE_UAV <= (C_max_t)) * 1  # binary association vector\n",
        "#         M_t = rho_array.sum()\n",
        "\n",
        "#         return M_t\n",
        "\n",
        "    \n",
        "#     def render_policy_plot(self, **kwargs):\n",
        "\n",
        "#         fig, ax = plt.subplots(1, figsize=(10,10))\n",
        "#         position_action_list = kwargs['position_action_list']\n",
        "#         for position_action in position_action_list:\n",
        "#             position = position_action[0]\n",
        "#             action = position_action[1]\n",
        "#             new_state = self.move(action, get_new_state=True)\n",
        "#             ax.arrow(position[0], position[1], new_state[0] - position[0], new_state[1] - position[1], head_width=0.09, head_length=0.1)\n",
        "#         plt.show()\n",
        "#         return\n",
        "\n",
        "\n",
        "#     def render_UAV_movement_through_episode(self, **kwargs):\n",
        "#         '''\n",
        "#         Helper function to visualize UAV movement through an episode\n",
        "#         Arguments: A list specifying UAV positions throughout the episode\n",
        "#         '''\n",
        "\n",
        "#         if 'reward' not in kwargs:\n",
        "#             kwargs['reward'] = 'Not known'\n",
        "        \n",
        "#         C_max_t = (kwargs['UAV_positions_list'][-1][2] / np.tan(self.phi_n))\n",
        "#         buffer = 5.\n",
        "#         fig, ax = plt.subplots(1, figsize=(10,10))\n",
        "#         ax.set_xlim(-buffer, self.boundary_x+buffer)\n",
        "#         ax.set_ylim(-buffer, self.boundary_y+buffer)\n",
        "#         ax.grid()\n",
        "#         UE_x = self.UE_positions[:, 0]\n",
        "#         UE_y = self.UE_positions[:, 1]\n",
        "#         ax.plot(UE_x, UE_y, color='black', marker='o', markersize=6, linestyle = '', label = \"UE\")\n",
        "        \n",
        "#         EC_x = self.EC_positions[:, 0]\n",
        "#         EC_y = self.EC_positions[:, 1]\n",
        "#         ax.plot(EC_x, EC_y, color='red', marker='D', markersize=7, linestyle = '', label = \"EC\")\n",
        "        \n",
        "#         ax.plot(np.array(kwargs['UAV_positions_list'])[:, 0] , np.array(kwargs['UAV_positions_list'])[:, 1], color=self.UAV_path_color, markersize=6, linestyle = '-', label = \"UAV Path Color\")\n",
        "#         ax.plot(kwargs['UAV_positions_list'][-1][0], kwargs['UAV_positions_list'][-1][1], color='blue', marker='x', markersize=9, linestyle = '', label = \"UAV ending position\")\n",
        "        \n",
        "#         UAV_coverage_area = plt.Circle((kwargs['UAV_positions_list'][-1][0], kwargs['UAV_positions_list'][-1][1]), C_max_t, color = self.UAV_coverage_circle_color)\n",
        "#         ax.add_artist(UAV_coverage_area)\n",
        "      \n",
        "#       # For testing: To plot the circle and visualize UE points inside it\n",
        "#         if self.UE_center is not None:\n",
        "#             Test_UE_allotment_circle = plt.Circle((self.UE_center[0] , self.UE_center[1]), self.UE_radius, color = self.EC_concentrated_region_color)\n",
        "#             ax.add_artist(Test_UE_allotment_circle)\n",
        "#       # End\n",
        "\n",
        "#         ax.set_aspect(1)\n",
        "#         # naming the x axis\n",
        "#         ax.set_xlabel('X pos (m)')\n",
        "#         # naming the y axis\n",
        "#         ax.set_ylabel('Y pos (m)')\n",
        "#         ax.set_title('UAV movement through episode')\n",
        "#         # giving a title to my graph\n",
        "#         # plt.title('Visually Appealing!')\n",
        "\n",
        "#         # show a legend on the plot\n",
        "#         ax.legend()\n",
        "#         # plt.show()\n",
        "#         return\n",
        "\n",
        "\n",
        "#     def render_bar_plot(self, ax, plot_number, idx):\n",
        "#         '''\n",
        "#         Plotting bar graph of each UE's fraction of tasks assigned to UAV and to EC, by the last action input given to step() function\n",
        "#         '''\n",
        "#         x_indices = np.arange(self.UE_count)\n",
        "#         width = 0.5\n",
        "\n",
        "#         gamma_array = (np.array(self.last_action[4:])).reshape((self.UE_count, self.EC_count))\n",
        "#         gamma_zeros = (1 - gamma_array.sum(axis = 1))\n",
        "        \n",
        "#         ax[plot_number, idx].bar(x_indices, gamma_zeros, width=width)\n",
        "#         for i in range(self.EC_count):\n",
        "#             ax[plot_number, idx].bar(x_indices, gamma_array[:, i], width=width)\n",
        "        \n",
        "    \n",
        "#     def render_position_plot(self, **kwargs):\n",
        "#         '''\n",
        "#         Helper function to render(), plots the current position plot on given axes. \n",
        "#         Plotting position plot of UAV's current position and coverage\n",
        "#         '''\n",
        "#         ax = kwargs['ax']\n",
        "#         plot_number = kwargs['i']\n",
        "#         idx = 0\n",
        "#         reward = kwargs['reward']\n",
        "\n",
        "#         C_max_t = (self.current_state[2] / np.tan(self.phi_n))\n",
        "#         buffer = 5.\n",
        "#         ax[plot_number, idx].set_xlim(-buffer, self.boundary_x+buffer)\n",
        "#         ax[plot_number, idx].set_ylim(-buffer, self.boundary_y+buffer)\n",
        "#         ax[plot_number, idx].grid()\n",
        "#         UE_x = self.UE_positions[:, 0]\n",
        "#         UE_y = self.UE_positions[:, 1]\n",
        "#         ax[plot_number, idx].plot(UE_x, UE_y, color='black', marker='o', markersize=6, linestyle = '', label = \"UE\")\n",
        "        \n",
        "#         EC_x = self.EC_positions[:, 0]\n",
        "#         EC_y = self.EC_positions[:, 1]\n",
        "#         ax[plot_number, idx].plot(EC_x, EC_y, color='red', marker='D', markersize=7, linestyle = '', label = \"EC\")\n",
        "        \n",
        "#         ax[plot_number, idx].plot(self.current_state[0], self.current_state[1], color='blue', marker='x', markersize=9, linestyle = '', label = \"UAV\")\n",
        "        \n",
        "#         UAV_coverage_area = plt.Circle((self.current_state[0] , self.current_state[1] ), C_max_t, color = self.UAV_coverage_circle_color)\n",
        "#         ax[plot_number, idx].add_artist(UAV_coverage_area)\n",
        "      \n",
        "#       # For testing: To plot the circle and visualize UE points inside it\n",
        "#         if self.UE_center is not None:\n",
        "#             Test_UE_allotment_circle = plt.Circle((self.UE_center[0] , self.UE_center[1]), self.UE_radius, color = self.EC_concentrated_region_color)\n",
        "#             ax[plot_number, idx].add_artist(Test_UE_allotment_circle)\n",
        "#       # End\n",
        "\n",
        "#         if 'learnt_policy_visualization' in kwargs:\n",
        "#             position_action_list = kwargs['position_action_list']\n",
        "#             for position_action in position_action_list:\n",
        "#                 position = position_action[0]\n",
        "#                 action = position_action[1]\n",
        "#                 action = np.clip(action, self.action_space_lb, self.action_space_ub)\n",
        "#                 action = (((self.action_space_coversion_ub - self.action_space_coversion_lb) * (action + 1)) / 2) + self.action_space_coversion_lb\n",
        "#                 # print(\"action after scaling: \", action)\n",
        "#                 new_state = self.move(action, get_new_state=True, provided_center=position)\n",
        "#                 # print(\"new_state: \", new_state)\n",
        "#                 ax[plot_number, idx].plot(position[0], position[1], color='blue', marker='o', markersize=6, linestyle = '')\n",
        "#                 ax[plot_number, idx].plot(new_state[0], new_state[1], color='orange', marker='o', markersize=6, linestyle = '')\n",
        "#                 ax[plot_number, idx].arrow(position[0], position[1], new_state[0] - position[0], new_state[1] - position[1], head_width=0.2, head_length=0.1)\n",
        "\n",
        "\n",
        "#         ax[plot_number, idx].set_aspect(1)\n",
        "#         # naming the x axis\n",
        "#         ax[plot_number, idx].set_xlabel('X pos (m)')\n",
        "#         # naming the y axis\n",
        "#         ax[plot_number, idx].set_ylabel('Y pos (m)')\n",
        "#         ax[plot_number, idx].set_title('reward: ' + str(reward))\n",
        "#         # giving a title to my graph\n",
        "#         # plt.title('Visually Appealing!')\n",
        "\n",
        "#         # show a legend on the plot\n",
        "#         ax[plot_number, idx].legend()\n",
        "#         # plt.show()\n",
        "\n",
        "\n",
        "#     def render(self, **kwargs):\n",
        "#         '''\n",
        "#         Function to visualize UAV position\n",
        "#         (this function has different configurations for different use cases)\n",
        "#         '''\n",
        "\n",
        "#         if 'UAV_positions_list' in kwargs:\n",
        "#             self.render_UAV_movement_through_episode(UAV_positions_list = kwargs['UAV_positions_list'])\n",
        "\n",
        "#         if 'fig' not in kwargs:\n",
        "#             fig, ax = plt.subplots(1, 2, figsize=(20,10))\n",
        "#             ax = np.array([ax])\n",
        "#             kwargs['fig'] = fig\n",
        "#             kwargs['ax'] = ax\n",
        "#             kwargs['i'] = 0\n",
        "        \n",
        "#         if 'reward' not in kwargs:\n",
        "#             kwargs['reward'] = 'Not known'\n",
        "#         self.render_position_plot(**kwargs)\n",
        "#         # if(self.timesteps_in_episode != 0):\n",
        "#         #     self.render_bar_plot(kwargs['ax'], kwargs['i'], 1)\n",
        "\n",
        "\n",
        "#     def reset(self):\n",
        "#         '''\n",
        "#         Resets the environment paramters to some initial values\n",
        "#         '''\n",
        "# #         we should only reassign the position of UAV here\n",
        "#         # Commenting for TESTING\n",
        "#         self.current_state = self.select_random_state()\n",
        "#         # Commenting for TESTING done\n",
        "#         self.this_episode_UAV_positions_list = []\n",
        "#         # self.current_state = self.initial_UAV_state\n",
        "#         # print(\"new initial state of UAV (after resetting): \", self.current_state)\n",
        "\n",
        "#         self.timesteps_in_episode = 0\n",
        "#         self.done = False\n",
        "#         return self.current_state\n",
        "    \n",
        "    \n",
        "#     def step(self, action):\n",
        "#         '''\n",
        "#         Takes action moving environment from current_state to next_state\n",
        "#         Arguments: `action` to be taken\n",
        "#         Returns: new_state, reward, done, info(=None)\n",
        "#         '''\n",
        "#         # print(\"printing action in step function: \", action)\n",
        "#         action = np.array(action).flatten()\n",
        "#         action = np.clip(action, self.action_space_lb, self.action_space_ub)\n",
        "#         # print(\"clipped action inside Environment: \", action)\n",
        "#         action = (((self.action_space_coversion_ub - self.action_space_coversion_lb) * (action + 1)) / 2) + self.action_space_coversion_lb\n",
        "#         # print(\"scaled action: \", action)\n",
        "# #         action is of the form [l_n(t), v_n(t), del_z_n(t), P_t_n(t), gamma_0_1(t), ..., gamma_0_k(t), gamma_1_1(t), ..., gamma_1_k(t), ..., gamma_m_k(t)]\n",
        "# #         What happens if (sum of gamma_n_m_k != 1) ?\n",
        "# #         The above problem has been dealt by not including gamma_i_0(t) in predicted action.\n",
        "# #         Rather, we evaluate it as:- gamma_i_0(t) = 1 - summation(gamma_i_k(t))\n",
        "#         # print(\"action just before moving: \", action.shape[0])\n",
        "#         self.timesteps_in_episode += 1\n",
        "#         # print(\"P_t of action: \", action[3])\n",
        "#         action = self.move(action)\n",
        "#         # print(\"UAV position: \", self.current_state)\n",
        "#         self.last_action = action\n",
        "#         # print(\"action after moving: \", action)\n",
        "        \n",
        "#         C_max_t = (self.current_state[2] / np.tan(self.phi_n))\n",
        "        \n",
        "#         ground_UAV_state = np.zeros(3)\n",
        "#         ground_UAV_state[:2] = self.current_state[:2]\n",
        "#         horizontal_dist_UE_UAV = np.linalg.norm(self.UE_positions - ground_UAV_state, axis = 1)\n",
        "#         dist_UE_UAV = np.linalg.norm(self.UE_positions - self.current_state, axis = 1)\n",
        "#         # print(\"horizontal distance b/w UEs and UAV: \", horizontal_dist_UE_UAV)\n",
        "#         # print(\"distance b/w UEs and UAV: \", dist_UE_UAV)\n",
        "#         rho_array = (horizontal_dist_UE_UAV <= (C_max_t)) * 1  # binary association vector\n",
        "#         M_t = rho_array.sum()  # no. of UEs served by the agent\n",
        "#         # print(\"UEs covered: \", M_t)\n",
        "#         # print(\"M_t: \", M_t, \" C_max_t: \", C_max_t)\n",
        "        \n",
        "#         try:\n",
        "#             if(M_t==0):\n",
        "#                 raise ValueError(\"-----UAV serves no UEs in its present state-----\")\n",
        "        \n",
        "#         except ValueError:\n",
        "#             #Reward: \n",
        "#             reward = coverage_penalty = -1 * (self.UE_count - M_t) * self.eta_3  # coverage constraint penalty\n",
        "#             reward += self.reward_bias\n",
        "#             # print(\"coverage penalty = reward:- \", coverage_penalty)\n",
        "#             self.is_done()\n",
        "    \n",
        "#             # if(self.done):\n",
        "#             #   print(\"------------------------\", \"reward in episode's last step: \", reward, \"------------------------\")\n",
        "    \n",
        "\n",
        "#             return self.current_state, reward, self.done, None\n",
        "            \n",
        "        \n",
        "#         dist_EC_UAV = np.linalg.norm(self.EC_positions - self.current_state, axis = 1)\n",
        "        \n",
        "#     #Reward: \n",
        "#         coverage_penalty = -1 * (self.UE_count - M_t) * self.eta_3  # coverage constraint penalty\n",
        "#         # print(\"coverage penalty: \", coverage_penalty)\n",
        "    \n",
        "#         #TODO for multi-agent:\n",
        "#         overlapping_penalty = 0  # overlapping constraint penalty\n",
        "#         collision_penalty = 0  # collision constraint penalty\n",
        "        \n",
        "#         reward = coverage_penalty + overlapping_penalty + collision_penalty  # complete this        \n",
        "#         reward += self.reward_bias\n",
        "#         # print(\"reward: \", reward)\n",
        "            \n",
        "#         self.is_done()\n",
        "\n",
        "#         # if(self.done):\n",
        "#         #   print(\"------------------------\", \"reward in episode's last step: \", reward, \"------------------------\")\n",
        "        \n",
        "#         return self.current_state, reward, self.done, None\n",
        "    \n",
        "    \n",
        "#     def is_done(self):\n",
        "#         '''\n",
        "#         Helper function to check if episode needs to be terminated\n",
        "#         '''\n",
        "#         if(self.timesteps_in_episode >= self.max_episode_steps):\n",
        "#             self.done = True\n",
        "    \n",
        "    \n",
        "#     def select_random_state(self):\n",
        "#         '''\n",
        "#         Selects and assigns random initial state (within bounds) to the UAV\n",
        "#         '''\n",
        "#         new_x = np.random.uniform(0.0, self.boundary_x)\n",
        "#         new_y = np.random.uniform(0.0, self.boundary_y)\n",
        "#         new_z = np.random.uniform(self.Z_min, self.Z_max)\n",
        "# #         new_x = math.floor(np.random.uniform(0.0, boundary_x) * 100) / 100\n",
        "# #         new_y = math.floor(np.random.uniform(0.0, boundary_y) * 100) / 100\n",
        "# #         new_z = math.floor(np.random.uniform(Z_min, Z_max) * 100) / 100\n",
        "        \n",
        "#         return np.array([new_x, new_y, new_z])\n",
        "    \n",
        "    \n",
        "#     def move(self, action, get_new_state=False, provided_center=None):\n",
        "#         '''\n",
        "#         Helper function to step() function.\n",
        "#         Clips the passed action to fit within action space bounds.\n",
        "#         Calculates new state after performing the passed action, and updates UAV position accordingly. \n",
        "#         '''\n",
        "# #         evaluates new state reached upon performing the move and saves it in self.current_state\n",
        "# #         returns the clamped action\n",
        "\n",
        "#         # print(\"action length after move 1: \", action.shape[0])\n",
        "#         if get_new_state == False:\n",
        "#             self.previous_state = self.current_state\n",
        "#         # print(\"current state before moving: \", self.previous_state)\n",
        "#     # updating vertical flight new state:\n",
        "#         delta_z = action[2] = np.clip(action[2], -self.L_v_max, self.L_v_max)\n",
        "#         z_next = np.clip(self.current_state[2] + delta_z, self.Z_min, self.Z_max)\n",
        "#         # print(\"action length after move 2: \", action.shape[0])\n",
        "    \n",
        "#     # updating horizontal_fly_distance and horizontal_direction_angle\n",
        "#         action[0] = horizontal_fly_distance = np.clip(action[0], 0, self.L_h_max)\n",
        "#         action[1] = horizontal_direction_angle = np.clip(action[1], 0, 2 * math.pi)\n",
        "#         # print(\"action length after move 5: \", action.shape[0])    \n",
        "#         # print(\"horizontal direction angle: \", horizontal_direction_angle)\n",
        "#         if get_new_state:\n",
        "#             x_next_dash = provided_center[0] + (horizontal_fly_distance * np.cos(horizontal_direction_angle)) \n",
        "#             y_next_dash = provided_center[1] + (horizontal_fly_distance * np.sin(horizontal_direction_angle))\n",
        "#         else:\n",
        "#             x_next_dash = self.current_state[0] + (horizontal_fly_distance * np.cos(horizontal_direction_angle)) \n",
        "#             y_next_dash = self.current_state[1] + (horizontal_fly_distance * np.sin(horizontal_direction_angle))\n",
        "      \n",
        "#     # updating horizontal_direction_angle if the new move is out of boundary\n",
        "#         if((x_next_dash < 0) or (x_next_dash > self.boundary_x) or (y_next_dash < 0) or (y_next_dash > self.boundary_y)):\n",
        "#             action[1] = horizontal_direction_angle = np.random.uniform(0, 2 * math.pi)\n",
        "        \n",
        "#     # updating new planar co-ordinates (x_next, y_next)\n",
        "#         if get_new_state:\n",
        "#             x_next = np.clip(provided_center[0] + (horizontal_fly_distance * np.cos(horizontal_direction_angle)), 0., self.boundary_x)\n",
        "#             y_next = np.clip(provided_center[1] + (horizontal_fly_distance * np.sin(horizontal_direction_angle)), 0., self.boundary_y)\n",
        "#         else:    \n",
        "#             x_next = np.clip(self.current_state[0] + (horizontal_fly_distance * np.cos(horizontal_direction_angle)), 0., self.boundary_x)\n",
        "#             y_next = np.clip(self.current_state[1] + (horizontal_fly_distance * np.sin(horizontal_direction_angle)), 0., self.boundary_y)\n",
        "        \n",
        "#         if get_new_state:\n",
        "#             # print(\"clipped action inside move(): \", action)\n",
        "#             return np.array([x_next, y_next, z_next])\n",
        "\n",
        "#         self.current_state = np.array([x_next, y_next, z_next])\n",
        "        \n",
        "#         # print(\"new state after move: \", self.current_state)\n",
        "        \n",
        "#         # print(\"action: \", action)\n",
        "#         return action\n",
        "        \n",
        "\n",
        "#     def helper_assign_Dm_Cm_to_UEs(self):\n",
        "#         '''\n",
        "#         Initializes D_array and C_array (denoting D_m and C_m values for each UE)\n",
        "#         '''\n",
        "#         for _ in range(self.UE_count):\n",
        "#             D_m = np.random.randint(self.D_m_min, self.D_m_max)\n",
        "#             self.D_array.append(D_m)\n",
        "#             C_m = np.random.randint(100, 200)\n",
        "#             self.C_array.append(C_m)\n",
        "#         self.D_array = np.array(self.D_array)\n",
        "#         self.C_array = np.array(self.C_array)\n",
        "#         # W = [D_m, C_m, lambda_m]\n",
        "#         return\n",
        "\n",
        "    \n",
        "#     def place_UEs_centered(self, desired_z_coord = None, center = None, centered_UE_count = None):\n",
        "#         '''\n",
        "#         Helper function to place_UEs\n",
        "#         Places `centered_UE_count` UEs within a circle with center `center` and radius `C_max_t`.\n",
        "#         Places remaining UEs (UE_count - centered_UE_count) randomly inside the area barring the above circular region\n",
        "#         Arguments: \n",
        "#             desired_z_coord: Z coordinate with which to calculate radius C_max_t for centering UEs\n",
        "#             center: Provides center of circular region in which UEs will be scattered\n",
        "#             centered_UE_count: Number of UEs to be placed within the circular region created using previous arguments\n",
        "#         '''\n",
        "\n",
        "#         if centered_UE_count is None:\n",
        "#           centered_UE_count = self.UE_count\n",
        "#         # focuses the UEs inside the circular region\n",
        "#         if(desired_z_coord == None): \n",
        "#           height_ = self.Z_max\n",
        "#         else:\n",
        "#           height_ = desired_z_coord\n",
        "#         radius = C_max_t = (height_ / np.tan(self.phi_n))\n",
        "#         if(center == None):\n",
        "#             # (x, y) co-ordinates\n",
        "#             x = np.random.uniform(0, self.boundary_x)\n",
        "# #             x = math.ceil(x*100)/100\n",
        "#             y = np.random.uniform(0, self.boundary_y)\n",
        "# #             y = math.ceil(y*100)/100\n",
        "#             center = np.array([x, y, 0.])\n",
        "\n",
        "#         r = radius * np.sqrt(np.random.uniform(size = centered_UE_count))\n",
        "#         theta = np.random.uniform(size = centered_UE_count) * 2 * math.pi\n",
        "\n",
        "#       # For testing: To plot the circle and visualize UE points inside it\n",
        "#         self.UE_center = center\n",
        "#         self.UE_radius = radius\n",
        "#         # print(\"self.UE_center: \", self.UE_center, \" self.UE_radius: \", self.UE_radius)\n",
        "#       # End\n",
        "\n",
        "#         self.UE_positions = np.zeros((centered_UE_count, 3))\n",
        "#         self.UE_positions[:, 0] = np.clip(center[0] + r * np.cos(theta), 0., self.boundary_x) \n",
        "#         self.UE_positions[:, 1] = np.clip(center[1] + r * np.sin(theta), 0., self.boundary_y)\n",
        "#         return\n",
        "\n",
        "\n",
        "#     def place_UEs_randomly(self, random_UE_count = None, **kwargs):\n",
        "#         '''\n",
        "#         Helper function to place_UEs\n",
        "#         places `random_UE_count` UEs randomly onto the rectangular region\n",
        "#         if kwargs has the key `exclude_center`, then the circular region spanned by `exclude_center` \\\n",
        "#         and `exclude_radius` is excluded\n",
        "\n",
        "#         '''\n",
        "\n",
        "#         if random_UE_count is None:\n",
        "#           random_UE_count = self.UE_count\n",
        "\n",
        "#         # places UE_count UEs on grid randomly\n",
        "#         if type(self.UE_positions) == np.ndarray:\n",
        "#             self.UE_positions = self.UE_positions.tolist()\n",
        "\n",
        "#         randomly_placed_count = 0\n",
        "#         while(randomly_placed_count < random_UE_count):\n",
        "#             #(x, y) co-ordinates\n",
        "#             x = np.random.uniform(0, self.boundary_x)\n",
        "# #             x = math.ceil(x*100)/100\n",
        "#             y = np.random.uniform(0, self.boundary_y)\n",
        "# #             y = math.ceil(y*100)/100\n",
        "#             coords = np.array((x, y, 0.))\n",
        "#             if 'exclude_center' in kwargs:\n",
        "#                 if (np.linalg.norm(coords - kwargs['exclude_center']) <= kwargs['exclude_radius']):\n",
        "#                     continue\n",
        "#             self.UE_positions.append(coords)\n",
        "#             randomly_placed_count += 1\n",
        "\n",
        "#         self.UE_positions = np.array(self.UE_positions)\n",
        "\n",
        "\n",
        "#     def place_UEs(self, position=\"random\", desired_z_coord = None, center = None):\n",
        "#         '''\n",
        "#         Function to place UEs onto the rectangular region\n",
        "#         Arguments:\n",
        "#             position: has 2 modes, \"random\" and \"centered\", representing the two configuration for scattering UEs\n",
        "#             desired_z_coord: if position=\"centered\", this argument gives height with which to calculate radius of circular region\n",
        "#             center: if position=\"centered\", this argument provides center of circular region\n",
        "#         '''\n",
        "\n",
        "#         self.UE_center = None  # initializing for non-centered generation algorithms\n",
        "\n",
        "#         if(position==\"centered\"):\n",
        "#             ratio = 0.65\n",
        "#             centered_count = int(ratio * self.UE_count)\n",
        "#             self.place_UEs_centered(desired_z_coord, center, centered_count)\n",
        "#             if(self.UE_count - centered_count > 0):\n",
        "#                 self.place_UEs_randomly(self.UE_count - centered_count, exclude_center = self.UE_center, exclude_radius = self.UE_radius)\n",
        "#         elif(position==\"random\"):\n",
        "#             self.place_UEs_randomly()\n",
        "\n",
        "#         # saves in self.UE_coord_list, assigns (D_m, C_m, lambda_m) to them\n",
        "#         self.UE_positions = np.array(self.UE_positions)\n",
        "#         self.helper_assign_Dm_Cm_to_UEs()\n",
        "#         # print(\"UE positions: \", self.UE_positions)\n",
        "#         # print(\"D_m array: \", self.D_array)\n",
        "#         # print(\"C_m array: \", self.C_array)\n",
        "#         return\n",
        "\n",
        "\n",
        "#     def place_ECs_randomly(self):\n",
        "#         '''\n",
        "#         Function to scatter EC_count ECs throughout rectangular region\n",
        "#         '''\n",
        "\n",
        "# #         places EC_count ECs in random locations\n",
        "# #         randomly assigns F_e_k for all ECs\n",
        "#         for _ in range(self.EC_count):\n",
        "#             x = np.random.uniform(0, self.boundary_x)\n",
        "# #             x = math.ceil(x*100)/100\n",
        "#             y = np.random.uniform(0, self.boundary_y)\n",
        "# #             y = math.ceil(y*100)/100\n",
        "#             coords = np.array((x, y, 0.))\n",
        "#             # coords[:2] = self.UE_center\n",
        "\n",
        "#             #TESTING CODE\n",
        "#             self.EC_positions.append(coords)\n",
        "#             #END\n",
        "\n",
        "#             self.EC_F_e_k.append(np.random.randint(self.F_e_k_min, self.F_e_k_max, dtype = np.int64))\n",
        "#         self.EC_F_e_k = np.array(self.EC_F_e_k)\n",
        "#         self.EC_positions = np.array(self.EC_positions)\n",
        "        \n",
        "#         # print(\"EC positions: \", self.EC_positions)\n",
        "#         # print(\"Computation resource at ECs F^e_k: \", self.EC_F_e_k)\n",
        "        \n",
        "#         return"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Environment Class\n",
        "\n",
        "class Single_Agent_UAV(Env):\n",
        "    def __init__(self, initial_UAV_state = None):\n",
        "        '''\n",
        "        Initializes necessary parameters of environment (UE_positions, UAV_initial_position, EC_positions, D_array, C_array, etc.) \n",
        "        '''\n",
        "        super(Single_Agent_UAV, self).__init__()\n",
        "        # Environment Parameters\n",
        "\n",
        "        self.UE_seed = 1\n",
        "        self.UE_count = 100\n",
        "        self.EC_count = 1\n",
        "        self.C_min = 100\n",
        "        self.C_max = 200\n",
        "        self.D_m_min = 1e6 # in bits\n",
        "        self.D_m_max = 5e6 # in bits\n",
        "        self.Z_max = 40\n",
        "        self.Z_min = 20\n",
        "        self.L_h_max = 49\n",
        "        self.L_v_max = 12\n",
        "        self.D_min = 100\n",
        "        self.lambda_m = 1\n",
        "        self.phi_n = np.radians(42.44)  # in degrees\n",
        "        self.g_0 = 1e-5 # in power gain # -50 in dB\n",
        "        self.B_u = 10 * 1e6  # in Hz\n",
        "        self.B_k = 0.5 * 1e6  # in Hz\n",
        "        self.P_max = 5\n",
        "        self.P_m = 0.1\n",
        "        self.P_r_n = 0.1\n",
        "        self.F_u = 3e9 # in Hz\n",
        "        self.F_e_k_max = 9e9 # in Hz\n",
        "        self.F_e_k_min = 6e9 # in Hz\n",
        "        self.kappa = (1e-28) # check if float maintains this precision\n",
        "        self.sigma_squared_u = (1e-13) # in watt # -100 in dBm\n",
        "        self.sigma_squared_e = (1e-13) # in watt # -100 in dBm\n",
        "        self.w1 = self.w2 = 1\n",
        "        self.eta_1 = 25\n",
        "        self.eta_2 = 25\n",
        "        self.eta_3 = 25\n",
        "        self.boundary_x = self.boundary_y = 100.\n",
        "        self.reward_bias = int(self.UE_count * 0.5 * self.eta_3)\n",
        "        self.max_episode_steps = 1 # Maximum number of steps in a single episode, after which environment returns done = True\n",
        "\n",
        "\n",
        "        # plotting parameters\n",
        "        self.plotting_boundary_buffer = 5.\n",
        "        self.UAV_coverage_circle_color = 'lavender'\n",
        "        self.EC_concentrated_region_color = 'mistyrose'\n",
        "        self.UAV_path_color = 'green'\n",
        "\n",
        "        # Environment Bounds\n",
        "\n",
        "        self.action_space_coversion_lb = -np.ones(2)\n",
        "        self.action_space_coversion_ub = np.ones(2)\n",
        "\n",
        "        # self.action_space_coversion_lb[0:2] = np.array([0, 0]) \n",
        "        self.action_space_coversion_lb[0:2] = np.array([-self.L_h_max, -self.L_h_max]) \n",
        "        # self.action_space_coversion_ub[0:2] = np.array([self.L_h_max, 2 * math.pi]) \n",
        "        self.action_space_coversion_ub[0:2] = np.array([self.L_h_max, self.L_h_max]) \n",
        "\n",
        "\n",
        "        self.action_space_lb = -1 * np.ones(2)\n",
        "        self.action_space_ub = np.ones(2)\n",
        "        self.state_space_lb = np.array([0, 0])\n",
        "        self.state_space_ub = np.array([self.boundary_x, self.boundary_y])\n",
        "\n",
        "\n",
        "#         self.state_shape = \n",
        "#         defining action space\n",
        "        self.state_space = gym.spaces.box.Box(low = self.state_space_lb, high = self.state_space_ub)\n",
        "#         defining observation space\n",
        "        self.action_space = gym.spaces.box.Box(low = self.action_space_lb, high = self.action_space_ub)\n",
        "        \n",
        "        self.timesteps_in_episode = 0\n",
        "        self.done = False\n",
        "        self.last_action = self.action_space.sample()\n",
        "\n",
        "        self.UE_positions = []\n",
        "        self.EC_positions = []\n",
        "        self.EC_F_e_k = []\n",
        "        self.D_array = []\n",
        "        self.C_array = []\n",
        "#         initialize grid dimensions (400 x 400) \n",
        "        if initial_UAV_state is not None:\n",
        "          self.current_state = np.array(initial_UAV_state)\n",
        "        else:\n",
        "          self.current_state = self.select_random_state()\n",
        "        \n",
        "        self.initial_UAV_state = self.current_state\n",
        "        \n",
        "        self.previous_state = self.current_state\n",
        "        print(\"initial state of UAV: \", self.current_state)\n",
        "    \n",
        "#         call function to place UEs on the grid and specify (D_m, C_m, lambda_m) for UAVs\n",
        "        self.place_UEs(position=\"centered\", desired_z_coord = (self.Z_min + self.Z_max) / 2, center = None)\n",
        "        self.place_ECs_randomly()\n",
        "\n",
        "\n",
        "    def get_count_of_UEs_covered(self):\n",
        "        '''\n",
        "        Returns count of UEs covered under UAV's current configuration\n",
        "        '''\n",
        "\n",
        "        C_max_t = (self.Z_max / np.tan(self.phi_n))\n",
        "        \n",
        "        ground_UAV_state = self.current_state\n",
        "        horizontal_dist_UE_UAV = np.linalg.norm(self.UE_positions - ground_UAV_state, axis = 1)\n",
        "        # print(\"horizontal distance b/w UEs and UAV: \", horizontal_dist_UE_UAV)\n",
        "        rho_array = (horizontal_dist_UE_UAV <= (C_max_t)) * 1  # binary association vector\n",
        "        M_t = rho_array.sum()\n",
        "\n",
        "        return M_t\n",
        "\n",
        "    \n",
        "    def render_policy_plot(self, **kwargs):\n",
        "\n",
        "        fig, ax = plt.subplots(1, figsize=(10,10))\n",
        "        position_action_list = kwargs['position_action_list']\n",
        "        for position_action in position_action_list:\n",
        "            position = position_action[0]\n",
        "            action = position_action[1]\n",
        "            new_state = self.move(action, get_new_state=True)\n",
        "            ax.arrow(position[0], position[1], new_state[0] - position[0], new_state[1] - position[1], head_width=0.09, head_length=0.1)\n",
        "        plt.show()\n",
        "        return\n",
        "\n",
        "\n",
        "    def render_UAV_movement_through_episode(self, **kwargs):\n",
        "        '''\n",
        "        Helper function to visualize UAV movement through an episode\n",
        "        Arguments: A list specifying UAV positions throughout the episode\n",
        "        '''\n",
        "\n",
        "        if 'reward' not in kwargs:\n",
        "            kwargs['reward'] = 'Not known'\n",
        "        \n",
        "        C_max_t = (self.Z_max / np.tan(self.phi_n))\n",
        "        buffer = 5.\n",
        "        fig, ax = plt.subplots(1, figsize=(10,10))\n",
        "        ax.set_xlim(-buffer, self.boundary_x+buffer)\n",
        "        ax.set_ylim(-buffer, self.boundary_y+buffer)\n",
        "        ax.grid()\n",
        "        UE_x = self.UE_positions[:, 0]\n",
        "        UE_y = self.UE_positions[:, 1]\n",
        "        ax.plot(UE_x, UE_y, color='black', marker='o', markersize=6, linestyle = '', label = \"UE\")\n",
        "        \n",
        "        EC_x = self.EC_positions[:, 0]\n",
        "        EC_y = self.EC_positions[:, 1]\n",
        "        ax.plot(EC_x, EC_y, color='red', marker='D', markersize=7, linestyle = '', label = \"EC\")\n",
        "        \n",
        "        ax.plot(np.array(kwargs['UAV_positions_list'])[:, 0] , np.array(kwargs['UAV_positions_list'])[:, 1], color=self.UAV_path_color, markersize=6, linestyle = '-', label = \"UAV Path Color\")\n",
        "        ax.plot(kwargs['UAV_positions_list'][-1][0], kwargs['UAV_positions_list'][-1][1], color='blue', marker='x', markersize=9, linestyle = '', label = \"UAV ending position\")\n",
        "        \n",
        "        UAV_coverage_area = plt.Circle((kwargs['UAV_positions_list'][-1][0], kwargs['UAV_positions_list'][-1][1]), C_max_t, color = self.UAV_coverage_circle_color)\n",
        "        ax.add_artist(UAV_coverage_area)\n",
        "      \n",
        "      # For testing: To plot the circle and visualize UE points inside it\n",
        "        if self.UE_center is not None:\n",
        "            Test_UE_allotment_circle = plt.Circle((self.UE_center[0] , self.UE_center[1]), self.UE_radius, color = self.EC_concentrated_region_color)\n",
        "            ax.add_artist(Test_UE_allotment_circle)\n",
        "      # End\n",
        "\n",
        "        ax.set_aspect(1)\n",
        "        # naming the x axis\n",
        "        ax.set_xlabel('X pos (m)')\n",
        "        # naming the y axis\n",
        "        ax.set_ylabel('Y pos (m)')\n",
        "        ax.set_title('UAV movement through episode')\n",
        "        # giving a title to my graph\n",
        "        # plt.title('Visually Appealing!')\n",
        "\n",
        "        # show a legend on the plot\n",
        "        ax.legend()\n",
        "        # plt.show()\n",
        "        return\n",
        "\n",
        "\n",
        "    def render_bar_plot(self, ax, plot_number, idx):\n",
        "        '''\n",
        "        Plotting bar graph of each UE's fraction of tasks assigned to UAV and to EC, by the last action input given to step() function\n",
        "        '''\n",
        "        x_indices = np.arange(self.UE_count)\n",
        "        width = 0.5\n",
        "\n",
        "        gamma_array = (np.array(self.last_action[4:])).reshape((self.UE_count, self.EC_count))\n",
        "        gamma_zeros = (1 - gamma_array.sum(axis = 1))\n",
        "        \n",
        "        ax[plot_number, idx].bar(x_indices, gamma_zeros, width=width)\n",
        "        for i in range(self.EC_count):\n",
        "            ax[plot_number, idx].bar(x_indices, gamma_array[:, i], width=width)\n",
        "        \n",
        "    \n",
        "    def render_position_plot(self, **kwargs):\n",
        "        '''\n",
        "        Helper function to render(), plots the current position plot on given axes. \n",
        "        Plotting position plot of UAV's current position and coverage\n",
        "        '''\n",
        "        ax = kwargs['ax']\n",
        "        plot_number = kwargs['i']\n",
        "        idx = 0\n",
        "        reward = kwargs['reward']\n",
        "\n",
        "        C_max_t = (self.Z_max / np.tan(self.phi_n))\n",
        "        buffer = 5.\n",
        "        ax[plot_number, idx].set_xlim(-buffer, self.boundary_x+buffer)\n",
        "        ax[plot_number, idx].set_ylim(-buffer, self.boundary_y+buffer)\n",
        "        ax[plot_number, idx].grid()\n",
        "        UE_x = self.UE_positions[:, 0]\n",
        "        UE_y = self.UE_positions[:, 1]\n",
        "        ax[plot_number, idx].plot(UE_x, UE_y, color='black', marker='o', markersize=6, linestyle = '', label = \"UE\")\n",
        "        \n",
        "        EC_x = self.EC_positions[:, 0]\n",
        "        EC_y = self.EC_positions[:, 1]\n",
        "        ax[plot_number, idx].plot(EC_x, EC_y, color='red', marker='D', markersize=7, linestyle = '', label = \"EC\")\n",
        "        \n",
        "        ax[plot_number, idx].plot(self.current_state[0], self.current_state[1], color='blue', marker='x', markersize=9, linestyle = '', label = \"UAV\")\n",
        "        \n",
        "        UAV_coverage_area = plt.Circle((self.current_state[0] , self.current_state[1] ), C_max_t, color = self.UAV_coverage_circle_color)\n",
        "        ax[plot_number, idx].add_artist(UAV_coverage_area)\n",
        "      \n",
        "      # For testing: To plot the circle and visualize UE points inside it\n",
        "        if self.UE_center is not None:\n",
        "            Test_UE_allotment_circle = plt.Circle((self.UE_center[0] , self.UE_center[1]), self.UE_radius, color = self.EC_concentrated_region_color)\n",
        "            ax[plot_number, idx].add_artist(Test_UE_allotment_circle)\n",
        "      # End\n",
        "\n",
        "        if 'learnt_policy_visualization' in kwargs:\n",
        "            position_action_list = kwargs['position_action_list']\n",
        "            for position_action in position_action_list:\n",
        "                position = position_action[0]\n",
        "                action = position_action[1]\n",
        "                action = np.clip(action, self.action_space_lb, self.action_space_ub)\n",
        "                action = (((self.action_space_coversion_ub - self.action_space_coversion_lb) * (action + 1)) / 2) + self.action_space_coversion_lb\n",
        "                print(\"scaled action: \", action)\n",
        "                # print(\"action after scaling: \", action)\n",
        "                new_state = self.move(action, get_new_state=True, provided_center=position)\n",
        "                print(\"previous state: \", position, \", new state: \", new_state)\n",
        "                # print(\"new_state: \", new_state)\n",
        "                ax[plot_number, idx].plot(position[0], position[1], color='blue', marker='o', markersize=6, linestyle = '')\n",
        "                ax[plot_number, idx].plot(new_state[0], new_state[1], color='orange', marker='o', markersize=6, linestyle = '')\n",
        "                ax[plot_number, idx].arrow(position[0], position[1], new_state[0] - position[0], new_state[1] - position[1], head_width=0.2, head_length=0.1)\n",
        "\n",
        "\n",
        "        ax[plot_number, idx].set_aspect(1)\n",
        "        # naming the x axis\n",
        "        ax[plot_number, idx].set_xlabel('X pos (m)')\n",
        "        # naming the y axis\n",
        "        ax[plot_number, idx].set_ylabel('Y pos (m)')\n",
        "        ax[plot_number, idx].set_title('reward: ' + str(reward))\n",
        "        # giving a title to my graph\n",
        "        # plt.title('Visually Appealing!')\n",
        "\n",
        "        # show a legend on the plot\n",
        "        ax[plot_number, idx].legend()\n",
        "        # plt.show()\n",
        "\n",
        "\n",
        "    def render(self, **kwargs):\n",
        "        '''\n",
        "        Function to visualize UAV position\n",
        "        (this function has different configurations for different use cases)\n",
        "        '''\n",
        "\n",
        "        if 'UAV_positions_list' in kwargs:\n",
        "            self.render_UAV_movement_through_episode(UAV_positions_list = kwargs['UAV_positions_list'])\n",
        "\n",
        "        if 'fig' not in kwargs:\n",
        "            fig, ax = plt.subplots(1, 2, figsize=(20,10))\n",
        "            ax = np.array([ax])\n",
        "            kwargs['fig'] = fig\n",
        "            kwargs['ax'] = ax\n",
        "            kwargs['i'] = 0\n",
        "        \n",
        "        if 'reward' not in kwargs:\n",
        "            kwargs['reward'] = 'Not known'\n",
        "        self.render_position_plot(**kwargs)\n",
        "        # if(self.timesteps_in_episode != 0):\n",
        "        #     self.render_bar_plot(kwargs['ax'], kwargs['i'], 1)\n",
        "\n",
        "\n",
        "    def reset(self):\n",
        "        '''\n",
        "        Resets the environment paramters to some initial values\n",
        "        '''\n",
        "#         we should only reassign the position of UAV here\n",
        "        # Commenting for TESTING\n",
        "        self.current_state = self.select_random_state()\n",
        "        # Commenting for TESTING done\n",
        "        self.this_episode_UAV_positions_list = []\n",
        "        # self.current_state = self.initial_UAV_state\n",
        "        # print(\"new initial state of UAV (after resetting): \", self.current_state)\n",
        "\n",
        "        self.timesteps_in_episode = 0\n",
        "        self.done = False\n",
        "        return self.current_state\n",
        "    \n",
        "\n",
        "    def ann_on_continuous_reward_testing_step_function(self, tf_action):\n",
        "        self.timesteps_in_episode += 1\n",
        "        current_state_tensor = tf.convert_to_tensor(self.current_state, dtype=tf.float32)\n",
        "        # tf_action = tf.clip_by_value(tf_action, clip_value_min = tf.convert_to_tensor(self.action_space_lb, dtype=tf.float32), clip_value_max = tf.convert_to_tensor(self.action_space_ub, dtype=tf.float32))\n",
        "        # print(\"clipped action inside Environment: \", action)\n",
        "        tf_action = (((tf.convert_to_tensor(self.action_space_coversion_ub - self.action_space_coversion_lb, dtype=tf.float32)) * (tf_action + 1)) / 2) + tf.convert_to_tensor(self.action_space_coversion_lb, dtype=tf.float32)\n",
        "        current_state_tensor = tf_action + current_state_tensor\n",
        "        # return tf.math.reduce_sum(current_state_tensor)\n",
        "\n",
        "        reward = self.calculate_continuous_reward(tf_new_UAV_state = current_state_tensor, ratio_for_calculating_k = 0.65)\n",
        "        self.current_state = np.clip(current_state_tensor.numpy(), a_min=self.state_space_lb, a_max=self.state_space_ub)\n",
        "        self.is_done()\n",
        "        return self.current_state, reward, self.done, None\n",
        "\n",
        "    \n",
        "    def step(self, action):\n",
        "        '''\n",
        "        Takes action moving environment from current_state to next_state\n",
        "        Arguments: `action` to be taken\n",
        "        Returns: new_state, reward, done, info(=None)\n",
        "        '''\n",
        "\n",
        "        ann_on_continuous_reward_testing = True\n",
        "        if ann_on_continuous_reward_testing: \n",
        "            return self.ann_on_continuous_reward_testing_step_function(action)\n",
        "\n",
        "        # print(\"printing action in step function: \", action)\n",
        "        action = np.array(action).flatten()\n",
        "        action = np.clip(action, self.action_space_lb, self.action_space_ub)\n",
        "        # print(\"clipped action inside Environment: \", action)\n",
        "        action = (((self.action_space_coversion_ub - self.action_space_coversion_lb) * (action + 1)) / 2) + self.action_space_coversion_lb\n",
        "        # print(\"scaled action: \", action)\n",
        "#         action is of the form [l_n(t), v_n(t), del_z_n(t), P_t_n(t), gamma_0_1(t), ..., gamma_0_k(t), gamma_1_1(t), ..., gamma_1_k(t), ..., gamma_m_k(t)]\n",
        "#         What happens if (sum of gamma_n_m_k != 1) ?\n",
        "#         The above problem has been dealt by not including gamma_i_0(t) in predicted action.\n",
        "#         Rather, we evaluate it as:- gamma_i_0(t) = 1 - summation(gamma_i_k(t))\n",
        "        # print(\"action just before moving: \", action.shape[0])\n",
        "        self.timesteps_in_episode += 1\n",
        "        # print(\"P_t of action: \", action[3])\n",
        "        action = self.move(action)\n",
        "        # print(\"UAV position: \", self.current_state)\n",
        "        self.last_action = action\n",
        "\n",
        "        ###TEST CODE\n",
        "        # Making the reward continuous\n",
        "        continuous_reward = True\n",
        "        if continuous_reward:\n",
        "            reward = self.calculate_continuous_reward(ratio_for_calculating_k = 0.65)\n",
        "            self.is_done()\n",
        "            return self.current_state, reward, self.done, None\n",
        "        ###TEST CODE ENDS HERE\n",
        "\n",
        "\n",
        "        # print(\"action after moving: \", action)\n",
        "        \n",
        "        C_max_t = (self.Z_max / np.tan(self.phi_n))\n",
        "        \n",
        "        ground_UAV_state = self.current_state\n",
        "        horizontal_dist_UE_UAV = np.linalg.norm(self.UE_positions - ground_UAV_state, axis = 1)\n",
        "        # print(\"horizontal distance b/w UEs and UAV: \", horizontal_dist_UE_UAV)\n",
        "        # print(\"distance b/w UEs and UAV: \", dist_UE_UAV)\n",
        "        rho_array = (horizontal_dist_UE_UAV <= (C_max_t)) * 1  # binary association vector\n",
        "        M_t = rho_array.sum()  # no. of UEs served by the agent\n",
        "        # print(\"UEs covered: \", M_t)\n",
        "        # print(\"M_t: \", M_t, \" C_max_t: \", C_max_t)\n",
        "        \n",
        "        try:\n",
        "            if(M_t==0):\n",
        "                raise ValueError(\"-----UAV serves no UEs in its present state-----\")\n",
        "        \n",
        "        except ValueError:\n",
        "            #Reward: \n",
        "            reward = coverage_penalty = -1 * (self.UE_count - M_t) * self.eta_3  # coverage constraint penalty\n",
        "            reward += self.reward_bias\n",
        "            # print(\"coverage penalty = reward:- \", coverage_penalty)\n",
        "            self.is_done()\n",
        "    \n",
        "            # if(self.done):\n",
        "            #   print(\"------------------------\", \"reward in episode's last step: \", reward, \"------------------------\")\n",
        "    \n",
        "\n",
        "            return self.current_state, reward, self.done, None\n",
        "            \n",
        "        \n",
        "    #Reward: \n",
        "        coverage_penalty = -1 * (self.UE_count - M_t) * self.eta_3  # coverage constraint penalty\n",
        "        # print(\"coverage penalty: \", coverage_penalty)\n",
        "    \n",
        "        #TODO for multi-agent:\n",
        "        overlapping_penalty = 0  # overlapping constraint penalty\n",
        "        collision_penalty = 0  # collision constraint penalty\n",
        "        \n",
        "        reward = coverage_penalty + overlapping_penalty + collision_penalty  # complete this        \n",
        "        reward += self.reward_bias\n",
        "        # print(\"reward: \", reward)\n",
        "            \n",
        "        self.is_done()\n",
        "\n",
        "        # if(self.done):\n",
        "        #   print(\"------------------------\", \"reward in episode's last step: \", reward, \"------------------------\")\n",
        "        \n",
        "        return self.current_state, reward, self.done, None\n",
        "    \n",
        "    \n",
        "    def is_done(self):\n",
        "        '''\n",
        "        Helper function to check if episode needs to be terminated\n",
        "        '''\n",
        "        if(self.timesteps_in_episode >= self.max_episode_steps):\n",
        "            self.done = True\n",
        "    \n",
        "    \n",
        "    def select_random_state(self):\n",
        "        '''\n",
        "        Selects and assigns random initial state (within bounds) to the UAV\n",
        "        '''\n",
        "        new_x = np.random.uniform(0.0, self.boundary_x)\n",
        "        new_y = np.random.uniform(0.0, self.boundary_y)\n",
        "#         new_x = math.floor(np.random.uniform(0.0, boundary_x) * 100) / 100\n",
        "#         new_y = math.floor(np.random.uniform(0.0, boundary_y) * 100) / 100\n",
        "#         new_z = math.floor(np.random.uniform(Z_min, Z_max) * 100) / 100\n",
        "        \n",
        "        return np.array([new_x, new_y])\n",
        "    \n",
        "    \n",
        "    def move(self, action, get_new_state=False, provided_center=None):\n",
        "        '''\n",
        "        Helper function to step() function.\n",
        "        Clips the passed action to fit within action space bounds.\n",
        "        Calculates new state after performing the passed action, and updates UAV position accordingly. \n",
        "        '''\n",
        "#         evaluates new state reached upon performing the move and saves it in self.current_state\n",
        "#         returns the clamped action\n",
        "\n",
        "        # TESTING CODE: [dx, dy]\n",
        "        action_in_dx_dy = True\n",
        "        new_state = (action + provided_center).clip(self.state_space_lb, self.state_space_ub)\n",
        "        return new_state\n",
        "        # TESTING CODE ENDS\n",
        "\n",
        "        # print(\"action length after move 1: \", action.shape[0])\n",
        "        if get_new_state == False:\n",
        "            self.previous_state = self.current_state\n",
        "        # print(\"current state before moving: \", self.previous_state)\n",
        "    # updating vertical flight new state:\n",
        "        \n",
        "    # updating horizontal_fly_distance and horizontal_direction_angle\n",
        "        action[0] = horizontal_fly_distance = np.clip(action[0], 0, self.L_h_max)\n",
        "        action[1] = horizontal_direction_angle = np.clip(action[1], 0, 2 * math.pi)\n",
        "        # print(\"action length after move 5: \", action.shape[0])    \n",
        "        # print(\"horizontal direction angle: \", horizontal_direction_angle)\n",
        "        if get_new_state:\n",
        "            x_next_dash = provided_center[0] + (horizontal_fly_distance * np.cos(horizontal_direction_angle)) \n",
        "            y_next_dash = provided_center[1] + (horizontal_fly_distance * np.sin(horizontal_direction_angle))\n",
        "        else:\n",
        "            x_next_dash = self.current_state[0] + (horizontal_fly_distance * np.cos(horizontal_direction_angle)) \n",
        "            y_next_dash = self.current_state[1] + (horizontal_fly_distance * np.sin(horizontal_direction_angle))\n",
        "      \n",
        "    # updating horizontal_direction_angle if the new move is out of boundary\n",
        "        if((x_next_dash < 0) or (x_next_dash > self.boundary_x) or (y_next_dash < 0) or (y_next_dash > self.boundary_y)):\n",
        "            action[1] = horizontal_direction_angle = np.random.uniform(0, 2 * math.pi)\n",
        "        \n",
        "    # updating new planar co-ordinates (x_next, y_next)\n",
        "        if get_new_state:\n",
        "            x_next = np.clip(provided_center[0] + (horizontal_fly_distance * np.cos(horizontal_direction_angle)), 0., self.boundary_x)\n",
        "            y_next = np.clip(provided_center[1] + (horizontal_fly_distance * np.sin(horizontal_direction_angle)), 0., self.boundary_y)\n",
        "        else:    \n",
        "            x_next = np.clip(self.current_state[0] + (horizontal_fly_distance * np.cos(horizontal_direction_angle)), 0., self.boundary_x)\n",
        "            y_next = np.clip(self.current_state[1] + (horizontal_fly_distance * np.sin(horizontal_direction_angle)), 0., self.boundary_y)\n",
        "        \n",
        "        if get_new_state:\n",
        "            # print(\"clipped action inside move(): \", action)\n",
        "            return np.array([x_next, y_next])\n",
        "\n",
        "        self.current_state = np.array([x_next, y_next])\n",
        "        \n",
        "        # print(\"new state after move: \", self.current_state)\n",
        "        \n",
        "        # print(\"action: \", action)\n",
        "        return action\n",
        "        \n",
        "\n",
        "    def calculate_continuous_reward(self, tf_new_UAV_state, ratio_for_calculating_k = 0.65):\n",
        "        '''\n",
        "        Function for computing a continuous reward. \n",
        "        Current Algorithm: Calculates mean distance of k closest UEs to current UAV position.\n",
        "        k = (ratio_for_calculating_k * self.UE_count)\n",
        "        '''\n",
        "\n",
        "        # Continuous Reward\n",
        "        k = int(ratio_for_calculating_k * env.UE_count)\n",
        "        UE_ground_positions = tf.convert_to_tensor(self.UE_positions[: ,:2], dtype=tf.float32)\n",
        "        horizontal_dist_UE_UAV = tf.norm(UE_ground_positions - tf_new_UAV_state, axis = 1)\n",
        "        # print(\"x: \", x, \", y: \", y)\n",
        "        # print(\"type(hor): \", type(horizontal_dist_UE_UAV))\n",
        "        # print(\"horizontal_dist_UE_UAV array: \", horizontal_dist_UE_UAV)\n",
        "        horizontal_dist_UE_UAV = tf.sort(horizontal_dist_UE_UAV)\n",
        "        # print(\"closest UE positions: \", horizontal_dist_UE_UAV[:k])\n",
        "        reward = tf.math.reduce_sum(horizontal_dist_UE_UAV[:k])\n",
        "        #TESTING CODE\n",
        "        #Checking if above sorting and selecting closest k makes the loss function non-differentiable\n",
        "        # reward = tf.math.reduce_sum(horizontal_dist_UE_UAV)\n",
        "        #TESTING CODE ENDS\n",
        "\n",
        "        # #RUBBISH\n",
        "        # k = int(ratio_for_calculating_k * self.UE_count)\n",
        "        # ground_UAV_state = self.current_state[:2]\n",
        "        # horizontal_dist_UE_UAV = np.linalg.norm(ground_UAV_state - self.UE_positions[: ,:2], axis = 1)\n",
        "        # horizontal_dist_UE_UAV = np.sort(horizontal_dist_UE_UAV)\n",
        "        # # print(\"closest UE positions: \", horizontal_dist_UE_UAV[:k])\n",
        "        # return horizontal_dist_UE_UAV[:k].sum()\n",
        "\n",
        "        return reward\n",
        "\n",
        "\n",
        "    def helper_assign_Dm_Cm_to_UEs(self):\n",
        "        '''\n",
        "        Initializes D_array and C_array (denoting D_m and C_m values for each UE)\n",
        "        '''\n",
        "        for _ in range(self.UE_count):\n",
        "            D_m = np.random.randint(self.D_m_min, self.D_m_max)\n",
        "            self.D_array.append(D_m)\n",
        "            C_m = np.random.randint(100, 200)\n",
        "            self.C_array.append(C_m)\n",
        "        self.D_array = np.array(self.D_array)\n",
        "        self.C_array = np.array(self.C_array)\n",
        "        # W = [D_m, C_m, lambda_m]\n",
        "        return\n",
        "\n",
        "    \n",
        "    def place_UEs_centered(self, desired_z_coord = None, center = None, centered_UE_count = None):\n",
        "        '''\n",
        "        Helper function to place_UEs\n",
        "        Places `centered_UE_count` UEs within a circle with center `center` and radius `C_max_t`.\n",
        "        Places remaining UEs (UE_count - centered_UE_count) randomly inside the area barring the above circular region\n",
        "        Arguments: \n",
        "            desired_z_coord: Z coordinate with which to calculate radius C_max_t for centering UEs\n",
        "            center: Provides center of circular region in which UEs will be scattered\n",
        "            centered_UE_count: Number of UEs to be placed within the circular region created using previous arguments\n",
        "        '''\n",
        "\n",
        "        if centered_UE_count is None:\n",
        "          centered_UE_count = self.UE_count\n",
        "        # focuses the UEs inside the circular region\n",
        "        if(desired_z_coord == None): \n",
        "          height_ = self.Z_max\n",
        "        else:\n",
        "          height_ = desired_z_coord\n",
        "        radius = C_max_t = (height_ / np.tan(self.phi_n))\n",
        "        if(center == None):\n",
        "            # (x, y) co-ordinates\n",
        "            x = np.random.uniform(0, self.boundary_x)\n",
        "#             x = math.ceil(x*100)/100\n",
        "            y = np.random.uniform(0, self.boundary_y)\n",
        "#             y = math.ceil(y*100)/100\n",
        "            center = np.array([x, y])\n",
        "\n",
        "        r = radius * np.sqrt(np.random.uniform(size = centered_UE_count))\n",
        "        theta = np.random.uniform(size = centered_UE_count) * 2 * math.pi\n",
        "\n",
        "      # For testing: To plot the circle and visualize UE points inside it\n",
        "        self.UE_center = center\n",
        "        self.UE_radius = radius\n",
        "        # print(\"self.UE_center: \", self.UE_center, \" self.UE_radius: \", self.UE_radius)\n",
        "      # End\n",
        "\n",
        "        self.UE_positions = np.zeros((centered_UE_count, 2))\n",
        "        self.UE_positions[:, 0] = np.clip(center[0] + r * np.cos(theta), 0., self.boundary_x) \n",
        "        self.UE_positions[:, 1] = np.clip(center[1] + r * np.sin(theta), 0., self.boundary_y)\n",
        "        return\n",
        "\n",
        "\n",
        "    def place_UEs_randomly(self, random_UE_count = None, **kwargs):\n",
        "        '''\n",
        "        Helper function to place_UEs\n",
        "        places `random_UE_count` UEs randomly onto the rectangular region\n",
        "        if kwargs has the key `exclude_center`, then the circular region spanned by `exclude_center` \\\n",
        "        and `exclude_radius` is excluded\n",
        "\n",
        "        '''\n",
        "\n",
        "        if random_UE_count is None:\n",
        "          random_UE_count = self.UE_count\n",
        "\n",
        "        # places UE_count UEs on grid randomly\n",
        "        if type(self.UE_positions) == np.ndarray:\n",
        "            self.UE_positions = self.UE_positions.tolist()\n",
        "\n",
        "        randomly_placed_count = 0\n",
        "        while(randomly_placed_count < random_UE_count):\n",
        "            #(x, y) co-ordinates\n",
        "            x = np.random.uniform(0, self.boundary_x)\n",
        "#             x = math.ceil(x*100)/100\n",
        "            y = np.random.uniform(0, self.boundary_y)\n",
        "#             y = math.ceil(y*100)/100\n",
        "            coords = np.array([x, y])\n",
        "            if 'exclude_center' in kwargs:\n",
        "                if (np.linalg.norm(coords - kwargs['exclude_center']) <= kwargs['exclude_radius']):\n",
        "                    continue\n",
        "            self.UE_positions.append(coords)\n",
        "            randomly_placed_count += 1\n",
        "\n",
        "        self.UE_positions = np.array(self.UE_positions)\n",
        "\n",
        "\n",
        "    def place_UEs(self, position=\"random\", desired_z_coord = None, center = None):\n",
        "        '''\n",
        "        Function to place UEs onto the rectangular region\n",
        "        Arguments:\n",
        "            position: has 2 modes, \"random\" and \"centered\", representing the two configuration for scattering UEs\n",
        "            desired_z_coord: if position=\"centered\", this argument gives height with which to calculate radius of circular region\n",
        "            center: if position=\"centered\", this argument provides center of circular region\n",
        "        '''\n",
        "\n",
        "        self.UE_center = None  # initializing for non-centered generation algorithms\n",
        "\n",
        "        if(position==\"centered\"):\n",
        "            ratio = 0.65\n",
        "            centered_count = int(ratio * self.UE_count)\n",
        "            self.place_UEs_centered(desired_z_coord, center, centered_count)\n",
        "            if(self.UE_count - centered_count > 0):\n",
        "                self.place_UEs_randomly(self.UE_count - centered_count, exclude_center = self.UE_center, exclude_radius = self.UE_radius)\n",
        "        elif(position==\"random\"):\n",
        "            self.place_UEs_randomly()\n",
        "\n",
        "        # saves in self.UE_coord_list, assigns (D_m, C_m, lambda_m) to them\n",
        "        self.UE_positions = np.array(self.UE_positions)\n",
        "        self.helper_assign_Dm_Cm_to_UEs()\n",
        "        # print(\"UE positions: \", self.UE_positions)\n",
        "        # print(\"D_m array: \", self.D_array)\n",
        "        # print(\"C_m array: \", self.C_array)\n",
        "        return\n",
        "\n",
        "\n",
        "    def place_ECs_randomly(self):\n",
        "        '''\n",
        "        Function to scatter EC_count ECs throughout rectangular region\n",
        "        '''\n",
        "\n",
        "#         places EC_count ECs in random locations\n",
        "#         randomly assigns F_e_k for all ECs\n",
        "        for _ in range(self.EC_count):\n",
        "            x = np.random.uniform(0, self.boundary_x)\n",
        "#             x = math.ceil(x*100)/100\n",
        "            y = np.random.uniform(0, self.boundary_y)\n",
        "#             y = math.ceil(y*100)/100\n",
        "            coords = np.array([x, y])\n",
        "            # coords[:2] = self.UE_center\n",
        "\n",
        "            #TESTING CODE\n",
        "            self.EC_positions.append(coords)\n",
        "            #END\n",
        "\n",
        "            self.EC_F_e_k.append(np.random.randint(self.F_e_k_min, self.F_e_k_max, dtype = np.int64))\n",
        "        self.EC_F_e_k = np.array(self.EC_F_e_k)\n",
        "        self.EC_positions = np.array(self.EC_positions)\n",
        "        \n",
        "        # print(\"EC positions: \", self.EC_positions)\n",
        "        # print(\"Computation resource at ECs F^e_k: \", self.EC_F_e_k)\n",
        "        \n",
        "        return"
      ],
      "metadata": {
        "id": "9j4LrivBVaLw"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AT-1V6vetj_g",
        "outputId": "0435d231-0001-404c-ef77-6c1710eb58eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "initial state of UAV:  [32.54130917  1.07899882]\n"
          ]
        }
      ],
      "source": [
        "env = Single_Agent_UAV()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 604
        },
        "id": "Cw_Xqv7GxvAy",
        "outputId": "4629ce50-2a1e-4444-a2ec-20d9945a7111"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of UEs covered:  23\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1440x720 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "env.render()\n",
        "print(\"Number of UEs covered: \", env.get_count_of_UEs_covered())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# env.reset()\n",
        "# env.render()"
      ],
      "metadata": {
        "id": "xiW0xak3iFt2"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_steps = 10000\n",
        "# checker = tf.convert_to_tensor(env.current_state)\n",
        "# v = tf.Variable(checker)\n",
        "x = tf.Variable(env.current_state[0])\n",
        "y = tf.Variable(env.current_state[1])\n",
        "for i in range(learning_steps):\n",
        "  with tf.GradientTape() as tape:\n",
        "\n",
        "    # Continuous Reward\n",
        "    ratio_for_calculating_k = 0.7\n",
        "    k = int(ratio_for_calculating_k * env.UE_count)\n",
        "    UE_ground_positions = tf.convert_to_tensor(env.UE_positions[: ,:2])\n",
        "    horizontal_dist_UE_UAV = tf.norm(UE_ground_positions - [x, y], axis = 1)\n",
        "    # horizontal_dist_UE_UAV = tf.norm(UE_ground_positions - v, axis = 1)\n",
        "    print(\"x: \", x, \", y: \", y)\n",
        "    # print(\"type(hor): \", type(horizontal_dist_UE_UAV))\n",
        "    # print(\"horizontal_dist_UE_UAV array: \", horizontal_dist_UE_UAV)\n",
        "    horizontal_dist_UE_UAV = tf.sort(horizontal_dist_UE_UAV)\n",
        "    # print(\"closest UE positions: \", horizontal_dist_UE_UAV[:k])\n",
        "    loss = tf.math.reduce_sum(horizontal_dist_UE_UAV[:k])\n",
        "\n",
        "    # # Discrete Reward\n",
        "    # C_max_t = (env.Z_max / np.tan(env.phi_n))\n",
        "    # UE_ground_positions = tf.convert_to_tensor(env.UE_positions[: ,:2])\n",
        "    # horizontal_dist_UE_UAV = tf.norm(UE_ground_positions - [x, y], axis = 1)\n",
        "    # rho_array = tf.cast((horizontal_dist_UE_UAV <= (tf.convert_to_tensor(C_max_t))), tf.float32)  # binary association vector\n",
        "    # M_t = tf.reduce_sum(rho_array)  # no. of UEs served by the agent\n",
        "    # print(\"M_t: \", M_t)\n",
        "    # loss = (env.UE_count - M_t) * 25\n",
        "    print(\"loss: \", loss)\n",
        "\n",
        "\n",
        "    # Gradient Descent\n",
        "    grads = tape.gradient(loss, [x, y])\n",
        "    print(\"gradients: \", grads)\n",
        "    print(\"--------------------------------------------------------\")\n",
        "    optimizer = tf.keras.optimizers.experimental.SGD(learning_rate=0.1)\n",
        "    optimizer.apply_gradients(zip(grads, [x, y]))\n",
        "    # print(\"type(v): \", v)\n",
        "    # optimizer.apply_gradients(zip(grads, v))"
      ],
      "metadata": {
        "id": "0BrGQFdvPcJt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "94e14add-53b9-44d7-982f-d3d6803b2315"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=7.319474226620604> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=4.432839125559274>\n",
            "loss:  tf.Tensor(4542.714740964559, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=-31.062994255035292>, <tf.Tensor: shape=(), dtype=float64, numpy=-51.79067344796591>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=10.425773698411602> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=9.611906547529982>\n",
            "loss:  tf.Tensor(4184.435028797518, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=-29.435782127178587>, <tf.Tensor: shape=(), dtype=float64, numpy=-50.335008110830046>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=13.369351954992194> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=14.645407433617994>\n",
            "loss:  tf.Tensor(3849.2863624828983, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=-28.00525356992816>, <tf.Tensor: shape=(), dtype=float64, numpy=-49.353284766845746>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=16.16987735371609> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=19.580735983844693>\n",
            "loss:  tf.Tensor(3534.025186304472, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=-25.785718416931275>, <tf.Tensor: shape=(), dtype=float64, numpy=-47.63258922341958>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=18.748449233832932> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=24.34399497716474>\n",
            "loss:  tf.Tensor(3254.2698768283753, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=-23.32271515614666>, <tf.Tensor: shape=(), dtype=float64, numpy=-43.917983350835684>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=21.08072078420115> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=28.735793377691202>\n",
            "loss:  tf.Tensor(3013.2319856779563, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=-20.592325456726535>, <tf.Tensor: shape=(), dtype=float64, numpy=-42.49082124729059>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=23.13995336055876> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=32.984875565736516>\n",
            "loss:  tf.Tensor(2798.0726057241127, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=-18.55981834284028>, <tf.Tensor: shape=(), dtype=float64, numpy=-39.79011837080901>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=24.99593522249907> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=36.96388746210931>\n",
            "loss:  tf.Tensor(2614.073076930449, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=-14.48138754135124>, <tf.Tensor: shape=(), dtype=float64, numpy=-37.77765477612818>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=26.444073998213145> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=40.74165299601522>\n",
            "loss:  tf.Tensor(2457.0068354305854, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=-10.892701208036886>, <tf.Tensor: shape=(), dtype=float64, numpy=-36.805388345733846>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=27.533344135248225> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=44.42219188543291>\n",
            "loss:  tf.Tensor(2315.4146977636465, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=-9.046524648616385>, <tf.Tensor: shape=(), dtype=float64, numpy=-34.59071546315792>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=28.437996613590236> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=47.881263483292884>\n",
            "loss:  tf.Tensor(2189.484888000164, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=-8.058638881551927>, <tf.Tensor: shape=(), dtype=float64, numpy=-34.82069097755711>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.243860513753738> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=51.36333263293547>\n",
            "loss:  tf.Tensor(2057.2603878010455, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=-6.610514490656692>, <tf.Tensor: shape=(), dtype=float64, numpy=-35.86587141990876>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.90491197266984> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=54.94991982837065>\n",
            "loss:  tf.Tensor(1930.1256993045217, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=-4.5050897566293475>, <tf.Tensor: shape=(), dtype=float64, numpy=-33.43977377950892>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=30.355420955045883> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=58.29389725615069>\n",
            "loss:  tf.Tensor(1824.1564314063585, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=-0.6648664715421003>, <tf.Tensor: shape=(), dtype=float64, numpy=-30.092829457834398>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=30.42190760319082> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=61.303180246775945>\n",
            "loss:  tf.Tensor(1740.0139133906912, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=-1.0458237500641374>, <tf.Tensor: shape=(), dtype=float64, numpy=-27.023880464926286>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=30.526489979755635> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=64.0055683335373>\n",
            "loss:  tf.Tensor(1674.4605772422133, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=-0.3806885708883366>, <tf.Tensor: shape=(), dtype=float64, numpy=-21.440323502545166>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=30.564558837411738> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=66.14960071574039>\n",
            "loss:  tf.Tensor(1633.5410659294564, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.586485838392962>, <tf.Tensor: shape=(), dtype=float64, numpy=-16.841928671994566>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=30.405910251208393> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=67.83379360803627>\n",
            "loss:  tf.Tensor(1605.7614651798053, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=0.8722514294737109>, <tf.Tensor: shape=(), dtype=float64, numpy=-14.583150844117748>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=30.318685106961265> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=69.29210871417864>\n",
            "loss:  tf.Tensor(1586.7233605131973, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=0.5585111289818268>, <tf.Tensor: shape=(), dtype=float64, numpy=-11.486277984801683>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=30.262833993230835> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=70.4407365297747>\n",
            "loss:  tf.Tensor(1575.0150565404101, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=-0.3038531653691932>, <tf.Tensor: shape=(), dtype=float64, numpy=-8.367447419183462>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=30.293219310220532> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=71.27748128416151>\n",
            "loss:  tf.Tensor(1569.2732229670482, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=0.46752322794104456>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.8341411189855386>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=30.246466986729764> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=71.8608954047536>\n",
            "loss:  tf.Tensor(1566.1622789236171, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=0.5408574122303904>, <tf.Tensor: shape=(), dtype=float64, numpy=-4.7575690444055105>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=30.192381244700783> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=72.33665231628349>\n",
            "loss:  tf.Tensor(1564.0725422665914, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=0.5315179311772962>, <tf.Tensor: shape=(), dtype=float64, numpy=-3.9069517573126373>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=30.13922945079103> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=72.72734749783656>\n",
            "loss:  tf.Tensor(1562.6537517674315, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=0.5038748685374919>, <tf.Tensor: shape=(), dtype=float64, numpy=-3.2156432002826323>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=30.08884196318645> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=73.0489118226565>\n",
            "loss:  tf.Tensor(1561.6862123397418, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=0.47002953116690477>, <tf.Tensor: shape=(), dtype=float64, numpy=-2.649687464937716>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=30.04183900936936> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=73.31388057309861>\n",
            "loss:  tf.Tensor(1561.0244713716897, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=0.43372851673080365>, <tf.Tensor: shape=(), dtype=float64, numpy=-2.184964852863633>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.998466157049975> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=73.53237706164083>\n",
            "loss:  tf.Tensor(1560.5708103502775, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=0.39668964416030006>, <tf.Tensor: shape=(), dtype=float64, numpy=-1.8028230512072754>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.95879719204283> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=73.71265936944798>\n",
            "loss:  tf.Tensor(1560.2591360533904, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=0.35997549365930165>, <tf.Tensor: shape=(), dtype=float64, numpy=-1.4883465523656794>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.922799642140493> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=73.86149402690235>\n",
            "loss:  tf.Tensor(1560.0445721154433, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=0.324346084663475>, <tf.Tensor: shape=(), dtype=float64, numpy=-1.2294243434214318>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.890365033190832> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=73.98443646307648>\n",
            "loss:  tf.Tensor(1559.896566449727, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=0.2903597923893521>, <tf.Tensor: shape=(), dtype=float64, numpy=-1.0161524072156165>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.861329053519228> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.08605170531223>\n",
            "loss:  tf.Tensor(1559.7942731614844, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=0.2584107920415939>, <tf.Tensor: shape=(), dtype=float64, numpy=-0.8404061882100871>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.835487973930007> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.17009232538554>\n",
            "loss:  tf.Tensor(1559.723439697728, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=0.22875281223359833>, <tf.Tensor: shape=(), dtype=float64, numpy=-0.6955131139461592>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.81261269236578> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.23964363781656>\n",
            "loss:  tf.Tensor(1559.6743014846852, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=0.20152130074911934>, <tf.Tensor: shape=(), dtype=float64, numpy=-0.5759917544581856>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.792460561990577> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.29724281412066>\n",
            "loss:  tf.Tensor(1559.6401547848059, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=0.17675561976521942>, <tf.Tensor: shape=(), dtype=float64, numpy=-0.47733973513373396>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.77478499975067> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.34497678834533>\n",
            "loss:  tf.Tensor(1559.6163875245413, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=0.15442038166816796>, <tf.Tensor: shape=(), dtype=float64, numpy=-0.39585960839691625>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.75934296135375> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.3845627497749>\n",
            "loss:  tf.Tensor(1559.599819962126, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=0.13442486014862537>, <tf.Tensor: shape=(), dtype=float64, numpy=-0.3285153613856343>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.745900475138576> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.41741428640299>\n",
            "loss:  tf.Tensor(1559.5882552992705, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=0.11663980278484876>, <tf.Tensor: shape=(), dtype=float64, numpy=-0.27281410092977587>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.734236494686286> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.44469569690249>\n",
            "loss:  tf.Tensor(1559.5801727668904, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=0.10091139108889352>, <tf.Tensor: shape=(), dtype=float64, numpy=-0.2267085846904806>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.724145355427027> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.46736655570936>\n",
            "loss:  tf.Tensor(1559.5745175627148, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=0.08707240312822406>, <tf.Tensor: shape=(), dtype=float64, numpy=-0.18851704175665596>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.715438114984455> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.48621826016594>\n",
            "loss:  tf.Tensor(1559.570556753956, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=0.07495082237450174>, <tf.Tensor: shape=(), dtype=float64, numpy=-0.15685731652057167>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.70794303263532> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.50190399205174>\n",
            "loss:  tf.Tensor(1559.5677802035877, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=0.06437623007081406>, <tf.Tensor: shape=(), dtype=float64, numpy=-0.13059285084064387>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.70150540953231> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.5149632773304>\n",
            "loss:  tf.Tensor(1559.5658322968038, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=0.05518434710490128>, <tf.Tensor: shape=(), dtype=float64, numpy=-0.1087884246791011>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.69598697473959> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.52584211996042>\n",
            "loss:  tf.Tensor(1559.5644647874233, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=0.047220079956859284>, <tf.Tensor: shape=(), dtype=float64, numpy=-0.09067392049791789>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.69126496667354> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.53490951214532>\n",
            "loss:  tf.Tensor(1559.5635041611883, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=0.04033939181490692>, <tf.Tensor: shape=(), dtype=float64, numpy=-0.07561467066382732>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.687231027431938> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.54247097932438>\n",
            "loss:  tf.Tensor(1559.5628290010084, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=0.03441027656367962>, <tf.Tensor: shape=(), dtype=float64, numpy=-0.06308719629751558>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.683789999724294> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.54877969904814>\n",
            "loss:  tf.Tensor(1559.5623542593262, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=0.02931306767849079>, <tf.Tensor: shape=(), dtype=float64, numpy=-0.0526593558232169>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.680858692912764> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.55404563470893>\n",
            "loss:  tf.Tensor(1559.5620203108745, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=0.024940270557883837>, <tf.Tensor: shape=(), dtype=float64, numpy=-0.043974096945544994>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.678364665819814> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.55844304446902>\n",
            "loss:  tf.Tensor(1559.5617853207723, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=0.021196067805339003>, <tf.Tensor: shape=(), dtype=float64, numpy=-0.03673615161072641>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.676245059007694> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.56211665968483>\n",
            "loss:  tf.Tensor(1559.5616199163119, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=0.017995613378939734>, <tf.Tensor: shape=(), dtype=float64, numpy=-0.030701134050382328>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.674445497642985> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.56518677313562>\n",
            "loss:  tf.Tensor(1559.5615034623038, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=0.015264203482407923>, <tf.Tensor: shape=(), dtype=float64, numpy=-0.02566660119415165>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.672919077272> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.56775343329328>\n",
            "loss:  tf.Tensor(1559.5614214544103, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=0.012936389226061884>, <tf.Tensor: shape=(), dtype=float64, numpy=-0.021464716060803135>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.671625438330118> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.56989990493135>\n",
            "loss:  tf.Tensor(1559.5613636930564, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=0.010955077865765661>, <tf.Tensor: shape=(), dtype=float64, numpy=-0.017956221221035795>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.670529930527216> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.57169552708021>\n",
            "loss:  tf.Tensor(1559.5613230030372, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=0.009270655168925945>, <tf.Tensor: shape=(), dtype=float64, numpy=-0.015025483663088646>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.66960286499651> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.57319807546891>\n",
            "loss:  tf.Tensor(1559.5612943350493, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=0.00784015050130854>, <tf.Tensor: shape=(), dtype=float64, numpy=-0.012576416568726878>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.668818849934695> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.57445571714452>\n",
            "loss:  tf.Tensor(1559.5612741348036, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=0.006626457966721455>, <tf.Tensor: shape=(), dtype=float64, numpy=-0.010529119455340963>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.66815620412815> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.57550862910574>\n",
            "loss:  tf.Tensor(1559.561259899759, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=0.00559762082642562>, <tf.Tensor: shape=(), dtype=float64, numpy=-0.008817107371822508>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.667596442037166> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.57639033985606>\n",
            "loss:  tf.Tensor(1559.5612498675316, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=0.00472618201740288>, <tf.Tensor: shape=(), dtype=float64, numpy=-0.007385023604763452>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.667123823828383> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.57712884222754>\n",
            "loss:  tf.Tensor(1559.5612427967592, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=0.003988600497310035>, <tf.Tensor: shape=(), dtype=float64, numpy=-0.006186749677605907>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.666724963772708> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.57774751720451>\n",
            "loss:  tf.Tensor(1559.5612378129358, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=0.003364731056788639>, <tf.Tensor: shape=(), dtype=float64, numpy=-0.005183842147233997>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.666388490662015> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.57826590142696>\n",
            "loss:  tf.Tensor(1559.5612342999148, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=0.0028373639077444723>, <tf.Tensor: shape=(), dtype=float64, numpy=-0.004344238497924424>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.666104754267014> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.57870032528322>\n",
            "loss:  tf.Tensor(1559.5612318235314, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=0.002391819581103183>, <tf.Tensor: shape=(), dtype=float64, numpy=-0.0036411848549704473>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.66586557230534> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.57906444377414>\n",
            "loss:  tf.Tensor(1559.5612300778255, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=0.0020155942958583473>, <tf.Tensor: shape=(), dtype=float64, numpy=-0.003052346737354328>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.66566401287275> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.57936967845242>\n",
            "loss:  tf.Tensor(1559.5612288471661, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=0.001698050873793877>, <tf.Tensor: shape=(), dtype=float64, numpy=-0.0025590710025553687>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.66549420778284> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.57962558555649>\n",
            "loss:  tf.Tensor(1559.5612279795723, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=0.0014301503814043715>, <tf.Tensor: shape=(), dtype=float64, numpy=-0.0021457728011988753>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.665351192742566> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.5798401628398>\n",
            "loss:  tf.Tensor(1559.56122736792, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=0.0012042199146805044>, <tf.Tensor: shape=(), dtype=float64, numpy=-0.0017994259920663946>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.665230770749304> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58002010544169>\n",
            "loss:  tf.Tensor(1559.5612269366982, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=0.001013752253377742>, <tf.Tensor: shape=(), dtype=float64, numpy=-0.0015091392613424404>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.665129395522456> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58017101937007>\n",
            "loss:  tf.Tensor(1559.5612266326764, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=0.0008532334638009509>, <tf.Tensor: shape=(), dtype=float64, numpy=-0.0012658032995718216>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.665044072174805> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58029759970191>\n",
            "loss:  tf.Tensor(1559.561226418331, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=0.0007179948963697003>, <tf.Tensor: shape=(), dtype=float64, numpy=-0.0010617969423637463>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664972272684096> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58040377939773>\n",
            "loss:  tf.Tensor(1559.5612262672084, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=0.0006040863898056359>, <tf.Tensor: shape=(), dtype=float64, numpy=-0.0008907422781360141>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664911864044214> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58049285362686>\n",
            "loss:  tf.Tensor(1559.5612261606602, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=0.0005081678447778071>, <tf.Tensor: shape=(), dtype=float64, numpy=-0.0007473004518063764>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664861047258977> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58056758367316>\n",
            "loss:  tf.Tensor(1559.5612260855376, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=0.0004274166601105911>, <tf.Tensor: shape=(), dtype=float64, numpy=-0.0006270013142856135>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.66481830559233> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58063028380552>\n",
            "loss:  tf.Tensor(1559.5612260325715, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=0.00035944882899069386>, <tf.Tensor: shape=(), dtype=float64, numpy=-0.0005261012399957465>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664782360708895> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.5806828939303>\n",
            "loss:  tf.Tensor(1559.5612259952272, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=0.00030225176985387847>, <tf.Tensor: shape=(), dtype=float64, numpy=-0.0004414644015918734>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664752135531458> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58072704037112>\n",
            "loss:  tf.Tensor(1559.5612259688971, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=0.0002541272163640307>, <tf.Tensor: shape=(), dtype=float64, numpy=-0.0003704635907219034>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664726722809444> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58076408673074>\n",
            "loss:  tf.Tensor(1559.5612259503323, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=0.00021364271318974337>, <tf.Tensor: shape=(), dtype=float64, numpy=-0.0003108973346880317>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664705358537805> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58079517646468>\n",
            "loss:  tf.Tensor(1559.5612259372433, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=0.00017959046190368921>, <tf.Tensor: shape=(), dtype=float64, numpy=-0.00026092060662818994>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664687399491346> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58082126852572>\n",
            "loss:  tf.Tensor(1559.5612259280142, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=0.0001509524345649771>, <tf.Tensor: shape=(), dtype=float64, numpy=-0.00021898688025334678>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664672304247663> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58084316721407>\n",
            "loss:  tf.Tensor(1559.561225921507, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=0.0001268708246605632>, <tf.Tensor: shape=(), dtype=float64, numpy=-0.00018379965660031417>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664659617165007> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58086154718>\n",
            "loss:  tf.Tensor(1559.5612259169188, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=0.00010662303741637569>, <tf.Tensor: shape=(), dtype=float64, numpy=-0.00015427190289918347>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664648954861107> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58087697437053>\n",
            "loss:  tf.Tensor(1559.561225913684, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=8.960053638140675e-05>, <tf.Tensor: shape=(), dtype=float64, numpy=-0.00012949210296253622>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664639994807334> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58088992358101>\n",
            "loss:  tf.Tensor(1559.561225911403, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=7.529096282948844e-05>, <tf.Tensor: shape=(), dtype=float64, numpy=-0.00010869583421124762>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.66463246571094> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58090079316459>\n",
            "loss:  tf.Tensor(1559.561225909795, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=6.32630299349235e-05>, <tf.Tensor: shape=(), dtype=float64, numpy=-9.12419663884334e-05>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664626139407854> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58090991736137>\n",
            "loss:  tf.Tensor(1559.561225908661, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=5.3153767744951175e-05>, <tf.Tensor: shape=(), dtype=float64, numpy=-7.65927260860666e-05>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664620824031> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58091757663409>\n",
            "loss:  tf.Tensor(1559.5612259078614, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=4.465775805445604e-05>, <tf.Tensor: shape=(), dtype=float64, numpy=-6.42969960715778e-05>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664616358255127> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.5809240063338>\n",
            "loss:  tf.Tensor(1559.5612259072977, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=3.751805275337139e-05>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.397632172432498e-05>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664612606449797> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58092940396605>\n",
            "loss:  tf.Tensor(1559.5612259069003, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=3.151851516330906e-05>, <tf.Tensor: shape=(), dtype=float64, numpy=-4.531318409950469e-05>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664609454598235> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58093393528453>\n",
            "loss:  tf.Tensor(1559.5612259066202, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=2.647736389582711e-05>, <tf.Tensor: shape=(), dtype=float64, numpy=-3.804117066563695e-05>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664606806861805> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58093773940166>\n",
            "loss:  tf.Tensor(1559.5612259064224, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=2.224173198395185e-05>, <tf.Tensor: shape=(), dtype=float64, numpy=-3.193673574941602e-05>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664604582688572> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58094093307528>\n",
            "loss:  tf.Tensor(1559.5612259062832, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.8683083228054898e-05>, <tf.Tensor: shape=(), dtype=float64, numpy=-2.681229242273986e-05>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664602714380223> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58094361430456>\n",
            "loss:  tf.Tensor(1559.561225906185, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.5693351550882806e-05>, <tf.Tensor: shape=(), dtype=float64, numpy=-2.2510420043753143e-05>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664601145045044> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58094586534659>\n",
            "loss:  tf.Tensor(1559.5612259061159, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.318169018743598e-05>, <tf.Tensor: shape=(), dtype=float64, numpy=-1.8899006804740104e-05>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664599826876007> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.5809477552473>\n",
            "loss:  tf.Tensor(1559.5612259060667, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.1071735113110659e-05>, <tf.Tensor: shape=(), dtype=float64, numpy=-1.5867175891859375e-05>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.66459871970248> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58094934196491>\n",
            "loss:  tf.Tensor(1559.5612259060322, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=9.299301644560831e-06>, <tf.Tensor: shape=(), dtype=float64, numpy=-1.3321868430060668e-05>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.6645977897723> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095067415178>\n",
            "loss:  tf.Tensor(1559.561225906008, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=7.810446233269541e-06>, <tf.Tensor: shape=(), dtype=float64, numpy=-1.1184977262157503e-05>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664597008727668> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095179264953>\n",
            "loss:  tf.Tensor(1559.5612259059908, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=6.559835644459611e-06>, <tf.Tensor: shape=(), dtype=float64, numpy=-9.390942364184696e-06>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664596352744095> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095273174378>\n",
            "loss:  tf.Tensor(1559.5612259059787, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=5.509375145540396e-06>, <tf.Tensor: shape=(), dtype=float64, numpy=-7.884733531193788e-06>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664595801806573> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095352021715>\n",
            "loss:  tf.Tensor(1559.5612259059703, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=4.6270546766868925e-06>, <tf.Tensor: shape=(), dtype=float64, numpy=-6.620157748993272e-06>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664595339101098> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095418223293>\n",
            "loss:  tf.Tensor(1559.5612259059644, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=3.885978444195803e-06>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.558439097108625e-06>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664594950503247> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095473807684>\n",
            "loss:  tf.Tensor(1559.56122590596, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=3.263549009258071e-06>, <tf.Tensor: shape=(), dtype=float64, numpy=-4.667026898608206e-06>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.66459462414834> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095520477954>\n",
            "loss:  tf.Tensor(1559.561225905957, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=2.7407812270840992e-06>, <tf.Tensor: shape=(), dtype=float64, numpy=-3.918595690377558e-06>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664594350070214> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095559663911>\n",
            "loss:  tf.Tensor(1559.5612259059549, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=2.30172549131602e-06>, <tf.Tensor: shape=(), dtype=float64, numpy=-3.290206048389699e-06>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.66459411989766> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095592565972>\n",
            "loss:  tf.Tensor(1559.5612259059535, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.9329829165637413e-06>, <tf.Tensor: shape=(), dtype=float64, numpy=-2.7626000974612097e-06>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664593926599366> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095620191973>\n",
            "loss:  tf.Tensor(1559.5612259059526, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.623297848141192e-06>, <tf.Tensor: shape=(), dtype=float64, numpy=-2.319610430956409e-06>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.66459376426958> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095643388079>\n",
            "loss:  tf.Tensor(1559.561225905952, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.363215341554369e-06>, <tf.Tensor: shape=(), dtype=float64, numpy=-1.9476638962734327e-06>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664593627948044> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095662864717>\n",
            "loss:  tf.Tensor(1559.5612259059512, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.1447933211949923e-06>, <tf.Tensor: shape=(), dtype=float64, numpy=-1.6353652276812625e-06>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.66459351346871> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.5809567921837>\n",
            "loss:  tf.Tensor(1559.5612259059508, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=9.613607173664107e-07>, <tf.Tensor: shape=(), dtype=float64, numpy=-1.3731473319511522e-06>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664593417332636> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095692949843>\n",
            "loss:  tf.Tensor(1559.5612259059508, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=8.073141925524219e-07>, <tf.Tensor: shape=(), dtype=float64, numpy=-1.1529780129526657e-06>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664593336601214> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095704479624>\n",
            "loss:  tf.Tensor(1559.5612259059503, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=6.779473751827858e-07>, <tf.Tensor: shape=(), dtype=float64, numpy=-9.681135281214281e-07>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664593268806478> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095714160758>\n",
            "loss:  tf.Tensor(1559.5612259059503, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=5.693073441004337e-07>, <tf.Tensor: shape=(), dtype=float64, numpy=-8.12891972956642e-07>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664593211875744> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095722289679>\n",
            "loss:  tf.Tensor(1559.5612259059503, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=4.780740843202125e-07>, <tf.Tensor: shape=(), dtype=float64, numpy=-6.825595437742749e-07>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664593164068336> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095729115274>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=4.0145921181844457e-07>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.731249702600749e-07>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664593123922415> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095734846525>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=3.3712086761061855e-07>, <tf.Tensor: shape=(), dtype=float64, numpy=-4.812370953954925e-07>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664593090210328> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095739658896>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=2.8309225036382557e-07>, <tf.Tensor: shape=(), dtype=float64, numpy=-4.040822649820086e-07>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.6645930619011> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095743699718>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=2.3772158375123809e-07>, <tf.Tensor: shape=(), dtype=float64, numpy=-3.3929801945831173e-07>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.66459303812894> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095747092699>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.9962167224774063e-07>, <tf.Tensor: shape=(), dtype=float64, numpy=-2.849007595395747e-07>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664593018166773> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095749941707>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.6762751986476587e-07>, <tf.Tensor: shape=(), dtype=float64, numpy=-2.3922502501161347e-07>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664593001404022> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095752333956>\n",
            "loss:  tf.Tensor(1559.5612259059499, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.407607639336561e-07>, <tf.Tensor: shape=(), dtype=float64, numpy=-2.008724137025908e-07>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592987327946> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.5809575434268>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.1819978951166377e-07>, <tf.Tensor: shape=(), dtype=float64, numpy=-1.686687209900839e-07>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.66459297550797> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095756029368>\n",
            "loss:  tf.Tensor(1559.5612259059499, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=9.925460692228327e-08>, <tf.Tensor: shape=(), dtype=float64, numpy=-1.416280666077796e-07>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592965582507> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095757445649>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=8.334577850099834e-08>, <tf.Tensor: shape=(), dtype=float64, numpy=-1.1892266771340587e-07>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.66459295724793> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095758634876>\n",
            "loss:  tf.Tensor(1559.5612259059499, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=6.998671081559493e-08>, <tf.Tensor: shape=(), dtype=float64, numpy=-9.985743587570539e-08>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592950249258> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.5809575963345>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=5.8768780897278106e-08>, <tf.Tensor: shape=(), dtype=float64, numpy=-8.38487622667472e-08>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.66459294437238> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095760471937>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=4.934884456631039e-08>, <tf.Tensor: shape=(), dtype=float64, numpy=-7.04065874490567e-08>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592939437494> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095761176003>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=4.143873488793304e-08>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.9119444562050205e-08>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.66459293529362> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095761767197>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=3.479648358339915e-08>, <tf.Tensor: shape=(), dtype=float64, numpy=-4.964181476996288e-08>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.66459293181397> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095762263615>\n",
            "loss:  tf.Tensor(1559.5612259059499, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=2.9218880592818408e-08>, <tf.Tensor: shape=(), dtype=float64, numpy=-4.168361000811416e-08>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592928892084> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.5809576268045>\n",
            "loss:  tf.Tensor(1559.5612259059499, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=2.453529812651567e-08>, <tf.Tensor: shape=(), dtype=float64, numpy=-3.500122847110987e-08>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592926438555> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095763030462>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=2.0602434036565143e-08>, <tf.Tensor: shape=(), dtype=float64, numpy=-2.93901329939672e-08>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.66459292437831> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095763324364>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.7299965793249328e-08>, <tf.Tensor: shape=(), dtype=float64, numpy=-2.4678558752100344e-08>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592922648314> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.5809576357115>\n",
            "loss:  tf.Tensor(1559.5612259059499, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.4526847835760748e-08>, <tf.Tensor: shape=(), dtype=float64, numpy=-2.072231652938683e-08>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.66459292119563> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095763778373>\n",
            "loss:  tf.Tensor(1559.5612259059499, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.219824602438635e-08>, <tf.Tensor: shape=(), dtype=float64, numpy=-1.740032407049341e-08>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592919975806> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095763952376>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.0242895420731202e-08>, <tf.Tensor: shape=(), dtype=float64, numpy=-1.4610875953557922e-08>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592918951517> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764098485>\n",
            "loss:  tf.Tensor(1559.5612259059499, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=8.60097859600728e-09>, <tf.Tensor: shape=(), dtype=float64, numpy=-1.2268609683729892e-08>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.66459291809142> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764221171>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=7.222254683192375e-09>, <tf.Tensor: shape=(), dtype=float64, numpy=-1.030182850136896e-08>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592917369195> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.5809576432419>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=6.06453925966477e-09>, <tf.Tensor: shape=(), dtype=float64, numpy=-8.650343330529608e-09>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.66459291676274> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764410693>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=5.092387844740642e-09>, <tf.Tensor: shape=(), dtype=float64, numpy=-7.263627588294241e-09>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.6645929162535> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764483329>\n",
            "loss:  tf.Tensor(1559.5612259059499, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=4.276072385067664e-09>, <tf.Tensor: shape=(), dtype=float64, numpy=-6.099210803078847e-09>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592915825892> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.5809576454432>\n",
            "loss:  tf.Tensor(1559.5612259059499, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=3.590610975212627e-09>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.121466029045507e-09>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.66459291546683> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764595535>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=3.0150293373054637e-09>, <tf.Tensor: shape=(), dtype=float64, numpy=-4.300458544825858e-09>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592915165326> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.5809576463854>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=2.5317168916849653e-09>, <tf.Tensor: shape=(), dtype=float64, numpy=-3.611054233410016e-09>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592914912156> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764674651>\n",
            "loss:  tf.Tensor(1559.5612259059499, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=2.1258823035275043e-09>, <tf.Tensor: shape=(), dtype=float64, numpy=-3.0321609667538496e-09>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.66459291469957> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764704973>\n",
            "loss:  tf.Tensor(1559.5612259059499, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.785099457141115e-09>, <tf.Tensor: shape=(), dtype=float64, numpy=-2.5460809016664143e-09>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.66459291452106> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764730433>\n",
            "loss:  tf.Tensor(1559.5612259059499, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.4989415819677276e-09>, <tf.Tensor: shape=(), dtype=float64, numpy=-2.1379367165508256e-09>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592914371166> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764751812>\n",
            "loss:  tf.Tensor(1559.5612259059499, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2586614528409257e-09>, <tf.Tensor: shape=(), dtype=float64, numpy=-1.7952195285886319e-09>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.6645929142453> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764769764>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.0568939612376482e-09>, <tf.Tensor: shape=(), dtype=float64, numpy=-1.5074265169445766e-09>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.66459291413961> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.5809576478484>\n",
            "loss:  tf.Tensor(1559.5612259059499, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=8.874744827913617e-10>, <tf.Tensor: shape=(), dtype=float64, numpy=-1.265763605040604e-09>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592914050864> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764797497>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=7.452086170367522e-10>, <tf.Tensor: shape=(), dtype=float64, numpy=-1.0628525837219627e-09>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913976342> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764808125>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=6.257460660741287e-10>, <tf.Tensor: shape=(), dtype=float64, numpy=-8.924747607608197e-10>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.66459291391377> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.5809576481705>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=5.254360835316163e-10>, <tf.Tensor: shape=(), dtype=float64, numpy=-7.494088682946654e-10>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913861224> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764824543>\n",
            "loss:  tf.Tensor(1559.5612259059499, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=4.412019083410712e-10>, <tf.Tensor: shape=(), dtype=float64, numpy=-6.292895093906736e-10>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913817103> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764830836>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=3.7047509504617437e-10>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.284146453732319e-10>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913780055> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764836119>\n",
            "loss:  tf.Tensor(1559.5612259059499, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=3.1108410292191024e-10>, <tf.Tensor: shape=(), dtype=float64, numpy=-4.437145095792516e-10>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913748947> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764840556>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=2.612176586147541e-10>, <tf.Tensor: shape=(), dtype=float64, numpy=-3.72593844666369e-10>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913722824> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764844282>\n",
            "loss:  tf.Tensor(1559.5612259059499, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=2.1934115634891782e-10>, <tf.Tensor: shape=(), dtype=float64, numpy=-3.128614034508814e-10>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.66459291370089> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764847411>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.8418350178350806e-10>, <tf.Tensor: shape=(), dtype=float64, numpy=-2.626960871054962e-10>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913682473> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764850039>\n",
            "loss:  tf.Tensor(1559.5612259059499, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.5466095071303698e-10>, <tf.Tensor: shape=(), dtype=float64, numpy=-2.205723381720759e-10>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913667008> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764852244>\n",
            "loss:  tf.Tensor(1559.5612259059499, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2987011466236709e-10>, <tf.Tensor: shape=(), dtype=float64, numpy=-1.85215176529141e-10>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.66459291365402> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764854096>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.090445511664484e-10>, <tf.Tensor: shape=(), dtype=float64, numpy=-1.5553602850104653e-10>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913643116> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.5809576485565>\n",
            "loss:  tf.Tensor(1559.5612259059499, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=9.156597702286717e-11>, <tf.Tensor: shape=(), dtype=float64, numpy=-1.3061307591044624e-10>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.66459291363396> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764856957>\n",
            "loss:  tf.Tensor(1559.5612259059499, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=7.689099357222062e-11>, <tf.Tensor: shape=(), dtype=float64, numpy=-1.0967915464732414e-10>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913626272> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764858054>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=6.456585266434445e-11>, <tf.Tensor: shape=(), dtype=float64, numpy=-9.209033535739763e-11>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913619817> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764858975>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=5.421946225325769e-11>, <tf.Tensor: shape=(), dtype=float64, numpy=-7.732647855362984e-11>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913614396> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764859748>\n",
            "loss:  tf.Tensor(1559.5612259059499, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=4.553013521757521e-11>, <tf.Tensor: shape=(), dtype=float64, numpy=-6.49342801750663e-11>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.66459291360984> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764860397>\n",
            "loss:  tf.Tensor(1559.5612259059503, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=3.822536731590276e-11>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.452449602927345e-11>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.66459291360602> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764860943>\n",
            "loss:  tf.Tensor(1559.5612259059499, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=3.210193222358271e-11>, <tf.Tensor: shape=(), dtype=float64, numpy=-4.577471734990013e-11>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913602807> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.580957648614>\n",
            "loss:  tf.Tensor(1559.5612259059499, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=2.695005330011213e-11>, <tf.Tensor: shape=(), dtype=float64, numpy=-3.844158324994851e-11>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.66459291360011> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764861785>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=2.263211840158874e-11>, <tf.Tensor: shape=(), dtype=float64, numpy=-3.226607869777354e-11>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913597847> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764862108>\n",
            "loss:  tf.Tensor(1559.5612259059499, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.9000523376888623e-11>, <tf.Tensor: shape=(), dtype=float64, numpy=-2.7094659849069558e-11>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913595946> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.5809576486238>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.5954626508829506e-11>, <tf.Tensor: shape=(), dtype=float64, numpy=-2.2743140704051257e-11>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.66459291359435> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764862607>\n",
            "loss:  tf.Tensor(1559.5612259059499, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.339911515074732e-11>, <tf.Tensor: shape=(), dtype=float64, numpy=-1.9098722603416718e-11>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.66459291359301> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764862797>\n",
            "loss:  tf.Tensor(1559.5612259059499, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.1251277687307493e-11>, <tf.Tensor: shape=(), dtype=float64, numpy=-1.6048162798654175e-11>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913591886> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764862958>\n",
            "loss:  tf.Tensor(1559.5612259059499, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=9.444223181276357e-12>, <tf.Tensor: shape=(), dtype=float64, numpy=-1.347322253764105e-11>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.66459291359094> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863093>\n",
            "loss:  tf.Tensor(1559.5612259059499, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=7.929878975687643e-12>, <tf.Tensor: shape=(), dtype=float64, numpy=-1.1306955371992444e-11>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.66459291359015> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863207>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=6.659284235155383e-12>, <tf.Tensor: shape=(), dtype=float64, numpy=-9.482969964835775e-12>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913589484> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863302>\n",
            "loss:  tf.Tensor(1559.5612259059499, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=5.598743690882202e-12>, <tf.Tensor: shape=(), dtype=float64, numpy=-7.95663535058111e-12>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913588923> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863381>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=4.696465438769337e-12>, <tf.Tensor: shape=(), dtype=float64, numpy=-6.681322162194192e-12>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913588454> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863448>\n",
            "loss:  tf.Tensor(1559.5612259059499, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=3.9455660960641126e-12>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.610956144153079e-12>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.66459291358806> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863504>\n",
            "loss:  tf.Tensor(1559.5612259059499, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=3.3090752360465103e-12>, <tf.Tensor: shape=(), dtype=float64, numpy=-4.7234438582677285e-12>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.66459291358773> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.5809576486355>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=2.7789992529392293e-12>, <tf.Tensor: shape=(), dtype=float64, numpy=-3.972933093621123e-12>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.66459291358745> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.5809576486359>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=2.3331336862497665e-12>, <tf.Tensor: shape=(), dtype=float64, numpy=-3.337663478930608e-12>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913587217> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863623>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.957323192414151e-12>, <tf.Tensor: shape=(), dtype=float64, numpy=-2.8130830997952216e-12>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913587022> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863651>\n",
            "loss:  tf.Tensor(1559.5612259059499, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.649014258475745e-12>, <tf.Tensor: shape=(), dtype=float64, numpy=-2.3566704143718198e-12>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.66459291358686> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863675>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.3853918012785016e-12>, <tf.Tensor: shape=(), dtype=float64, numpy=-1.96787031114809e-12>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.66459291358672> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863695>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.1656786647051831e-12>, <tf.Tensor: shape=(), dtype=float64, numpy=-1.6480150577535824e-12>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586603> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863712>\n",
            "loss:  tf.Tensor(1559.5612259059499, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=9.790501742656943e-13>, <tf.Tensor: shape=(), dtype=float64, numpy=-1.3742340598810188e-12>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586503> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863727>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=8.19011525265978e-13>, <tf.Tensor: shape=(), dtype=float64, numpy=-1.1465273175303992e-12>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.66459291358642> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863738>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=6.868949853355844e-13>, <tf.Tensor: shape=(), dtype=float64, numpy=-9.644507414918735e-13>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586354> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863748>\n",
            "loss:  tf.Tensor(1559.5612259059499, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=5.790923296444817e-13>, <tf.Tensor: shape=(), dtype=float64, numpy=-8.041345367360009e-13>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586297> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863756>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=4.909961326404755e-13>, <tf.Tensor: shape=(), dtype=float64, numpy=-6.674660824046441e-13>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586247> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863764>\n",
            "loss:  tf.Tensor(1559.5612259059499, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=4.1006087414530157e-13>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.541123115904156e-13>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586205> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863769>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=3.4083846855992306e-13>, <tf.Tensor: shape=(), dtype=float64, numpy=-4.630740235711528e-13>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.66459291358617> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863774>\n",
            "loss:  tf.Tensor(1559.5612259059499, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=2.7977620220553945e-13>, <tf.Tensor: shape=(), dtype=float64, numpy=-3.943512183468556e-13>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.66459291358614> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863778>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=2.3686608230377715e-13>, <tf.Tensor: shape=(), dtype=float64, numpy=-3.282929483816588e-13>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586116> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.5809576486378>\n",
            "loss:  tf.Tensor(1559.5612259059499, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.957323192414151e-13>, <tf.Tensor: shape=(), dtype=float64, numpy=-2.829958489769524e-13>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586095> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863783>\n",
            "loss:  tf.Tensor(1559.5612259059499, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.5881740367262864e-13>, <tf.Tensor: shape=(), dtype=float64, numpy=-2.398081733190338e-13>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.66459291358608> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863786>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.3705703238997557e-13>, <tf.Tensor: shape=(), dtype=float64, numpy=-1.9129142714291447e-13>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586066> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863788>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.1368683772161603e-13>, <tf.Tensor: shape=(), dtype=float64, numpy=-1.7008616737257398e-13>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586056> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863789>\n",
            "loss:  tf.Tensor(1559.5612259059499, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=9.581224702515101e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-1.4721557306529576e-13>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586045> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.5809576486379>\n",
            "loss:  tf.Tensor(1559.5612259059499, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=8.038014698286133e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-1.2434497875801753e-13>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586038> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863792>\n",
            "loss:  tf.Tensor(1559.5612259059499, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=7.077671781985373e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-9.992007221626409e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.66459291358603> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863793>\n",
            "loss:  tf.Tensor(1559.5612259059499, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=5.967448757360216e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-7.593925488436071e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586024> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=5.112577028398846e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.1736392947532295e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.66459291358602> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=4.29101199017623e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.262457136723242e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586016> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=3.4083846855992306e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.573319583618286e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586013> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=2.6700863742235015e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.706546346573305e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.66459291358601> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.8596235662471372e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.706546346573305e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n",
            "x:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=29.664592913586006> , y:  <tf.Variable 'Variable:0' shape=() dtype=float64, numpy=74.58095764863795>\n",
            "loss:  tf.Tensor(1559.56122590595, shape=(), dtype=float64)\n",
            "gradients:  [<tf.Tensor: shape=(), dtype=float64, numpy=1.2434497875801753e-14>, <tf.Tensor: shape=(), dtype=float64, numpy=-5.88418203051333e-14>]\n",
            "--------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-40a2e5be0479>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"--------------------------------------------------------\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m     \u001b[0;31m# print(\"type(v): \", v)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;31m# optimizer.apply_gradients(zip(grads, v))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_experimental/optimizer.py\u001b[0m in \u001b[0;36mapply_gradients\u001b[0;34m(self, grads_and_vars, name, skip_gradients_aggregation, **kwargs)\u001b[0m\n\u001b[1;32m   1138\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mskip_gradients_aggregation\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mexperimental_aggregate_gradients\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m             \u001b[0mgrads_and_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maggregate_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1140\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply_weight_decay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_experimental/optimizer.py\u001b[0m in \u001b[0;36mapply_gradients\u001b[0;34m(self, grads_and_vars, name)\u001b[0m\n\u001b[1;32m    632\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_weight_decay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0mgrads_and_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m         \u001b[0miteration\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_internal_apply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m         \u001b[0;31m# Apply variable constraints after applying gradients.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_experimental/optimizer.py\u001b[0m in \u001b[0;36m_internal_apply_gradients\u001b[0;34m(self, grads_and_vars)\u001b[0m\n\u001b[1;32m   1164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1165\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_internal_apply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1166\u001b[0;31m         return tf.__internal__.distribute.interim.maybe_merge_call(\n\u001b[0m\u001b[1;32m   1167\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_distributed_apply_gradients_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_distribution_strategy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/merge_call_interim.py\u001b[0m in \u001b[0;36mmaybe_merge_call\u001b[0;34m(fn, strategy, *args, **kwargs)\u001b[0m\n\u001b[1;32m     49\u001b[0m   \"\"\"\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mstrategy_supports_no_merge_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     return distribution_strategy_context.get_replica_context().merge_call(\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_experimental/optimizer.py\u001b[0m in \u001b[0;36m_distributed_apply_gradients_fn\u001b[0;34m(self, distribution, grads_and_vars, **kwargs)\u001b[0m\n\u001b[1;32m   1214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m             distribution.extended.update(\n\u001b[0m\u001b[1;32m   1217\u001b[0m                 \u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_grad_to_update_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[1;32m   2635\u001b[0m           fn, autograph_ctx.control_status_ctx(), convert_by_default=False)\n\u001b[1;32m   2636\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2637\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2638\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2639\u001b[0m       return self._replica_ctx_update(\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_update\u001b[0;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[1;32m   3708\u001b[0m     \u001b[0;31m# The implementations of _update() and _update_non_slot() are identical\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3709\u001b[0m     \u001b[0;31m# except _update() passes `var` as the first argument to `fn()`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3710\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_non_slot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3711\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3712\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_update_non_slot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolocate_with\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshould_group\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_update_non_slot\u001b[0;34m(self, colocate_with, fn, args, kwargs, should_group)\u001b[0m\n\u001b[1;32m   3714\u001b[0m     \u001b[0;31m# once that value is used for something.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3715\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mUpdateContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolocate_with\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3716\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3717\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mshould_group\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3718\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    593\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mControlStatusCtx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUNSPECIFIED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 595\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    596\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mismethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_experimental/optimizer.py\u001b[0m in \u001b[0;36mapply_grad_to_update_var\u001b[0;34m(var, grad)\u001b[0m\n\u001b[1;32m   1209\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mapply_grad_to_update_var\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1210\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit_compile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1211\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_step_xla\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_var_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1212\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1213\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    918\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 919\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    920\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mALLOW_DYNAMIC_VARIABLE_CREATION\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    921\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    132\u001b[0m       (concrete_function,\n\u001b[1;32m    133\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m--> 134\u001b[0;31m     return concrete_function._call_flat(\n\u001b[0m\u001b[1;32m    135\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1743\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1745\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1746\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    376\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    379\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# with tf.GradientTape() as t1:\n",
        "#     a = tf.Variable(1.)\n",
        "#     b = 2*a\n",
        "#     gr = t1.gradient(b, a)\n",
        "#     print(gr)"
      ],
      "metadata": {
        "id": "QhDHgftyaOxP"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "state_low = env.state_space.low\n",
        "state_high = env.state_space.high\n",
        "action_low = env.action_space.low \n",
        "action_high = env.action_space.high\n",
        "\n",
        "\n",
        "class ANN(tf.keras.Model):\n",
        "  def __init__(self, no_action):\n",
        "    super(ANN, self).__init__()    \n",
        "    self.f1 = tf.keras.layers.Dense(512, activation='relu', kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.01), bias_initializer=tf.keras.initializers.Ones())\n",
        "    self.f2 = tf.keras.layers.Dense(512, activation='relu', kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.01), bias_initializer=tf.keras.initializers.Ones())\n",
        "    self.f3 = tf.keras.layers.Dense(512, activation='relu', kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.01), bias_initializer=tf.keras.initializers.Ones())\n",
        "    self.f4 = tf.keras.layers.Dense(512, activation='relu', kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.01), bias_initializer=tf.keras.initializers.Ones())\n",
        "    self.f5 = tf.keras.layers.Dense(512, activation='relu', kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.01), bias_initializer=tf.keras.initializers.Ones())\n",
        "    self.f6 = tf.keras.layers.Dense(512, activation='relu', kernel_initializer=tf.keras.initializers.RandomNormal(stddev=0.01), bias_initializer=tf.keras.initializers.Ones())\n",
        "    self.mu =  tf.keras.layers.Dense(no_action, activation='tanh')\n",
        "\n",
        "  def call(self, state):\n",
        "    x = self.f1(state)\n",
        "    x = self.f2(x)\n",
        "    x = self.f3(x)\n",
        "    x = self.f4(x)\n",
        "    x = self.f5(x)\n",
        "    x = self.f6(x)\n",
        "    x = self.mu(x)  \n",
        "    return x\n",
        "  \n",
        "\n",
        "\n",
        "no_action= len(env.action_space.high)\n",
        "network = ANN(no_action)\n",
        "# odd = True\n",
        "#     for param in network.parameters():\n",
        "#         # print(param.size())\n",
        "#         if(odd):\n",
        "#             network.init.xavier_normal_(param, gain=1.0)\n",
        "#             odd = False\n",
        "#         else:\n",
        "#             odd = True\n",
        "network_optimizer = tf.keras.optimizers.Adam(0.000001)  # 0.001\n",
        "\n",
        "total_learning_episodes = 100000\n",
        "current_episode = 0\n",
        "while current_episode < total_learning_episodes:\n",
        "    print(\"iteration \", current_episode)\n",
        "    done = False\n",
        "    env.reset()\n",
        "    current_episode_total_reward = 0\n",
        "    current_episode_num_steps = 0\n",
        "    current_episode_final_reward = 0\n",
        "    while not done:\n",
        "      with tf.GradientTape() as tape:\n",
        "        tf_state = tf.convert_to_tensor([env.current_state], dtype=tf.float32)\n",
        "        print(\"state: \", tf_state)\n",
        "        tf_action = network(tf_state)\n",
        "        # tf_action = (((tf.convert_to_tensor(env.action_space_coversion_ub - env.action_space_coversion_lb, dtype=tf.float32)) * (tf_action + 1)) / 2) + tf.convert_to_tensor(env.action_space_coversion_lb, dtype=tf.float32)\n",
        "        #TESTING \n",
        "        # #Declaring reward as sum of tf_action (just to check the erroreneous part)\n",
        "        # reward = tf.math.reduce_sum(tf_action)\n",
        "        # #TESTING CODE ENDS\n",
        "        # print(\"action: \", tf_action)\n",
        "        # mse = tf.keras.losses.MeanSquaredError()\n",
        "        # diff_true = tf.convert_to_tensor(np.array([x - env.current_state[0], y - env.current_state[1]]))\n",
        "        # print(\"expected_action: \", diff_true)\n",
        "        # print(\"action taken: \", tf_action)\n",
        "        # reward = mse(diff_true, tf_action)\n",
        "        # print(\"loss: \", reward)\n",
        "        next_state, reward, done, _ = env.step(tf_action)\n",
        "        # loss = reward\n",
        "        current_episode_total_reward += reward.numpy()\n",
        "        current_episode_num_steps += 1\n",
        "        current_episode_final_reward = reward.numpy()\n",
        "        # Gradient Descent\n",
        "        grads = tape.gradient(reward, network.trainable_variables)\n",
        "        print(\"action: \", tf_action)\n",
        "        print(\"gradient: \", tf.math.reduce_sum(grads[2]))\n",
        "        grads = [(grad / (tf.math.reduce_max(grad) + 0.0001)) for grad in grads]\n",
        "        # grads = [tf.clip_by_value(grad, -1., 1.) for grad in grads]\n",
        "        print(\"clipped gradient: \", tf.math.reduce_sum(grads[2]))\n",
        "        network_optimizer.apply_gradients(zip(grads, network.trainable_variables))\n",
        "        done = True\n",
        "\n",
        "    current_episode += 1\n",
        "    print(\"Average reward in episode \", current_episode, \": \", current_episode_total_reward / current_episode_num_steps)\n",
        "    print(\"Final reward in episode \", current_episode, \": \", current_episode_final_reward)\n",
        "    print(\"------------------------------------------------------------------------------\")\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "UQF0B2r5vmN1",
        "outputId": "1ee4c125-6c32-4603-ca0b-34b49d354354"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "iteration  21181\n",
            "state:  tf.Tensor([[25.146364 94.15609 ]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.13829042 -0.79705286]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(33661.125, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(2252.2732, shape=(), dtype=float32)\n",
            "Average reward in episode  21182 :  1199.0894775390625\n",
            "Final reward in episode  21182 :  1199.0895\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21182\n",
            "state:  tf.Tensor([[89.07155  78.515335]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.91775644 -0.46900523]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-208806.4, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-13639.8, shape=(), dtype=float32)\n",
            "Average reward in episode  21183 :  1894.096923828125\n",
            "Final reward in episode  21183 :  1894.0969\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21183\n",
            "state:  tf.Tensor([[52.592796 82.26251 ]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.63767344 -0.64484185]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(23509.205, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(1229.3152, shape=(), dtype=float32)\n",
            "Average reward in episode  21184 :  1223.9390869140625\n",
            "Final reward in episode  21184 :  1223.9391\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21184\n",
            "state:  tf.Tensor([[21.77363  15.329964]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.9075006   0.48445234]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-41415.695, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-2091.5488, shape=(), dtype=float32)\n",
            "Average reward in episode  21185 :  2624.310791015625\n",
            "Final reward in episode  21185 :  2624.3108\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21185\n",
            "state:  tf.Tensor([[36.761166 75.51311 ]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.5432262 -0.6034299]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(132834.02, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(8286.532, shape=(), dtype=float32)\n",
            "Average reward in episode  21186 :  1183.5535888671875\n",
            "Final reward in episode  21186 :  1183.5536\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21186\n",
            "state:  tf.Tensor([[71.65376 64.13608]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.91176987 -0.2730855 ]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-32523.879, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-3594.1978, shape=(), dtype=float32)\n",
            "Average reward in episode  21187 :  1355.836181640625\n",
            "Final reward in episode  21187 :  1355.8362\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21187\n",
            "state:  tf.Tensor([[28.976269 83.20558 ]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.35816348 -0.7063253 ]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(26115.008, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(3803.1584, shape=(), dtype=float32)\n",
            "Average reward in episode  21188 :  1166.1273193359375\n",
            "Final reward in episode  21188 :  1166.1273\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21188\n",
            "state:  tf.Tensor([[25.845528 97.56718 ]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.14880508 -0.81602395]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-5336.8164, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-325.3783, shape=(), dtype=float32)\n",
            "Average reward in episode  21189 :  1226.7691650390625\n",
            "Final reward in episode  21189 :  1226.7692\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21189\n",
            "state:  tf.Tensor([[11.264073   1.1761767]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.9294509  0.5817844]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-191883.12, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-19895.95, shape=(), dtype=float32)\n",
            "Average reward in episode  21190 :  3473.3115234375\n",
            "Final reward in episode  21190 :  3473.3115\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21190\n",
            "state:  tf.Tensor([[92.39413 95.15748]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.87368536 -0.6887503 ]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-256916.12, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-11630.658, shape=(), dtype=float32)\n",
            "Average reward in episode  21191 :  2105.567138671875\n",
            "Final reward in episode  21191 :  2105.5671\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21191\n",
            "state:  tf.Tensor([[80.33424  60.905266]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.94873273 -0.1530487 ]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-219858.31, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-15612.246, shape=(), dtype=float32)\n",
            "Average reward in episode  21192 :  1560.9295654296875\n",
            "Final reward in episode  21192 :  1560.9296\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21192\n",
            "state:  tf.Tensor([[82.777565 45.483685]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.9754338   0.20561504]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-377739.5, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-16087.165, shape=(), dtype=float32)\n",
            "Average reward in episode  21193 :  1611.910888671875\n",
            "Final reward in episode  21193 :  1611.9109\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21193\n",
            "state:  tf.Tensor([[22.922935 23.128895]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.88928455  0.3741418 ]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(69666.83, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(2800.3608, shape=(), dtype=float32)\n",
            "Average reward in episode  21194 :  2473.7216796875\n",
            "Final reward in episode  21194 :  2473.7217\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21194\n",
            "state:  tf.Tensor([[ 2.4723303 70.34517  ]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.27847704 -0.6535687 ]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-560721.0, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-11525.417, shape=(), dtype=float32)\n",
            "Average reward in episode  21195 :  2010.1142578125\n",
            "Final reward in episode  21195 :  2010.1143\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21195\n",
            "state:  tf.Tensor([[42.894756 23.093172]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.95077646  0.4654996 ]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(258631.06, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(16461.592, shape=(), dtype=float32)\n",
            "Average reward in episode  21196 :  1526.2872314453125\n",
            "Final reward in episode  21196 :  1526.2872\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21196\n",
            "state:  tf.Tensor([[58.510643 55.36834 ]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.9045417  -0.15402402]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(53544.68, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(16512.613, shape=(), dtype=float32)\n",
            "Average reward in episode  21197 :  1162.3812255859375\n",
            "Final reward in episode  21197 :  1162.3812\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21197\n",
            "state:  tf.Tensor([[81.72859    6.6629477]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.993256  0.730542]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(31586.803, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(2907.787, shape=(), dtype=float32)\n",
            "Average reward in episode  21198 :  1580.024658203125\n",
            "Final reward in episode  21198 :  1580.0247\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21198\n",
            "state:  tf.Tensor([[53.321083 58.342884]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.8690662 -0.2359253]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(174998.14, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(14243.439, shape=(), dtype=float32)\n",
            "Average reward in episode  21199 :  1175.009033203125\n",
            "Final reward in episode  21199 :  1175.009\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21199\n",
            "state:  tf.Tensor([[77.60864 92.45726]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.811431  -0.6915044]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-294213.3, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-10296.992, shape=(), dtype=float32)\n",
            "Average reward in episode  21200 :  1734.031494140625\n",
            "Final reward in episode  21200 :  1734.0315\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21200\n",
            "state:  tf.Tensor([[66.20097  11.710914]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.9877106  0.6844634]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(78036.35, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(7695.7314, shape=(), dtype=float32)\n",
            "Average reward in episode  21201 :  1197.7525634765625\n",
            "Final reward in episode  21201 :  1197.7526\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21201\n",
            "state:  tf.Tensor([[28.841015 70.172554]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.5645732  -0.53515023]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(181193.83, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(4262.1157, shape=(), dtype=float32)\n",
            "Average reward in episode  21202 :  1360.216796875\n",
            "Final reward in episode  21202 :  1360.2168\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21202\n",
            "state:  tf.Tensor([[95.50619    1.8427294]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.99534255  0.7809427 ]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(9181.627, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(732.5206, shape=(), dtype=float32)\n",
            "Average reward in episode  21203 :  2025.8265380859375\n",
            "Final reward in episode  21203 :  2025.8265\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21203\n",
            "state:  tf.Tensor([[14.313443 70.52959 ]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.40553057 -0.5829607 ]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-310534.94, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-5934.2627, shape=(), dtype=float32)\n",
            "Average reward in episode  21204 :  1665.28271484375\n",
            "Final reward in episode  21204 :  1665.2827\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21204\n",
            "state:  tf.Tensor([[21.658533 11.16966 ]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.9322742   0.57218564]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-60962.93, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-4061.8027, shape=(), dtype=float32)\n",
            "Average reward in episode  21205 :  2698.6484375\n",
            "Final reward in episode  21205 :  2698.6484\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21205\n",
            "state:  tf.Tensor([[87.81776 30.11427]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.98909485  0.56326026]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-252058.0, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-14618.4375, shape=(), dtype=float32)\n",
            "Average reward in episode  21206 :  1769.4979248046875\n",
            "Final reward in episode  21206 :  1769.4979\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21206\n",
            "state:  tf.Tensor([[ 2.369017 54.125607]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.4850753  -0.37416273]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-510325.94, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-10478.07, shape=(), dtype=float32)\n",
            "Average reward in episode  21207 :  2610.087158203125\n",
            "Final reward in episode  21207 :  2610.0872\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21207\n",
            "state:  tf.Tensor([[74.21428 71.08653]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.90585345 -0.3360383 ]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-248497.53, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-15150.42, shape=(), dtype=float32)\n",
            "Average reward in episode  21208 :  1451.995361328125\n",
            "Final reward in episode  21208 :  1451.9954\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21208\n",
            "state:  tf.Tensor([[53.875256 24.960585]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.9665454   0.53088945]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(6190.792, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(4284.634, shape=(), dtype=float32)\n",
            "Average reward in episode  21209 :  1197.176025390625\n",
            "Final reward in episode  21209 :  1197.176\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21209\n",
            "state:  tf.Tensor([[78.80195 74.8091 ]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.9080977 -0.3823865]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-421758.28, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-15041.987, shape=(), dtype=float32)\n",
            "Average reward in episode  21210 :  1595.8531494140625\n",
            "Final reward in episode  21210 :  1595.8531\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21210\n",
            "state:  tf.Tensor([[15.402151 71.29729 ]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.3926085 -0.5647594]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-263433.38, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-4813.173, shape=(), dtype=float32)\n",
            "Average reward in episode  21211 :  1559.7738037109375\n",
            "Final reward in episode  21211 :  1559.7738\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21211\n",
            "state:  tf.Tensor([[39.366287 14.446152]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.9594775  0.634857 ]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(34754.277, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(3071.7568, shape=(), dtype=float32)\n",
            "Average reward in episode  21212 :  1719.239501953125\n",
            "Final reward in episode  21212 :  1719.2395\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21212\n",
            "state:  tf.Tensor([[61.377224 27.751421]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.9716067  0.5152302]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-77660.56, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-18217.646, shape=(), dtype=float32)\n",
            "Average reward in episode  21213 :  1161.755615234375\n",
            "Final reward in episode  21213 :  1161.7556\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21213\n",
            "state:  tf.Tensor([[66.824165 69.44137 ]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.87618893 -0.33016658]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-215423.55, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-14439.207, shape=(), dtype=float32)\n",
            "Average reward in episode  21214 :  1283.229736328125\n",
            "Final reward in episode  21214 :  1283.2297\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21214\n",
            "state:  tf.Tensor([[34.264866 20.816004]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.93356746  0.5329494 ]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(101833.38, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(7805.8477, shape=(), dtype=float32)\n",
            "Average reward in episode  21215 :  1907.3638916015625\n",
            "Final reward in episode  21215 :  1907.3639\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21215\n",
            "state:  tf.Tensor([[69.144485 51.505596]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.9442851   0.06926361]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-277669.6, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-16914.77, shape=(), dtype=float32)\n",
            "Average reward in episode  21216 :  1269.3037109375\n",
            "Final reward in episode  21216 :  1269.3037\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21216\n",
            "state:  tf.Tensor([[27.945292 40.345837]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.8140157   0.11350205]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(282555.88, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(8287.525, shape=(), dtype=float32)\n",
            "Average reward in episode  21217 :  1939.6387939453125\n",
            "Final reward in episode  21217 :  1939.6388\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21217\n",
            "state:  tf.Tensor([[86.528   72.84811]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.93376863 -0.3161436 ]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-427993.25, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-14752.732, shape=(), dtype=float32)\n",
            "Average reward in episode  21218 :  1809.8819580078125\n",
            "Final reward in episode  21218 :  1809.882\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21218\n",
            "state:  tf.Tensor([[39.150734 57.511307]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.76694375 -0.2277467 ]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(257704.56, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(8704.317, shape=(), dtype=float32)\n",
            "Average reward in episode  21219 :  1323.476806640625\n",
            "Final reward in episode  21219 :  1323.4768\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21219\n",
            "state:  tf.Tensor([[98.327736 77.745605]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.9490571  -0.36465997]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-454140.4, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-14010.785, shape=(), dtype=float32)\n",
            "Average reward in episode  21220 :  2145.50830078125\n",
            "Final reward in episode  21220 :  2145.5083\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21220\n",
            "state:  tf.Tensor([[34.668457 58.071663]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.7185957  -0.27004886]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(352526.75, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(7905.5967, shape=(), dtype=float32)\n",
            "Average reward in episode  21221 :  1405.1051025390625\n",
            "Final reward in episode  21221 :  1405.1051\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21221\n",
            "state:  tf.Tensor([[22.503597  9.115331]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.93199843  0.59643626]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-84408.66, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-5624.748, shape=(), dtype=float32)\n",
            "Average reward in episode  21222 :  2662.81005859375\n",
            "Final reward in episode  21222 :  2662.81\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21222\n",
            "state:  tf.Tensor([[25.611725 53.156734]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.6744708  -0.21480429]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(372389.56, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(6515.882, shape=(), dtype=float32)\n",
            "Average reward in episode  21223 :  1744.8836669921875\n",
            "Final reward in episode  21223 :  1744.8837\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21223\n",
            "state:  tf.Tensor([[96.01697  20.233015]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.99252903  0.69660485]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-40255.633, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-7784.831, shape=(), dtype=float32)\n",
            "Average reward in episode  21224 :  1985.0091552734375\n",
            "Final reward in episode  21224 :  1985.0092\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21224\n",
            "state:  tf.Tensor([[60.00925 66.25981]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.8422234  -0.33306178]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(46295.812, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(7769.8887, shape=(), dtype=float32)\n",
            "Average reward in episode  21225 :  1186.49365234375\n",
            "Final reward in episode  21225 :  1186.4937\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21225\n",
            "state:  tf.Tensor([[31.798882 89.24306 ]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.28655106 -0.73714733]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-9602.549, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-891.74646, shape=(), dtype=float32)\n",
            "Average reward in episode  21226 :  1181.4263916015625\n",
            "Final reward in episode  21226 :  1181.4264\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21226\n",
            "state:  tf.Tensor([[98.906784 76.79037 ]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.94892704 -0.3628396 ]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-412459.06, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-14065.261, shape=(), dtype=float32)\n",
            "Average reward in episode  21227 :  2150.808349609375\n",
            "Final reward in episode  21227 :  2150.8083\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21227\n",
            "state:  tf.Tensor([[84.273575 47.621674]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.97162336  0.19461264]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-429751.53, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-16134.488, shape=(), dtype=float32)\n",
            "Average reward in episode  21228 :  1681.691162109375\n",
            "Final reward in episode  21228 :  1681.6912\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21228\n",
            "state:  tf.Tensor([[32.74385  29.966377]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.8873327  0.3172207]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(320922.4, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(13218.883, shape=(), dtype=float32)\n",
            "Average reward in episode  21229 :  1878.930419921875\n",
            "Final reward in episode  21229 :  1878.9304\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21229\n",
            "state:  tf.Tensor([[54.219322 21.31072 ]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.96685725  0.54774946]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(112385.69, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(15895.348, shape=(), dtype=float32)\n",
            "Average reward in episode  21230 :  1202.115234375\n",
            "Final reward in episode  21230 :  1202.1152\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21230\n",
            "state:  tf.Tensor([[55.16735  54.099125]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.8802124  -0.12209117]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(105584.3, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(14647.505, shape=(), dtype=float32)\n",
            "Average reward in episode  21231 :  1164.7242431640625\n",
            "Final reward in episode  21231 :  1164.7242\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21231\n",
            "state:  tf.Tensor([[17.653532 35.865646]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.7567549   0.09474631]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-258549.06, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-7841.9883, shape=(), dtype=float32)\n",
            "Average reward in episode  21232 :  2416.96728515625\n",
            "Final reward in episode  21232 :  2416.9673\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21232\n",
            "state:  tf.Tensor([[73.923996 79.05264 ]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.8465927  -0.52479744]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-124638.95, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-7296.579, shape=(), dtype=float32)\n",
            "Average reward in episode  21233 :  1519.6468505859375\n",
            "Final reward in episode  21233 :  1519.6469\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21233\n",
            "state:  tf.Tensor([[54.740784 27.685999]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.9574453   0.44478372]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(105078.63, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(16263.894, shape=(), dtype=float32)\n",
            "Average reward in episode  21234 :  1184.548583984375\n",
            "Final reward in episode  21234 :  1184.5486\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21234\n",
            "state:  tf.Tensor([[54.797237 17.012665]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.9723173   0.60897624]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(177168.69, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(14909.207, shape=(), dtype=float32)\n",
            "Average reward in episode  21235 :  1206.7093505859375\n",
            "Final reward in episode  21235 :  1206.7094\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21235\n",
            "state:  tf.Tensor([[77.84165 88.00413]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.8142468  -0.63207424]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-245106.03, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-9332.221, shape=(), dtype=float32)\n",
            "Average reward in episode  21236 :  1719.7344970703125\n",
            "Final reward in episode  21236 :  1719.7345\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21236\n",
            "state:  tf.Tensor([[ 6.2715173 38.77894  ]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.64241433 -0.0723239 ]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-509104.0, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-14076.506, shape=(), dtype=float32)\n",
            "Average reward in episode  21237 :  2835.445068359375\n",
            "Final reward in episode  21237 :  2835.445\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21237\n",
            "state:  tf.Tensor([[17.065386 24.326097]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.8359148   0.33415243]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-194099.06, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-8031.656, shape=(), dtype=float32)\n",
            "Average reward in episode  21238 :  2670.50390625\n",
            "Final reward in episode  21238 :  2670.504\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21238\n",
            "state:  tf.Tensor([[97.99091 59.14343]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.9733029   0.02266144]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-503439.66, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-14814.414, shape=(), dtype=float32)\n",
            "Average reward in episode  21239 :  2111.0859375\n",
            "Final reward in episode  21239 :  2111.086\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21239\n",
            "state:  tf.Tensor([[85.51457 61.18107]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.95263946 -0.09915794]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-410651.56, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-15439.43, shape=(), dtype=float32)\n",
            "Average reward in episode  21240 :  1741.2735595703125\n",
            "Final reward in episode  21240 :  1741.2736\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21240\n",
            "state:  tf.Tensor([[44.366756  8.802755]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.969495   0.6737674]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(28768.395, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(1578.3193, shape=(), dtype=float32)\n",
            "Average reward in episode  21241 :  1558.3607177734375\n",
            "Final reward in episode  21241 :  1558.3607\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21241\n",
            "state:  tf.Tensor([[23.949095 34.564255]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.8067074   0.19113474]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(318465.03, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(8882.6045, shape=(), dtype=float32)\n",
            "Average reward in episode  21242 :  2157.600341796875\n",
            "Final reward in episode  21242 :  2157.6003\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21242\n",
            "state:  tf.Tensor([[62.760376 40.408802]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.94794244  0.24395241]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-46379.85, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-18456.803, shape=(), dtype=float32)\n",
            "Average reward in episode  21243 :  1169.7254638671875\n",
            "Final reward in episode  21243 :  1169.7255\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21243\n",
            "state:  tf.Tensor([[7.3890576 2.6841369]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.9046067  0.5605672]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-243979.36, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-31786.754, shape=(), dtype=float32)\n",
            "Average reward in episode  21244 :  3616.767578125\n",
            "Final reward in episode  21244 :  3616.7676\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21244\n",
            "state:  tf.Tensor([[75.41015 53.39009]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.9469341   0.02292167]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-313403.2, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-16533.73, shape=(), dtype=float32)\n",
            "Average reward in episode  21245 :  1426.90087890625\n",
            "Final reward in episode  21245 :  1426.9009\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21245\n",
            "state:  tf.Tensor([[49.093716   1.6327484]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.9805219  0.730295 ]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-4214.489, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-203.37915, shape=(), dtype=float32)\n",
            "Average reward in episode  21246 :  1497.323974609375\n",
            "Final reward in episode  21246 :  1497.324\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21246\n",
            "state:  tf.Tensor([[11.936707 94.00668 ]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.00870019 -0.7942655 ]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-140566.66, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-18271.227, shape=(), dtype=float32)\n",
            "Average reward in episode  21247 :  1174.349609375\n",
            "Final reward in episode  21247 :  1174.3496\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21247\n",
            "state:  tf.Tensor([[59.98597  97.302124]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.5283838 -0.7574223]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-198261.1, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-4138.7256, shape=(), dtype=float32)\n",
            "Average reward in episode  21248 :  1643.932861328125\n",
            "Final reward in episode  21248 :  1643.9329\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21248\n",
            "state:  tf.Tensor([[43.96639 27.11292]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.9330098   0.42812288]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(188841.27, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(13890.99, shape=(), dtype=float32)\n",
            "Average reward in episode  21249 :  1427.134765625\n",
            "Final reward in episode  21249 :  1427.1348\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21249\n",
            "state:  tf.Tensor([[94.56578 42.25864]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.98349696  0.36799267]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-446222.16, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-15028.203, shape=(), dtype=float32)\n",
            "Average reward in episode  21250 :  2003.5550537109375\n",
            "Final reward in episode  21250 :  2003.555\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21250\n",
            "state:  tf.Tensor([[70.15824  23.386717]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.97985107  0.5735195 ]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-32681.8, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-17077.754, shape=(), dtype=float32)\n",
            "Average reward in episode  21251 :  1239.599853515625\n",
            "Final reward in episode  21251 :  1239.5999\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21251\n",
            "state:  tf.Tensor([[44.08849 89.49025]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.42096967 -0.7243191 ]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(42978.926, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(1360.9653, shape=(), dtype=float32)\n",
            "Average reward in episode  21252 :  1277.3153076171875\n",
            "Final reward in episode  21252 :  1277.3153\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21252\n",
            "state:  tf.Tensor([[26.170265 95.19054 ]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.12810957 -0.7973664 ]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(19100.912, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(993.4734, shape=(), dtype=float32)\n",
            "Average reward in episode  21253 :  1225.4703369140625\n",
            "Final reward in episode  21253 :  1225.4703\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21253\n",
            "state:  tf.Tensor([[88.13461  64.807915]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.9497913  -0.18873006]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-337067.88, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-15232.07, shape=(), dtype=float32)\n",
            "Average reward in episode  21254 :  1820.4915771484375\n",
            "Final reward in episode  21254 :  1820.4916\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21254\n",
            "state:  tf.Tensor([[34.756657 83.99323 ]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.3869989 -0.6995552]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(60311.34, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(9894.478, shape=(), dtype=float32)\n",
            "Average reward in episode  21255 :  1166.559326171875\n",
            "Final reward in episode  21255 :  1166.5593\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21255\n",
            "state:  tf.Tensor([[33.10024 72.15008]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.5277442  -0.56653935]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(185123.44, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(6776.374, shape=(), dtype=float32)\n",
            "Average reward in episode  21256 :  1225.490478515625\n",
            "Final reward in episode  21256 :  1225.4905\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21256\n",
            "state:  tf.Tensor([[82.2804   45.979137]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.97125846  0.18701464]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-354781.7, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-16535.451, shape=(), dtype=float32)\n",
            "Average reward in episode  21257 :  1598.89599609375\n",
            "Final reward in episode  21257 :  1598.896\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21257\n",
            "state:  tf.Tensor([[80.5316   57.979843]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.95052177 -0.10064306]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-163632.16, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-16154.259, shape=(), dtype=float32)\n",
            "Average reward in episode  21258 :  1562.5987548828125\n",
            "Final reward in episode  21258 :  1562.5988\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21258\n",
            "state:  tf.Tensor([[86.77001 71.74558]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.933771   -0.36927024]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-220851.72, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-15150.647, shape=(), dtype=float32)\n",
            "Average reward in episode  21259 :  1789.5076904296875\n",
            "Final reward in episode  21259 :  1789.5077\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21259\n",
            "state:  tf.Tensor([[29.283144 51.32064 ]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.72817177 -0.22439118]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(635049.1, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(10883.817, shape=(), dtype=float32)\n",
            "Average reward in episode  21260 :  1734.1739501953125\n",
            "Final reward in episode  21260 :  1734.174\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21260\n",
            "state:  tf.Tensor([[ 5.6641054 14.281631 ]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.8511779  0.3415797]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-335508.94, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-25721.88, shape=(), dtype=float32)\n",
            "Average reward in episode  21261 :  3546.34765625\n",
            "Final reward in episode  21261 :  3546.3477\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21261\n",
            "state:  tf.Tensor([[58.775166 42.904034]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.9372917   0.09532316]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(103152.55, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(15943.26, shape=(), dtype=float32)\n",
            "Average reward in episode  21262 :  1163.669189453125\n",
            "Final reward in episode  21262 :  1163.6692\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21262\n",
            "state:  tf.Tensor([[77.67567  39.131897]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.9751383   0.27305624]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-105616.25, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-17234.465, shape=(), dtype=float32)\n",
            "Average reward in episode  21263 :  1445.20458984375\n",
            "Final reward in episode  21263 :  1445.2046\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21263\n",
            "state:  tf.Tensor([[33.042263 67.096115]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.6136802  -0.52304065]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(431077.34, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(8986.52, shape=(), dtype=float32)\n",
            "Average reward in episode  21264 :  1351.943603515625\n",
            "Final reward in episode  21264 :  1351.9436\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21264\n",
            "state:  tf.Tensor([[89.486916 26.764448]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.9897583  0.5469787]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-123713.47, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-13587.287, shape=(), dtype=float32)\n",
            "Average reward in episode  21265 :  1788.2376708984375\n",
            "Final reward in episode  21265 :  1788.2377\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21265\n",
            "state:  tf.Tensor([[34.124405 23.807993]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.92188704  0.38321313]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(465067.9, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(17831.066, shape=(), dtype=float32)\n",
            "Average reward in episode  21266 :  1929.47314453125\n",
            "Final reward in episode  21266 :  1929.4731\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21266\n",
            "state:  tf.Tensor([[54.798664 24.386866]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.9658234  0.4484401]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(194938.72, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(16776.184, shape=(), dtype=float32)\n",
            "Average reward in episode  21267 :  1206.86376953125\n",
            "Final reward in episode  21267 :  1206.8638\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21267\n",
            "state:  tf.Tensor([[60.873062   2.1634355]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.9882318  0.7072664]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(59832.383, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(2179.1177, shape=(), dtype=float32)\n",
            "Average reward in episode  21268 :  1319.581787109375\n",
            "Final reward in episode  21268 :  1319.5818\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21268\n",
            "state:  tf.Tensor([[ 1.8757992 22.464119 ]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.78360987  0.14411265]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-374439.2, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-15967.937, shape=(), dtype=float32)\n",
            "Average reward in episode  21269 :  3606.293701171875\n",
            "Final reward in episode  21269 :  3606.2937\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21269\n",
            "state:  tf.Tensor([[13.668551 74.26053 ]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.3126299  -0.68099004]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-228473.4, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-4452.503, shape=(), dtype=float32)\n",
            "Average reward in episode  21270 :  1513.612060546875\n",
            "Final reward in episode  21270 :  1513.612\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21270\n",
            "state:  tf.Tensor([[64.62351  58.619022]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.9085662  -0.22647808]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(137219.77, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(13568.053, shape=(), dtype=float32)\n",
            "Average reward in episode  21271 :  1208.7633056640625\n",
            "Final reward in episode  21271 :  1208.7633\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21271\n",
            "state:  tf.Tensor([[62.923203   6.6980147]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.98718405  0.6904016 ]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(92851.03, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(4564.342, shape=(), dtype=float32)\n",
            "Average reward in episode  21272 :  1239.714111328125\n",
            "Final reward in episode  21272 :  1239.7141\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21272\n",
            "state:  tf.Tensor([[19.727606 93.80923 ]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.13539262 -0.81083345]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-65562.42, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-13792.225, shape=(), dtype=float32)\n",
            "Average reward in episode  21273 :  1165.597900390625\n",
            "Final reward in episode  21273 :  1165.5979\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21273\n",
            "state:  tf.Tensor([[83.641495 35.32043 ]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.9830669  0.3960279]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-276376.1, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-15965.233, shape=(), dtype=float32)\n",
            "Average reward in episode  21274 :  1621.0474853515625\n",
            "Final reward in episode  21274 :  1621.0475\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21274\n",
            "state:  tf.Tensor([[38.841335 11.452889]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.9608328   0.60334307]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(32020.887, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(1680.3776, shape=(), dtype=float32)\n",
            "Average reward in episode  21275 :  1811.1783447265625\n",
            "Final reward in episode  21275 :  1811.1783\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21275\n",
            "state:  tf.Tensor([[89.00213    3.1718686]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.99408823  0.74795234]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(18916.143, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(1527.9797, shape=(), dtype=float32)\n",
            "Average reward in episode  21276 :  1836.1688232421875\n",
            "Final reward in episode  21276 :  1836.1688\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21276\n",
            "state:  tf.Tensor([[78.73364  58.479523]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.94844747 -0.12273498]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-74309.97, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-11568.569, shape=(), dtype=float32)\n",
            "Average reward in episode  21277 :  1512.1937255859375\n",
            "Final reward in episode  21277 :  1512.1937\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21277\n",
            "state:  tf.Tensor([[46.928608 46.12598 ]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.88664764 -0.00436167]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(378484.53, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(15244.663, shape=(), dtype=float32)\n",
            "Average reward in episode  21278 :  1279.5386962890625\n",
            "Final reward in episode  21278 :  1279.5387\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21278\n",
            "state:  tf.Tensor([[75.8677   38.387867]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.97444415  0.31338513]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-182513.12, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-17335.766, shape=(), dtype=float32)\n",
            "Average reward in episode  21279 :  1395.584716796875\n",
            "Final reward in episode  21279 :  1395.5847\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21279\n",
            "state:  tf.Tensor([[41.250732 79.948845]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.55887204 -0.6448735 ]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(39082.67, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(15515.984, shape=(), dtype=float32)\n",
            "Average reward in episode  21280 :  1161.6361083984375\n",
            "Final reward in episode  21280 :  1161.6361\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21280\n",
            "state:  tf.Tensor([[22.092482 38.837425]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.78129584  0.05484707]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(373778.6, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(8579.947, shape=(), dtype=float32)\n",
            "Average reward in episode  21281 :  2221.719482421875\n",
            "Final reward in episode  21281 :  2221.7195\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21281\n",
            "state:  tf.Tensor([[74.24216  10.313931]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.9902018   0.70481586]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(55310.723, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(5886.7266, shape=(), dtype=float32)\n",
            "Average reward in episode  21282 :  1347.36279296875\n",
            "Final reward in episode  21282 :  1347.3628\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21282\n",
            "state:  tf.Tensor([[ 9.287723 81.89509 ]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.18105282 -0.7320658 ]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-383738.16, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-12673.909, shape=(), dtype=float32)\n",
            "Average reward in episode  21283 :  1360.0302734375\n",
            "Final reward in episode  21283 :  1360.0303\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21283\n",
            "state:  tf.Tensor([[74.73573 47.28206]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.9622476   0.14221159]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-259056.48, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-17161.0, shape=(), dtype=float32)\n",
            "Average reward in episode  21284 :  1382.892822265625\n",
            "Final reward in episode  21284 :  1382.8928\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21284\n",
            "state:  tf.Tensor([[95.88465  54.145836]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.9784219   0.11588314]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-510147.38, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-15335.051, shape=(), dtype=float32)\n",
            "Average reward in episode  21285 :  2043.3045654296875\n",
            "Final reward in episode  21285 :  2043.3046\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21285\n",
            "state:  tf.Tensor([[15.730104 30.187347]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.8051791   0.20514293]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-287902.44, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-11973.698, shape=(), dtype=float32)\n",
            "Average reward in episode  21286 :  2666.66162109375\n",
            "Final reward in episode  21286 :  2666.6616\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21286\n",
            "state:  tf.Tensor([[92.71113 66.24534]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.96050406 -0.18138814]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-399316.06, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-15020.869, shape=(), dtype=float32)\n",
            "Average reward in episode  21287 :  1951.3441162109375\n",
            "Final reward in episode  21287 :  1951.3441\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21287\n",
            "state:  tf.Tensor([[ 4.3775206 51.347076 ]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.5047272  -0.34452614]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-461754.16, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-8517.197, shape=(), dtype=float32)\n",
            "Average reward in episode  21288 :  2581.039794921875\n",
            "Final reward in episode  21288 :  2581.0398\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21288\n",
            "state:  tf.Tensor([[94.16182  49.240967]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.98066354  0.2124261 ]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-476850.25, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-15273.512, shape=(), dtype=float32)\n",
            "Average reward in episode  21289 :  1988.411376953125\n",
            "Final reward in episode  21289 :  1988.4114\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21289\n",
            "state:  tf.Tensor([[48.28718  23.545126]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.9563041  0.4963164]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(195364.84, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(16647.982, shape=(), dtype=float32)\n",
            "Average reward in episode  21290 :  1316.57568359375\n",
            "Final reward in episode  21290 :  1316.5757\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21290\n",
            "state:  tf.Tensor([[77.04903  32.464146]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.9803096   0.44812834]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-217611.2, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-16669.352, shape=(), dtype=float32)\n",
            "Average reward in episode  21291 :  1426.3746337890625\n",
            "Final reward in episode  21291 :  1426.3746\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21291\n",
            "state:  tf.Tensor([[ 8.041269 92.35304 ]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.03465583 -0.795735  ]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-282382.1, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-21624.842, shape=(), dtype=float32)\n",
            "Average reward in episode  21292 :  1205.6107177734375\n",
            "Final reward in episode  21292 :  1205.6107\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21292\n",
            "state:  tf.Tensor([[52.46998    0.3162692]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.98480743  0.73127   ]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-4899.6357, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-209.99939, shape=(), dtype=float32)\n",
            "Average reward in episode  21293 :  1442.412353515625\n",
            "Final reward in episode  21293 :  1442.4124\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21293\n",
            "state:  tf.Tensor([[75.11962  71.557945]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.89529043 -0.39505967]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-123039.94, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-10163.824, shape=(), dtype=float32)\n",
            "Average reward in episode  21294 :  1483.522216796875\n",
            "Final reward in episode  21294 :  1483.5222\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21294\n",
            "state:  tf.Tensor([[66.282234 55.654926]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.92058855 -0.10886679]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-5386.8965, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-1197.2366, shape=(), dtype=float32)\n",
            "Average reward in episode  21295 :  1220.67431640625\n",
            "Final reward in episode  21295 :  1220.6743\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21295\n",
            "state:  tf.Tensor([[38.26565 71.08131]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.6116728  -0.53165257]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(205204.53, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(9352.822, shape=(), dtype=float32)\n",
            "Average reward in episode  21296 :  1206.7884521484375\n",
            "Final reward in episode  21296 :  1206.7885\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21296\n",
            "state:  tf.Tensor([[28.284924 65.76294 ]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.5601063 -0.4828951]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(401157.53, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(7338.657, shape=(), dtype=float32)\n",
            "Average reward in episode  21297 :  1399.9853515625\n",
            "Final reward in episode  21297 :  1399.9854\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21297\n",
            "state:  tf.Tensor([[18.719854 70.299255]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.39053544 -0.5876241 ]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(9036.242, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(163.7172, shape=(), dtype=float32)\n",
            "Average reward in episode  21298 :  1454.04052734375\n",
            "Final reward in episode  21298 :  1454.0405\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21298\n",
            "state:  tf.Tensor([[26.587343 98.99935 ]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.11084194 -0.82242155]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(40791.305, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(1617.198, shape=(), dtype=float32)\n",
            "Average reward in episode  21299 :  1278.747314453125\n",
            "Final reward in episode  21299 :  1278.7473\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21299\n",
            "state:  tf.Tensor([[96.13332    4.0527854]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.9945131  0.7614284]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(17438.21, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(1418.5857, shape=(), dtype=float32)\n",
            "Average reward in episode  21300 :  2027.6500244140625\n",
            "Final reward in episode  21300 :  2027.65\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21300\n",
            "state:  tf.Tensor([[58.424984 14.791467]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.97873074  0.63457036]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(96481.53, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(11142.467, shape=(), dtype=float32)\n",
            "Average reward in episode  21301 :  1181.682861328125\n",
            "Final reward in episode  21301 :  1181.6829\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21301\n",
            "state:  tf.Tensor([[99.53955 55.20059]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.9791925   0.10078792]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-507369.78, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-15072.602, shape=(), dtype=float32)\n",
            "Average reward in episode  21302 :  2141.585205078125\n",
            "Final reward in episode  21302 :  2141.5852\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21302\n",
            "state:  tf.Tensor([[ 9.587428 32.114643]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.73890734  0.09087493]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-397114.06, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-13489.685, shape=(), dtype=float32)\n",
            "Average reward in episode  21303 :  2891.511962890625\n",
            "Final reward in episode  21303 :  2891.512\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21303\n",
            "state:  tf.Tensor([[24.80009  10.771438]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.9309132   0.57084405]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-76545.65, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-4405.344, shape=(), dtype=float32)\n",
            "Average reward in episode  21304 :  2522.631103515625\n",
            "Final reward in episode  21304 :  2522.631\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21304\n",
            "state:  tf.Tensor([[49.415348  8.922893]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.9756243   0.67758065]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(91307.23, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(4764.7695, shape=(), dtype=float32)\n",
            "Average reward in episode  21305 :  1376.7283935546875\n",
            "Final reward in episode  21305 :  1376.7284\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21305\n",
            "state:  tf.Tensor([[72.001274 35.359203]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.9719109   0.38082758]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-201076.61, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-17863.059, shape=(), dtype=float32)\n",
            "Average reward in episode  21306 :  1298.703369140625\n",
            "Final reward in episode  21306 :  1298.7034\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21306\n",
            "state:  tf.Tensor([[67.189735 56.3534  ]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.9193266 -0.0919788]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-102114.3, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-14009.629, shape=(), dtype=float32)\n",
            "Average reward in episode  21307 :  1240.1956787109375\n",
            "Final reward in episode  21307 :  1240.1957\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21307\n",
            "state:  tf.Tensor([[79.989426 17.485977]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.98908925  0.6708356 ]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(12143.301, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(7571.0117, shape=(), dtype=float32)\n",
            "Average reward in episode  21308 :  1489.3321533203125\n",
            "Final reward in episode  21308 :  1489.3322\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21308\n",
            "state:  tf.Tensor([[38.7755   15.188693]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.9515781   0.59919757]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(69956.74, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(4660.2783, shape=(), dtype=float32)\n",
            "Average reward in episode  21309 :  1739.810302734375\n",
            "Final reward in episode  21309 :  1739.8103\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21309\n",
            "state:  tf.Tensor([[62.777092 40.185238]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.9503394   0.25150272]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-62029.66, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-18736.656, shape=(), dtype=float32)\n",
            "Average reward in episode  21310 :  1169.3690185546875\n",
            "Final reward in episode  21310 :  1169.369\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21310\n",
            "state:  tf.Tensor([[49.945084 75.2748  ]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.6864398 -0.5293739]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(16683.074, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(3466.7913, shape=(), dtype=float32)\n",
            "Average reward in episode  21311 :  1169.1197509765625\n",
            "Final reward in episode  21311 :  1169.1198\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21311\n",
            "state:  tf.Tensor([[14.921498 13.623487]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.8888081   0.49253687]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-176816.31, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-11408.02, shape=(), dtype=float32)\n",
            "Average reward in episode  21312 :  2988.91845703125\n",
            "Final reward in episode  21312 :  2988.9185\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21312\n",
            "state:  tf.Tensor([[79.12189    3.4726088]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.99252456  0.7609197 ]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(23622.66, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(1974.7072, shape=(), dtype=float32)\n",
            "Average reward in episode  21313 :  1523.12109375\n",
            "Final reward in episode  21313 :  1523.1211\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21313\n",
            "state:  tf.Tensor([[87.93138 37.97595]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.9836471   0.43018135]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-408035.7, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-15519.622, shape=(), dtype=float32)\n",
            "Average reward in episode  21314 :  1796.062255859375\n",
            "Final reward in episode  21314 :  1796.0623\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21314\n",
            "state:  tf.Tensor([[23.814169 20.8184  ]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.8930352   0.46136215]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(7225.411, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(339.09808, shape=(), dtype=float32)\n",
            "Average reward in episode  21315 :  2409.29931640625\n",
            "Final reward in episode  21315 :  2409.2993\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21315\n",
            "state:  tf.Tensor([[ 7.2015944 17.609245 ]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.8371968   0.37686694]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-351201.5, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-27820.305, shape=(), dtype=float32)\n",
            "Average reward in episode  21316 :  3321.863525390625\n",
            "Final reward in episode  21316 :  3321.8635\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21316\n",
            "state:  tf.Tensor([[29.30561  10.016183]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.94511795  0.6268238 ]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-38833.86, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-2711.0632, shape=(), dtype=float32)\n",
            "Average reward in episode  21317 :  2278.15087890625\n",
            "Final reward in episode  21317 :  2278.151\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21317\n",
            "state:  tf.Tensor([[55.068172 98.91975 ]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.46901956 -0.7641822 ]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-188052.16, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-3991.9802, shape=(), dtype=float32)\n",
            "Average reward in episode  21318 :  1602.639892578125\n",
            "Final reward in episode  21318 :  1602.6399\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21318\n",
            "state:  tf.Tensor([[85.96422  85.092094]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.8846068  -0.53241986]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-359153.44, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-14752.998, shape=(), dtype=float32)\n",
            "Average reward in episode  21319 :  1883.45361328125\n",
            "Final reward in episode  21319 :  1883.4536\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21319\n",
            "state:  tf.Tensor([[31.590433  9.570074]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.9509297   0.64639264]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-38831.06, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-2859.9856, shape=(), dtype=float32)\n",
            "Average reward in episode  21320 :  2160.59033203125\n",
            "Final reward in episode  21320 :  2160.5903\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21320\n",
            "state:  tf.Tensor([[23.457375 47.823017]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.7080613  -0.07463022]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(214534.48, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(4282.2983, shape=(), dtype=float32)\n",
            "Average reward in episode  21321 :  1919.4337158203125\n",
            "Final reward in episode  21321 :  1919.4337\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21321\n",
            "state:  tf.Tensor([[ 5.3274007 29.804169 ]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.73709327  0.15411377]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-456442.0, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-21427.877, shape=(), dtype=float32)\n",
            "Average reward in episode  21322 :  3122.257568359375\n",
            "Final reward in episode  21322 :  3122.2576\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21322\n",
            "state:  tf.Tensor([[55.59746    5.6502724]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.9836341  0.7413098]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(63747.71, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(4148.477, shape=(), dtype=float32)\n",
            "Average reward in episode  21323 :  1253.4034423828125\n",
            "Final reward in episode  21323 :  1253.4034\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21323\n",
            "state:  tf.Tensor([[13.750443 18.222015]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.8622475   0.45403555]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-230243.95, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-16314.186, shape=(), dtype=float32)\n",
            "Average reward in episode  21324 :  2943.370361328125\n",
            "Final reward in episode  21324 :  2943.3704\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21324\n",
            "state:  tf.Tensor([[44.965294 27.925787]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.93826544  0.4690935 ]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-556.37463, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-90.63943, shape=(), dtype=float32)\n",
            "Average reward in episode  21325 :  1389.935791015625\n",
            "Final reward in episode  21325 :  1389.9358\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21325\n",
            "state:  tf.Tensor([[18.048023 70.67186 ]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.37418613 -0.5275454 ]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-178272.72, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-3842.5613, shape=(), dtype=float32)\n",
            "Average reward in episode  21326 :  1395.85986328125\n",
            "Final reward in episode  21326 :  1395.8599\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21326\n",
            "state:  tf.Tensor([[29.959833 34.33906 ]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.85005784  0.29263335]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(132547.38, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(5709.2993, shape=(), dtype=float32)\n",
            "Average reward in episode  21327 :  1910.4735107421875\n",
            "Final reward in episode  21327 :  1910.4735\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21327\n",
            "state:  tf.Tensor([[87.02063  73.990814]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.92518604 -0.28960738]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-494602.88, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-15057.461, shape=(), dtype=float32)\n",
            "Average reward in episode  21328 :  1863.95751953125\n",
            "Final reward in episode  21328 :  1863.9575\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21328\n",
            "state:  tf.Tensor([[33.165813 87.809944]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.3049524 -0.6815319]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-38179.55, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-2530.0464, shape=(), dtype=float32)\n",
            "Average reward in episode  21329 :  1192.826171875\n",
            "Final reward in episode  21329 :  1192.8262\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21329\n",
            "state:  tf.Tensor([[65.28525  66.438095]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.86444044 -0.23579332]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-277625.1, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-16620.082, shape=(), dtype=float32)\n",
            "Average reward in episode  21330 :  1270.3441162109375\n",
            "Final reward in episode  21330 :  1270.3441\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21330\n",
            "state:  tf.Tensor([[86.82643  35.645653]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.9830326  0.5173967]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-413147.8, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-15726.244, shape=(), dtype=float32)\n",
            "Average reward in episode  21331 :  1789.794921875\n",
            "Final reward in episode  21331 :  1789.7949\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21331\n",
            "state:  tf.Tensor([[84.602455 67.91912 ]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.9331945 -0.1741907]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-605934.6, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-15426.008, shape=(), dtype=float32)\n",
            "Average reward in episode  21332 :  1774.781494140625\n",
            "Final reward in episode  21332 :  1774.7815\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21332\n",
            "state:  tf.Tensor([[47.457657 32.266914]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.9277939   0.40647626]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-61263.25, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-10163.165, shape=(), dtype=float32)\n",
            "Average reward in episode  21333 :  1290.12744140625\n",
            "Final reward in episode  21333 :  1290.1274\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21333\n",
            "state:  tf.Tensor([[60.77615 50.99342]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.91019416  0.06351791]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-240158.53, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-17985.238, shape=(), dtype=float32)\n",
            "Average reward in episode  21334 :  1174.8377685546875\n",
            "Final reward in episode  21334 :  1174.8378\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21334\n",
            "state:  tf.Tensor([[77.97926  88.489296]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.80166507 -0.5954261 ]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-413865.78, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-12783.089, shape=(), dtype=float32)\n",
            "Average reward in episode  21335 :  1768.681640625\n",
            "Final reward in episode  21335 :  1768.6816\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21335\n",
            "state:  tf.Tensor([[88.48656  86.293076]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.87822855 -0.53649724]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-383565.75, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-14701.904, shape=(), dtype=float32)\n",
            "Average reward in episode  21336 :  1973.7554931640625\n",
            "Final reward in episode  21336 :  1973.7555\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21336\n",
            "state:  tf.Tensor([[ 8.3029585 25.443827 ]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.7682116   0.25792122]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-424507.22, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-22373.18, shape=(), dtype=float32)\n",
            "Average reward in episode  21337 :  3025.697509765625\n",
            "Final reward in episode  21337 :  3025.6975\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21337\n",
            "state:  tf.Tensor([[39.37821 70.84543]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.5933863  -0.48540363]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(95021.92, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(7411.3477, shape=(), dtype=float32)\n",
            "Average reward in episode  21338 :  1176.766845703125\n",
            "Final reward in episode  21338 :  1176.7668\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21338\n",
            "state:  tf.Tensor([[17.319962  1.230116]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.93280125  0.6413124 ]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-134398.22, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-9869.842, shape=(), dtype=float32)\n",
            "Average reward in episode  21339 :  3069.9443359375\n",
            "Final reward in episode  21339 :  3069.9443\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21339\n",
            "state:  tf.Tensor([[18.607634 71.70141 ]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.32211915 -0.5828888 ]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(26970.895, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(666.97064, shape=(), dtype=float32)\n",
            "Average reward in episode  21340 :  1327.5130615234375\n",
            "Final reward in episode  21340 :  1327.5131\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21340\n",
            "state:  tf.Tensor([[43.21118 73.34258]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.6011698  -0.52437407]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(77150.33, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(14669.959, shape=(), dtype=float32)\n",
            "Average reward in episode  21341 :  1162.351806640625\n",
            "Final reward in episode  21341 :  1162.3518\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21341\n",
            "state:  tf.Tensor([[29.672318 13.197889]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.9282823  0.5874757]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-23059.8, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-1366.3049, shape=(), dtype=float32)\n",
            "Average reward in episode  21342 :  2194.677490234375\n",
            "Final reward in episode  21342 :  2194.6775\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21342\n",
            "state:  tf.Tensor([[65.14219  93.774765]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.611636   -0.71471846]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-243036.38, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-5933.248, shape=(), dtype=float32)\n",
            "Average reward in episode  21343 :  1656.060302734375\n",
            "Final reward in episode  21343 :  1656.0603\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21343\n",
            "state:  tf.Tensor([[21.811453  8.225797]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.92038447  0.59884685]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-109536.16, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-6678.239, shape=(), dtype=float32)\n",
            "Average reward in episode  21344 :  2682.833251953125\n",
            "Final reward in episode  21344 :  2682.8333\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21344\n",
            "state:  tf.Tensor([[34.343716 27.264565]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.8916891   0.39739326]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(241889.58, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(11671.687, shape=(), dtype=float32)\n",
            "Average reward in episode  21345 :  1796.333251953125\n",
            "Final reward in episode  21345 :  1796.3333\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21345\n",
            "state:  tf.Tensor([[19.972914 78.4851  ]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.22438107 -0.6586864 ]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-10414.096, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-660.2739, shape=(), dtype=float32)\n",
            "Average reward in episode  21346 :  1191.975341796875\n",
            "Final reward in episode  21346 :  1191.9753\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21346\n",
            "state:  tf.Tensor([[59.758415 92.73539 ]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.54674995 -0.7109467 ]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-205566.6, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-4427.696, shape=(), dtype=float32)\n",
            "Average reward in episode  21347 :  1577.166259765625\n",
            "Final reward in episode  21347 :  1577.1663\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21347\n",
            "state:  tf.Tensor([[96.27731  61.251575]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.9644088  -0.01787415]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-500029.06, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-15176.971, shape=(), dtype=float32)\n",
            "Average reward in episode  21348 :  2078.807861328125\n",
            "Final reward in episode  21348 :  2078.8079\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21348\n",
            "state:  tf.Tensor([[41.76652  53.652306]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.77067155 -0.14009485]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(365420.56, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(12971.775, shape=(), dtype=float32)\n",
            "Average reward in episode  21349 :  1260.765380859375\n",
            "Final reward in episode  21349 :  1260.7654\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21349\n",
            "state:  tf.Tensor([[ 1.4437265 84.68644  ]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[ 0.04301617 -0.7470979 ]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-294486.03, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-16674.969, shape=(), dtype=float32)\n",
            "Average reward in episode  21350 :  1261.14501953125\n",
            "Final reward in episode  21350 :  1261.145\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21350\n",
            "state:  tf.Tensor([[37.052044 49.20475 ]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.7640916  -0.06108321]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(365745.56, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(9849.505, shape=(), dtype=float32)\n",
            "Average reward in episode  21351 :  1385.96875\n",
            "Final reward in episode  21351 :  1385.9688\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21351\n",
            "state:  tf.Tensor([[41.117817 13.333763]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.9500207  0.63962  ]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(54662.79, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(3794.3843, shape=(), dtype=float32)\n",
            "Average reward in episode  21352 :  1619.871337890625\n",
            "Final reward in episode  21352 :  1619.8713\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21352\n",
            "state:  tf.Tensor([[64.69884  45.874107]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.9281339   0.15720485]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-250525.95, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-18240.59, shape=(), dtype=float32)\n",
            "Average reward in episode  21353 :  1198.487548828125\n",
            "Final reward in episode  21353 :  1198.4875\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21353\n",
            "state:  tf.Tensor([[8.733528 7.716275]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.8653918  0.5297909]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-291785.44, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-26561.506, shape=(), dtype=float32)\n",
            "Average reward in episode  21354 :  3354.805419921875\n",
            "Final reward in episode  21354 :  3354.8054\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21354\n",
            "state:  tf.Tensor([[ 7.0472054 71.79403  ]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.12782691 -0.621894  ]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-171889.38, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-3573.6646, shape=(), dtype=float32)\n",
            "Average reward in episode  21355 :  1417.152587890625\n",
            "Final reward in episode  21355 :  1417.1526\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21355\n",
            "state:  tf.Tensor([[99.05899  48.279736]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.9786152   0.30155075]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-457145.6, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-15173.607, shape=(), dtype=float32)\n",
            "Average reward in episode  21356 :  2164.372802734375\n",
            "Final reward in episode  21356 :  2164.3728\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21356\n",
            "state:  tf.Tensor([[33.584545 37.557945]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.81130755  0.19483101]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(294057.62, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(9113.242, shape=(), dtype=float32)\n",
            "Average reward in episode  21357 :  1633.7236328125\n",
            "Final reward in episode  21357 :  1633.7236\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21357\n",
            "state:  tf.Tensor([[42.21058    6.6638327]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.9604006   0.69805646]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-5548.464, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-303.95398, shape=(), dtype=float32)\n",
            "Average reward in episode  21358 :  1651.8555908203125\n",
            "Final reward in episode  21358 :  1651.8556\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21358\n",
            "state:  tf.Tensor([[81.8493   18.985561]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.9853452   0.67989486]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-31110.043, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-10877.749, shape=(), dtype=float32)\n",
            "Average reward in episode  21359 :  1549.2393798828125\n",
            "Final reward in episode  21359 :  1549.2394\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21359\n",
            "state:  tf.Tensor([[81.75804  54.378036]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.9439684  0.0619616]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-526694.7, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-16446.465, shape=(), dtype=float32)\n",
            "Average reward in episode  21360 :  1649.097412109375\n",
            "Final reward in episode  21360 :  1649.0974\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21360\n",
            "state:  tf.Tensor([[91.86284 14.04295]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.98997015  0.7341909 ]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(636.5751, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(550.87555, shape=(), dtype=float32)\n",
            "Average reward in episode  21361 :  1855.68359375\n",
            "Final reward in episode  21361 :  1855.6836\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21361\n",
            "state:  tf.Tensor([[36.819065 43.541943]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.77904254  0.07253518]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(270474.28, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(8315.062, shape=(), dtype=float32)\n",
            "Average reward in episode  21362 :  1416.5562744140625\n",
            "Final reward in episode  21362 :  1416.5563\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21362\n",
            "state:  tf.Tensor([[46.433636 27.176893]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.9193317  0.4567519]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(96013.69, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(10015.646, shape=(), dtype=float32)\n",
            "Average reward in episode  21363 :  1309.589111328125\n",
            "Final reward in episode  21363 :  1309.5891\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21363\n",
            "state:  tf.Tensor([[57.699253 92.799225]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.44088376 -0.70993674]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-182655.02, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-3620.8704, shape=(), dtype=float32)\n",
            "Average reward in episode  21364 :  1674.0623779296875\n",
            "Final reward in episode  21364 :  1674.0624\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21364\n",
            "state:  tf.Tensor([[24.820728 35.65567 ]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.73640734  0.19324064]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(308250.53, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(7353.2144, shape=(), dtype=float32)\n",
            "Average reward in episode  21365 :  1910.560546875\n",
            "Final reward in episode  21365 :  1910.5605\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21365\n",
            "state:  tf.Tensor([[53.780464 46.146214]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.86938405  0.0964992 ]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(1521.5819, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(1565.7717, shape=(), dtype=float32)\n",
            "Average reward in episode  21366 :  1161.89013671875\n",
            "Final reward in episode  21366 :  1161.8901\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21366\n",
            "state:  tf.Tensor([[59.47274  75.740616]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.6784511 -0.4905311]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-40576.043, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-1526.9584, shape=(), dtype=float32)\n",
            "Average reward in episode  21367 :  1335.79345703125\n",
            "Final reward in episode  21367 :  1335.7935\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21367\n",
            "state:  tf.Tensor([[90.53063 75.59828]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.90105474 -0.3554243 ]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-426668.3, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-15069.725, shape=(), dtype=float32)\n",
            "Average reward in episode  21368 :  1980.3507080078125\n",
            "Final reward in episode  21368 :  1980.3507\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21368\n",
            "state:  tf.Tensor([[51.17784 56.87327]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.77763665 -0.15833084]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(63986.277, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(15425.579, shape=(), dtype=float32)\n",
            "Average reward in episode  21369 :  1161.0338134765625\n",
            "Final reward in episode  21369 :  1161.0338\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21369\n",
            "state:  tf.Tensor([[66.6437  99.16893]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.4625959 -0.7495385]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-198902.31, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-4105.926, shape=(), dtype=float32)\n",
            "Average reward in episode  21370 :  1960.14111328125\n",
            "Final reward in episode  21370 :  1960.1411\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21370\n",
            "state:  tf.Tensor([[15.260358 63.838963]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.25982216 -0.4692955 ]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(54932.086, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(1031.9111, shape=(), dtype=float32)\n",
            "Average reward in episode  21371 :  1375.492431640625\n",
            "Final reward in episode  21371 :  1375.4924\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21371\n",
            "state:  tf.Tensor([[78.12472  26.971216]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.9762735  0.571843 ]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-163536.47, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-16175.714, shape=(), dtype=float32)\n",
            "Average reward in episode  21372 :  1467.397705078125\n",
            "Final reward in episode  21372 :  1467.3977\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21372\n",
            "state:  tf.Tensor([[77.98607  25.423933]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.9774688  0.5919091]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-148293.25, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-15928.2705, shape=(), dtype=float32)\n",
            "Average reward in episode  21373 :  1458.28564453125\n",
            "Final reward in episode  21373 :  1458.2856\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21373\n",
            "state:  tf.Tensor([[24.640862 69.5426  ]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.29705825 -0.5179277 ]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(216575.7, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(9870.037, shape=(), dtype=float32)\n",
            "Average reward in episode  21374 :  1198.831787109375\n",
            "Final reward in episode  21374 :  1198.8318\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21374\n",
            "state:  tf.Tensor([[36.82657  16.505644]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.9188489   0.58843476]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(74457.64, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(4525.425, shape=(), dtype=float32)\n",
            "Average reward in episode  21375 :  1749.0262451171875\n",
            "Final reward in episode  21375 :  1749.0262\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21375\n",
            "state:  tf.Tensor([[57.36398  30.429052]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.93814224  0.4344549 ]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-65307.773, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-19677.041, shape=(), dtype=float32)\n",
            "Average reward in episode  21376 :  1162.275390625\n",
            "Final reward in episode  21376 :  1162.2754\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21376\n",
            "state:  tf.Tensor([[13.216193 83.41242 ]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[ 0.03582818 -0.7216517 ]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(77670.016, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(15321.227, shape=(), dtype=float32)\n",
            "Average reward in episode  21377 :  1164.4466552734375\n",
            "Final reward in episode  21377 :  1164.4467\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21377\n",
            "state:  tf.Tensor([[51.859505 85.51549 ]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.4462343  -0.65213436]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(10888.985, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(241.06714, shape=(), dtype=float32)\n",
            "Average reward in episode  21378 :  1451.2239990234375\n",
            "Final reward in episode  21378 :  1451.224\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21378\n",
            "state:  tf.Tensor([[44.574158   7.1904244]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.9592382   0.69033647]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(10204.16, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(521.78516, shape=(), dtype=float32)\n",
            "Average reward in episode  21379 :  1542.8919677734375\n",
            "Final reward in episode  21379 :  1542.892\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21379\n",
            "state:  tf.Tensor([[71.551544 89.14328 ]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.6638889 -0.6459492]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-271266.5, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-7218.301, shape=(), dtype=float32)\n",
            "Average reward in episode  21380 :  1757.28857421875\n",
            "Final reward in episode  21380 :  1757.2886\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21380\n",
            "state:  tf.Tensor([[ 7.3903475 82.172935 ]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[ 0.06253212 -0.7247905 ]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-44694.773, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-4427.9575, shape=(), dtype=float32)\n",
            "Average reward in episode  21381 :  1177.3846435546875\n",
            "Final reward in episode  21381 :  1177.3846\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21381\n",
            "state:  tf.Tensor([[88.272316 92.65897 ]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.79409736 -0.6438596 ]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-341413.5, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-11143.824, shape=(), dtype=float32)\n",
            "Average reward in episode  21382 :  2096.083251953125\n",
            "Final reward in episode  21382 :  2096.0833\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21382\n",
            "state:  tf.Tensor([[26.257797 40.772556]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.70141715  0.07247277]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(405531.2, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(8233.758, shape=(), dtype=float32)\n",
            "Average reward in episode  21383 :  1755.50341796875\n",
            "Final reward in episode  21383 :  1755.5034\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21383\n",
            "state:  tf.Tensor([[83.63524 70.80392]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.89559555 -0.30645803]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-347476.78, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-15820.5, shape=(), dtype=float32)\n",
            "Average reward in episode  21384 :  1764.532958984375\n",
            "Final reward in episode  21384 :  1764.533\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21384\n",
            "state:  tf.Tensor([[19.252375 21.840193]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.81164926  0.40168113]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-108196.46, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-3636.3894, shape=(), dtype=float32)\n",
            "Average reward in episode  21385 :  2465.28173828125\n",
            "Final reward in episode  21385 :  2465.2817\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21385\n",
            "state:  tf.Tensor([[82.357285 80.463104]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.8410961  -0.49389306]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-300797.06, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-11688.22, shape=(), dtype=float32)\n",
            "Average reward in episode  21386 :  1811.51171875\n",
            "Final reward in episode  21386 :  1811.5117\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21386\n",
            "state:  tf.Tensor([[89.09213 79.41086]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.8836909  -0.45139772]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-342768.4, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-14787.258, shape=(), dtype=float32)\n",
            "Average reward in episode  21387 :  1954.971435546875\n",
            "Final reward in episode  21387 :  1954.9714\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21387\n",
            "state:  tf.Tensor([[68.857735 93.937645]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.5909593 -0.7097504]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-263434.34, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-6018.01, shape=(), dtype=float32)\n",
            "Average reward in episode  21388 :  1802.45263671875\n",
            "Final reward in episode  21388 :  1802.4526\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21388\n",
            "state:  tf.Tensor([[75.46984 92.25813]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.6928563 -0.6814099]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-283622.88, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-7683.896, shape=(), dtype=float32)\n",
            "Average reward in episode  21389 :  1848.768798828125\n",
            "Final reward in episode  21389 :  1848.7688\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21389\n",
            "state:  tf.Tensor([[ 8.413093 26.584051]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.70939046  0.19481322]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-485572.25, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-19842.549, shape=(), dtype=float32)\n",
            "Average reward in episode  21390 :  2883.668212890625\n",
            "Final reward in episode  21390 :  2883.6682\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21390\n",
            "state:  tf.Tensor([[57.90665 82.41151]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.6126499 -0.6171915]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-36818.17, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-1068.9065, shape=(), dtype=float32)\n",
            "Average reward in episode  21391 :  1383.5076904296875\n",
            "Final reward in episode  21391 :  1383.5077\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21391\n",
            "state:  tf.Tensor([[68.85739 22.54927]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.97454226  0.5695555 ]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-12881.323, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-9914.887, shape=(), dtype=float32)\n",
            "Average reward in episode  21392 :  1219.5257568359375\n",
            "Final reward in episode  21392 :  1219.5258\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21392\n",
            "state:  tf.Tensor([[22.134727 95.989746]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[ 0.02117002 -0.80753976]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(177411.27, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(6042.98, shape=(), dtype=float32)\n",
            "Average reward in episode  21393 :  1288.525146484375\n",
            "Final reward in episode  21393 :  1288.5251\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21393\n",
            "state:  tf.Tensor([[13.164458 85.185715]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.03012403 -0.75294423]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-35963.98, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-6639.2554, shape=(), dtype=float32)\n",
            "Average reward in episode  21394 :  1165.6058349609375\n",
            "Final reward in episode  21394 :  1165.6058\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21394\n",
            "state:  tf.Tensor([[57.88079  52.036316]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.87993383 -0.07013912]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(45315.812, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(15100.693, shape=(), dtype=float32)\n",
            "Average reward in episode  21395 :  1163.3289794921875\n",
            "Final reward in episode  21395 :  1163.329\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21395\n",
            "state:  tf.Tensor([[ 1.3829097 82.77335  ]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[ 0.02894584 -0.7528338 ]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-306572.25, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-13579.359, shape=(), dtype=float32)\n",
            "Average reward in episode  21396 :  1295.578369140625\n",
            "Final reward in episode  21396 :  1295.5784\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21396\n",
            "state:  tf.Tensor([[83.64408 91.40016]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.80573267 -0.66566676]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-296361.88, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-10620.535, shape=(), dtype=float32)\n",
            "Average reward in episode  21397 :  1923.9654541015625\n",
            "Final reward in episode  21397 :  1923.9655\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21397\n",
            "state:  tf.Tensor([[15.235954 97.85129 ]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[ 0.06333467 -0.8219226 ]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(20003.012, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(1321.007, shape=(), dtype=float32)\n",
            "Average reward in episode  21398 :  1224.3690185546875\n",
            "Final reward in episode  21398 :  1224.369\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21398\n",
            "state:  tf.Tensor([[82.52381    5.8230553]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.99129343  0.73482066]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(28715.328, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(2744.8188, shape=(), dtype=float32)\n",
            "Average reward in episode  21399 :  1613.0631103515625\n",
            "Final reward in episode  21399 :  1613.0631\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21399\n",
            "state:  tf.Tensor([[24.42539 99.78801]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.01858425 -0.8276949 ]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(108518.44, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(3446.0032, shape=(), dtype=float32)\n",
            "Average reward in episode  21400 :  1333.4349365234375\n",
            "Final reward in episode  21400 :  1333.4349\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21400\n",
            "state:  tf.Tensor([[72.52678    3.0360339]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.9898332  0.7391644]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(49493.336, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(2495.8774, shape=(), dtype=float32)\n",
            "Average reward in episode  21401 :  1376.8604736328125\n",
            "Final reward in episode  21401 :  1376.8605\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21401\n",
            "state:  tf.Tensor([[51.329235 21.89795 ]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.9582503  0.5226169]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(188623.4, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(16480.023, shape=(), dtype=float32)\n",
            "Average reward in episode  21402 :  1247.4947509765625\n",
            "Final reward in episode  21402 :  1247.4948\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21402\n",
            "state:  tf.Tensor([[22.005281 17.39252 ]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.8897404   0.47067544]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-15058.689, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-662.6324, shape=(), dtype=float32)\n",
            "Average reward in episode  21403 :  2540.853515625\n",
            "Final reward in episode  21403 :  2540.8535\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21403\n",
            "state:  tf.Tensor([[18.770243 10.385318]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.9083874   0.54384035]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-110030.66, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-5971.024, shape=(), dtype=float32)\n",
            "Average reward in episode  21404 :  2832.731201171875\n",
            "Final reward in episode  21404 :  2832.7312\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21404\n",
            "state:  tf.Tensor([[65.43481  33.207462]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.96461034  0.39034644]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-98023.984, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-19127.854, shape=(), dtype=float32)\n",
            "Average reward in episode  21405 :  1181.85302734375\n",
            "Final reward in episode  21405 :  1181.853\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21405\n",
            "state:  tf.Tensor([[44.49764 46.67113]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.8596743   0.00841472]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(334952.03, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(14202.123, shape=(), dtype=float32)\n",
            "Average reward in episode  21406 :  1296.2890625\n",
            "Final reward in episode  21406 :  1296.2891\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21406\n",
            "state:  tf.Tensor([[ 4.7213497 72.16397  ]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.2039537 -0.6481371]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-441050.78, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-8513.178, shape=(), dtype=float32)\n",
            "Average reward in episode  21407 :  1680.167236328125\n",
            "Final reward in episode  21407 :  1680.1672\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21407\n",
            "state:  tf.Tensor([[80.33567  11.110745]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.9905978  0.7225387]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(39047.582, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(5056.358, shape=(), dtype=float32)\n",
            "Average reward in episode  21408 :  1510.8857421875\n",
            "Final reward in episode  21408 :  1510.8857\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21408\n",
            "state:  tf.Tensor([[55.3416   14.458643]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.97494495  0.6543153 ]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(119204.3, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(11560.548, shape=(), dtype=float32)\n",
            "Average reward in episode  21409 :  1204.580810546875\n",
            "Final reward in episode  21409 :  1204.5808\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21409\n",
            "state:  tf.Tensor([[81.40341 84.99155]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.8565853  -0.55887634]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-348215.6, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-13507.701, shape=(), dtype=float32)\n",
            "Average reward in episode  21410 :  1770.801025390625\n",
            "Final reward in episode  21410 :  1770.801\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21410\n",
            "state:  tf.Tensor([[38.68764 82.21736]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.4697408  -0.64070034]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(15004.57, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(3945.941, shape=(), dtype=float32)\n",
            "Average reward in episode  21411 :  1165.2728271484375\n",
            "Final reward in episode  21411 :  1165.2728\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21411\n",
            "state:  tf.Tensor([[15.449799 87.28607 ]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.1368365  -0.74073595]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-113622.76, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-13989.41, shape=(), dtype=float32)\n",
            "Average reward in episode  21412 :  1173.9403076171875\n",
            "Final reward in episode  21412 :  1173.9403\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21412\n",
            "state:  tf.Tensor([[93.27474  58.638344]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.96922004  0.04191046]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-569367.5, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-15695.693, shape=(), dtype=float32)\n",
            "Average reward in episode  21413 :  1991.1663818359375\n",
            "Final reward in episode  21413 :  1991.1664\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21413\n",
            "state:  tf.Tensor([[42.192104 10.430927]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.96460783  0.67733586]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(36697.344, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(2436.5327, shape=(), dtype=float32)\n",
            "Average reward in episode  21414 :  1616.598876953125\n",
            "Final reward in episode  21414 :  1616.5989\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21414\n",
            "state:  tf.Tensor([[94.997215 59.449272]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.97044045  0.03881409]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-518418.62, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-15572.554, shape=(), dtype=float32)\n",
            "Average reward in episode  21415 :  2046.6629638671875\n",
            "Final reward in episode  21415 :  2046.663\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21415\n",
            "state:  tf.Tensor([[94.9208    1.866877]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.9944065  0.7962895]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(12823.016, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(1115.8821, shape=(), dtype=float32)\n",
            "Average reward in episode  21416 :  2002.399658203125\n",
            "Final reward in episode  21416 :  2002.3997\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21416\n",
            "state:  tf.Tensor([[79.766846 27.70352 ]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.9843366   0.57990533]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-247300.31, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-16067.67, shape=(), dtype=float32)\n",
            "Average reward in episode  21417 :  1512.6822509765625\n",
            "Final reward in episode  21417 :  1512.6823\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21417\n",
            "state:  tf.Tensor([[99.81622 40.30131]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.98783195  0.47456646]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-389467.25, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-14781.658, shape=(), dtype=float32)\n",
            "Average reward in episode  21418 :  2177.724609375\n",
            "Final reward in episode  21418 :  2177.7246\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21418\n",
            "state:  tf.Tensor([[ 9.365924 11.832077]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.8739433  0.4950761]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-273935.44, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-23172.375, shape=(), dtype=float32)\n",
            "Average reward in episode  21419 :  3300.039306640625\n",
            "Final reward in episode  21419 :  3300.0393\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21419\n",
            "state:  tf.Tensor([[59.835583 71.96576 ]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.8062841 -0.4174214]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-73064.4, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-6895.3037, shape=(), dtype=float32)\n",
            "Average reward in episode  21420 :  1206.86181640625\n",
            "Final reward in episode  21420 :  1206.8618\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21420\n",
            "state:  tf.Tensor([[71.95411  47.219894]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.9548606   0.17356223]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-366103.0, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-17912.035, shape=(), dtype=float32)\n",
            "Average reward in episode  21421 :  1328.9267578125\n",
            "Final reward in episode  21421 :  1328.9268\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21421\n",
            "state:  tf.Tensor([[77.6503  58.12318]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.94475585 -0.04573826]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-432295.97, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-16862.555, shape=(), dtype=float32)\n",
            "Average reward in episode  21422 :  1505.3135986328125\n",
            "Final reward in episode  21422 :  1505.3136\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21422\n",
            "state:  tf.Tensor([[74.061676 93.423996]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.75430113 -0.6861044 ]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-354867.12, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-10641.902, shape=(), dtype=float32)\n",
            "Average reward in episode  21423 :  1728.058349609375\n",
            "Final reward in episode  21423 :  1728.0583\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21423\n",
            "state:  tf.Tensor([[24.896442  9.03296 ]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.9364846   0.61055225]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-83467.1, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-5306.8164, shape=(), dtype=float32)\n",
            "Average reward in episode  21424 :  2529.226318359375\n",
            "Final reward in episode  21424 :  2529.2263\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21424\n",
            "state:  tf.Tensor([[48.747585 71.7028  ]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.7230934  -0.48167837]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(21016.168, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(10607.884, shape=(), dtype=float32)\n",
            "Average reward in episode  21425 :  1162.07275390625\n",
            "Final reward in episode  21425 :  1162.0728\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21425\n",
            "state:  tf.Tensor([[ 4.674164 87.17803 ]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.06547616 -0.76650995]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-450143.44, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-19372.137, shape=(), dtype=float32)\n",
            "Average reward in episode  21426 :  1307.06396484375\n",
            "Final reward in episode  21426 :  1307.064\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21426\n",
            "state:  tf.Tensor([[63.870564 64.09408 ]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.8806483 -0.2769291]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-28264.668, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-4293.9033, shape=(), dtype=float32)\n",
            "Average reward in episode  21427 :  1213.0712890625\n",
            "Final reward in episode  21427 :  1213.0713\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21427\n",
            "state:  tf.Tensor([[50.795734 21.44436 ]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.96291965  0.5462224 ]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(179644.16, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(16531.215, shape=(), dtype=float32)\n",
            "Average reward in episode  21428 :  1258.877685546875\n",
            "Final reward in episode  21428 :  1258.8777\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21428\n",
            "state:  tf.Tensor([[ 8.240281 23.194191]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.80723476  0.26764515]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-343503.4, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-16682.215, shape=(), dtype=float32)\n",
            "Average reward in episode  21429 :  3169.8369140625\n",
            "Final reward in episode  21429 :  3169.837\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21429\n",
            "state:  tf.Tensor([[81.38652    2.7876027]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.9929852  0.7624082]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(27218.977, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(2147.301, shape=(), dtype=float32)\n",
            "Average reward in episode  21430 :  1594.632080078125\n",
            "Final reward in episode  21430 :  1594.6321\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21430\n",
            "state:  tf.Tensor([[84.933205 67.73055 ]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.9412337  -0.24868481]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-368686.66, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-16098.158, shape=(), dtype=float32)\n",
            "Average reward in episode  21431 :  1734.1846923828125\n",
            "Final reward in episode  21431 :  1734.1847\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21431\n",
            "state:  tf.Tensor([[ 8.843926 86.74392 ]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.10576937 -0.7625992 ]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-287230.12, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-12911.483, shape=(), dtype=float32)\n",
            "Average reward in episode  21432 :  1251.3668212890625\n",
            "Final reward in episode  21432 :  1251.3668\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21432\n",
            "state:  tf.Tensor([[18.469738 12.629687]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.9068375  0.528512 ]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-92058.65, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-4995.6587, shape=(), dtype=float32)\n",
            "Average reward in episode  21433 :  2821.467041015625\n",
            "Final reward in episode  21433 :  2821.467\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21433\n",
            "state:  tf.Tensor([[75.99228 77.81247]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.8734891  -0.48318094]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-195342.9, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-11117.012, shape=(), dtype=float32)\n",
            "Average reward in episode  21434 :  1544.8138427734375\n",
            "Final reward in episode  21434 :  1544.8138\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21434\n",
            "state:  tf.Tensor([[15.045704 56.065163]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.54284817 -0.3524533 ]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-49594.49, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-763.21594, shape=(), dtype=float32)\n",
            "Average reward in episode  21435 :  2020.2119140625\n",
            "Final reward in episode  21435 :  2020.2119\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21435\n",
            "state:  tf.Tensor([[22.403904 60.534576]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.564975   -0.39434525]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(237799.5, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(3763.4758, shape=(), dtype=float32)\n",
            "Average reward in episode  21436 :  1665.2764892578125\n",
            "Final reward in episode  21436 :  1665.2765\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21436\n",
            "state:  tf.Tensor([[33.770767 53.013237]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.7503099 -0.1791193]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(533518.94, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(10566.26, shape=(), dtype=float32)\n",
            "Average reward in episode  21437 :  1513.82275390625\n",
            "Final reward in episode  21437 :  1513.8228\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21437\n",
            "state:  tf.Tensor([[75.16595 87.91828]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.8043772  -0.62908196]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-365448.88, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-12046.205, shape=(), dtype=float32)\n",
            "Average reward in episode  21438 :  1652.87255859375\n",
            "Final reward in episode  21438 :  1652.8726\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21438\n",
            "state:  tf.Tensor([[29.986843 11.143815]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.9415358  0.6130778]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-22980.035, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-1478.807, shape=(), dtype=float32)\n",
            "Average reward in episode  21439 :  2224.154296875\n",
            "Final reward in episode  21439 :  2224.1543\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21439\n",
            "state:  tf.Tensor([[17.949083 52.531433]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.60031074 -0.25106665]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(48484.492, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(795.203, shape=(), dtype=float32)\n",
            "Average reward in episode  21440 :  1988.536865234375\n",
            "Final reward in episode  21440 :  1988.5369\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21440\n",
            "state:  tf.Tensor([[27.727217 24.157433]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.889092    0.42883447]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(127288.55, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(5797.057, shape=(), dtype=float32)\n",
            "Average reward in episode  21441 :  2159.67626953125\n",
            "Final reward in episode  21441 :  2159.6763\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21441\n",
            "state:  tf.Tensor([[28.123938 61.95151 ]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.5931064  -0.37930802]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(404459.4, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(6593.667, shape=(), dtype=float32)\n",
            "Average reward in episode  21442 :  1440.6737060546875\n",
            "Final reward in episode  21442 :  1440.6737\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21442\n",
            "state:  tf.Tensor([[49.37571 71.27443]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.71414787 -0.45864037]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(13231.242, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(6428.577, shape=(), dtype=float32)\n",
            "Average reward in episode  21443 :  1162.1085205078125\n",
            "Final reward in episode  21443 :  1162.1085\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21443\n",
            "state:  tf.Tensor([[60.54212 73.13996]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.7934744  -0.44154277]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-60652.047, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-4614.0522, shape=(), dtype=float32)\n",
            "Average reward in episode  21444 :  1230.211181640625\n",
            "Final reward in episode  21444 :  1230.2112\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21444\n",
            "state:  tf.Tensor([[29.178938 42.59398 ]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.78250307  0.06710847]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(345423.06, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(8618.602, shape=(), dtype=float32)\n",
            "Average reward in episode  21445 :  1793.58984375\n",
            "Final reward in episode  21445 :  1793.5898\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21445\n",
            "state:  tf.Tensor([[95.10807  38.506737]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.98595977  0.477866  ]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-359363.06, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-15249.324, shape=(), dtype=float32)\n",
            "Average reward in episode  21446 :  2034.54443359375\n",
            "Final reward in episode  21446 :  2034.5444\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21446\n",
            "state:  tf.Tensor([[17.472887 24.8314  ]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.8274325  0.3685425]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-188424.55, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-7519.7085, shape=(), dtype=float32)\n",
            "Average reward in episode  21447 :  2595.698486328125\n",
            "Final reward in episode  21447 :  2595.6985\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21447\n",
            "state:  tf.Tensor([[76.58698    4.0819893]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.991063   0.7716038]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(32235.547, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(2805.7668, shape=(), dtype=float32)\n",
            "Average reward in episode  21448 :  1439.700927734375\n",
            "Final reward in episode  21448 :  1439.7009\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21448\n",
            "state:  tf.Tensor([[73.91063  74.200005]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.8683795 -0.3855439]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-323449.38, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-15174.456, shape=(), dtype=float32)\n",
            "Average reward in episode  21449 :  1500.6092529296875\n",
            "Final reward in episode  21449 :  1500.6093\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21449\n",
            "state:  tf.Tensor([[55.402462 43.614292]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.9169994   0.18668357]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-111753.36, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-19229.902, shape=(), dtype=float32)\n",
            "Average reward in episode  21450 :  1167.5750732421875\n",
            "Final reward in episode  21450 :  1167.5751\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21450\n",
            "state:  tf.Tensor([[71.95945  18.079634]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.9841641   0.67666215]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-38102.734, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-13283.873, shape=(), dtype=float32)\n",
            "Average reward in episode  21451 :  1273.55419921875\n",
            "Final reward in episode  21451 :  1273.5542\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21451\n",
            "state:  tf.Tensor([[19.131714 22.307665]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.8493367  0.4293086]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-57060.96, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-2196.137, shape=(), dtype=float32)\n",
            "Average reward in episode  21452 :  2556.813720703125\n",
            "Final reward in episode  21452 :  2556.8137\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21452\n",
            "state:  tf.Tensor([[67.40356  14.427195]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.9834838  0.6975505]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(23981.203, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(9774.57, shape=(), dtype=float32)\n",
            "Average reward in episode  21453 :  1194.067138671875\n",
            "Final reward in episode  21453 :  1194.0671\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21453\n",
            "state:  tf.Tensor([[86.04053  49.149323]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.9697503  0.222306 ]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-603563.0, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-16760.566, shape=(), dtype=float32)\n",
            "Average reward in episode  21454 :  1773.18115234375\n",
            "Final reward in episode  21454 :  1773.1812\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21454\n",
            "state:  tf.Tensor([[ 6.0744824 94.12737  ]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[ 0.06168898 -0.78441787]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-224117.73, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-20626.15, shape=(), dtype=float32)\n",
            "Average reward in episode  21455 :  1192.825927734375\n",
            "Final reward in episode  21455 :  1192.8259\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21455\n",
            "state:  tf.Tensor([[91.43342   4.659553]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.99327064  0.7838741 ]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(17649.164, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(1683.7388, shape=(), dtype=float32)\n",
            "Average reward in episode  21456 :  1879.33642578125\n",
            "Final reward in episode  21456 :  1879.3364\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21456\n",
            "state:  tf.Tensor([[69.784164 45.264023]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.9494383  0.2122023]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-369110.0, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-18365.203, shape=(), dtype=float32)\n",
            "Average reward in episode  21457 :  1283.3580322265625\n",
            "Final reward in episode  21457 :  1283.358\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21457\n",
            "state:  tf.Tensor([[24.191277    0.22471829]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.9488624  0.6908413]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-93712.36, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-6476.6465, shape=(), dtype=float32)\n",
            "Average reward in episode  21458 :  2696.927734375\n",
            "Final reward in episode  21458 :  2696.9277\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21458\n",
            "state:  tf.Tensor([[48.516747 26.50264 ]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.94254243  0.48648223]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(66589.81, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(10392.232, shape=(), dtype=float32)\n",
            "Average reward in episode  21459 :  1280.9073486328125\n",
            "Final reward in episode  21459 :  1280.9073\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21459\n",
            "state:  tf.Tensor([[81.02513 68.38358]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.9176345  -0.24603738]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-451375.62, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-16405.252, shape=(), dtype=float32)\n",
            "Average reward in episode  21460 :  1654.3155517578125\n",
            "Final reward in episode  21460 :  1654.3156\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21460\n",
            "state:  tf.Tensor([[ 4.5712748 52.45767  ]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.42003602 -0.3361834 ]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-451736.47, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-7462.911, shape=(), dtype=float32)\n",
            "Average reward in episode  21461 :  2312.818115234375\n",
            "Final reward in episode  21461 :  2312.818\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21461\n",
            "state:  tf.Tensor([[66.95122 33.41884]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.9637776   0.42895806]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-200291.25, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-19119.11, shape=(), dtype=float32)\n",
            "Average reward in episode  21462 :  1210.2447509765625\n",
            "Final reward in episode  21462 :  1210.2448\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21462\n",
            "state:  tf.Tensor([[70.20282 90.024  ]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.71152467 -0.6554298 ]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-364379.75, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-10149.223, shape=(), dtype=float32)\n",
            "Average reward in episode  21463 :  1650.1658935546875\n",
            "Final reward in episode  21463 :  1650.1659\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21463\n",
            "state:  tf.Tensor([[46.500443 41.86121 ]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.88167995  0.15358184]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(186904.53, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(12620.885, shape=(), dtype=float32)\n",
            "Average reward in episode  21464 :  1259.5999755859375\n",
            "Final reward in episode  21464 :  1259.6\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21464\n",
            "state:  tf.Tensor([[72.59782 79.37622]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.8188936  -0.50865924]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-291029.0, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-12234.256, shape=(), dtype=float32)\n",
            "Average reward in episode  21465 :  1526.225830078125\n",
            "Final reward in episode  21465 :  1526.2258\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21465\n",
            "state:  tf.Tensor([[33.235023 76.43071 ]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.42525873 -0.59731346]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(83000.0, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(9927.966, shape=(), dtype=float32)\n",
            "Average reward in episode  21466 :  1166.0450439453125\n",
            "Final reward in episode  21466 :  1166.045\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21466\n",
            "state:  tf.Tensor([[22.790422 44.5121  ]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.6876798  -0.03619125]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(365207.75, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(6613.578, shape=(), dtype=float32)\n",
            "Average reward in episode  21467 :  1919.857666015625\n",
            "Final reward in episode  21467 :  1919.8577\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21467\n",
            "state:  tf.Tensor([[34.9942  87.89427]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.28455237 -0.7209147 ]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(97431.695, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(3725.746, shape=(), dtype=float32)\n",
            "Average reward in episode  21468 :  1222.07568359375\n",
            "Final reward in episode  21468 :  1222.0757\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21468\n",
            "state:  tf.Tensor([[35.551105 88.57419 ]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.28292042 -0.7265025 ]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(88408.46, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(3139.4238, shape=(), dtype=float32)\n",
            "Average reward in episode  21469 :  1235.257568359375\n",
            "Final reward in episode  21469 :  1235.2576\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21469\n",
            "state:  tf.Tensor([[31.971695 72.601456]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.46074772 -0.5518832 ]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(170587.62, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(8155.203, shape=(), dtype=float32)\n",
            "Average reward in episode  21470 :  1192.359619140625\n",
            "Final reward in episode  21470 :  1192.3596\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21470\n",
            "state:  tf.Tensor([[92.83271 92.53854]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.8635429 -0.6345718]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-400769.9, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-15050.2, shape=(), dtype=float32)\n",
            "Average reward in episode  21471 :  2130.84814453125\n",
            "Final reward in episode  21471 :  2130.8481\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21471\n",
            "state:  tf.Tensor([[44.163548 46.186424]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.84705544  0.02906743]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(290245.06, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(13393.112, shape=(), dtype=float32)\n",
            "Average reward in episode  21472 :  1285.46435546875\n",
            "Final reward in episode  21472 :  1285.4644\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21472\n",
            "state:  tf.Tensor([[51.619503 66.603195]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.75516754 -0.37806395]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(29098.63, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(10714.328, shape=(), dtype=float32)\n",
            "Average reward in episode  21473 :  1163.22412109375\n",
            "Final reward in episode  21473 :  1163.2241\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21473\n",
            "state:  tf.Tensor([[67.85213  21.103012]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.9783463   0.60967106]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(11629.818, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(9998.273, shape=(), dtype=float32)\n",
            "Average reward in episode  21474 :  1199.9827880859375\n",
            "Final reward in episode  21474 :  1199.9828\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21474\n",
            "state:  tf.Tensor([[2.8862696 0.2520697]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.89041746  0.56464255]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-298730.25, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-37534.67, shape=(), dtype=float32)\n",
            "Average reward in episode  21475 :  3887.74658203125\n",
            "Final reward in episode  21475 :  3887.7466\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21475\n",
            "state:  tf.Tensor([[63.2464  64.69026]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.8565035  -0.27503785]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-38398.203, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-4405.76, shape=(), dtype=float32)\n",
            "Average reward in episode  21476 :  1222.76513671875\n",
            "Final reward in episode  21476 :  1222.7651\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21476\n",
            "state:  tf.Tensor([[99.37417  30.075499]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.99015915  0.6186962 ]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-244706.89, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-12666.884, shape=(), dtype=float32)\n",
            "Average reward in episode  21477 :  2126.627685546875\n",
            "Final reward in episode  21477 :  2126.6277\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21477\n",
            "state:  tf.Tensor([[54.231457 41.125706]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.9202846   0.20786275]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-34730.297, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-14891.916, shape=(), dtype=float32)\n",
            "Average reward in episode  21478 :  1171.2550048828125\n",
            "Final reward in episode  21478 :  1171.255\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21478\n",
            "state:  tf.Tensor([[53.49955  68.293144]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.76940495 -0.3900535 ]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(22843.566, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(7466.5645, shape=(), dtype=float32)\n",
            "Average reward in episode  21479 :  1166.8714599609375\n",
            "Final reward in episode  21479 :  1166.8715\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21479\n",
            "state:  tf.Tensor([[67.505806 85.061165]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.75024307 -0.6054233 ]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-258316.73, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-9160.838, shape=(), dtype=float32)\n",
            "Average reward in episode  21480 :  1483.421630859375\n",
            "Final reward in episode  21480 :  1483.4216\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21480\n",
            "state:  tf.Tensor([[15.247003 25.443558]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.81193364  0.31740564]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-291044.94, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-12991.467, shape=(), dtype=float32)\n",
            "Average reward in episode  21481 :  2703.951904296875\n",
            "Final reward in episode  21481 :  2703.952\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21481\n",
            "state:  tf.Tensor([[30.06737 79.91591]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.38241085 -0.64402014]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(15032.324, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(2052.3125, shape=(), dtype=float32)\n",
            "Average reward in episode  21482 :  1166.92919921875\n",
            "Final reward in episode  21482 :  1166.9292\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21482\n",
            "state:  tf.Tensor([[ 1.922142 30.38726 ]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.6897824   0.07898545]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-461000.62, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-15885.785, shape=(), dtype=float32)\n",
            "Average reward in episode  21483 :  3238.935302734375\n",
            "Final reward in episode  21483 :  3238.9353\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21483\n",
            "state:  tf.Tensor([[46.45386 84.36592]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.5365195 -0.6517779]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-24152.227, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-1180.6521, shape=(), dtype=float32)\n",
            "Average reward in episode  21484 :  1206.6573486328125\n",
            "Final reward in episode  21484 :  1206.6573\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21484\n",
            "state:  tf.Tensor([[56.629913 32.303165]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.9518565  0.4031915]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-94197.7, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-20118.498, shape=(), dtype=float32)\n",
            "Average reward in episode  21485 :  1167.6431884765625\n",
            "Final reward in episode  21485 :  1167.6432\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21485\n",
            "state:  tf.Tensor([[56.763134 10.000933]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.980123   0.7037746]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(77884.31, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(7460.619, shape=(), dtype=float32)\n",
            "Average reward in episode  21486 :  1206.810791015625\n",
            "Final reward in episode  21486 :  1206.8108\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21486\n",
            "state:  tf.Tensor([[88.44526 47.05769]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.976145    0.26194745]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-514578.8, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-16636.838, shape=(), dtype=float32)\n",
            "Average reward in episode  21487 :  1833.094482421875\n",
            "Final reward in episode  21487 :  1833.0945\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21487\n",
            "state:  tf.Tensor([[45.233746 69.4084  ]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.69761693 -0.4427967 ]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(131116.12, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(12371.077, shape=(), dtype=float32)\n",
            "Average reward in episode  21488 :  1169.946533203125\n",
            "Final reward in episode  21488 :  1169.9465\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21488\n",
            "state:  tf.Tensor([[18.1534  46.45098]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.66264653 -0.10236756]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-4975.9575, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-103.30586, shape=(), dtype=float32)\n",
            "Average reward in episode  21489 :  2120.334228515625\n",
            "Final reward in episode  21489 :  2120.3342\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21489\n",
            "state:  tf.Tensor([[42.68834 82.9526 ]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.51301736 -0.6440813 ]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-8929.609, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-985.7281, shape=(), dtype=float32)\n",
            "Average reward in episode  21490 :  1175.046875\n",
            "Final reward in episode  21490 :  1175.0469\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21490\n",
            "state:  tf.Tensor([[88.29391    4.0184827]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.99343455  0.77538186]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(15633.729, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(1725.1359, shape=(), dtype=float32)\n",
            "Average reward in episode  21491 :  1791.49560546875\n",
            "Final reward in episode  21491 :  1791.4956\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21491\n",
            "state:  tf.Tensor([[10.027595 65.368614]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.35275084 -0.52168673]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-274751.0, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-4146.501, shape=(), dtype=float32)\n",
            "Average reward in episode  21492 :  1785.3697509765625\n",
            "Final reward in episode  21492 :  1785.3698\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21492\n",
            "state:  tf.Tensor([[92.23689 48.17203]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.97861654  0.26557592]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-492588.0, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-16060.053, shape=(), dtype=float32)\n",
            "Average reward in episode  21493 :  1953.4522705078125\n",
            "Final reward in episode  21493 :  1953.4523\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21493\n",
            "state:  tf.Tensor([[56.700375  5.713882]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.98317575  0.7354238 ]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(81740.0, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(5205.362, shape=(), dtype=float32)\n",
            "Average reward in episode  21494 :  1242.6976318359375\n",
            "Final reward in episode  21494 :  1242.6976\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21494\n",
            "state:  tf.Tensor([[77.906395 35.954044]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.97677773  0.43158886]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-379076.47, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-17512.12, shape=(), dtype=float32)\n",
            "Average reward in episode  21495 :  1480.208251953125\n",
            "Final reward in episode  21495 :  1480.2083\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21495\n",
            "state:  tf.Tensor([[96.9994     2.3638506]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.9945012  0.7942925]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(16083.36, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(1475.4573, shape=(), dtype=float32)\n",
            "Average reward in episode  21496 :  2049.01025390625\n",
            "Final reward in episode  21496 :  2049.0103\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21496\n",
            "state:  tf.Tensor([[50.265816 16.570873]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.9670791   0.63440853]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(128278.414, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(15251.625, shape=(), dtype=float32)\n",
            "Average reward in episode  21497 :  1279.735107421875\n",
            "Final reward in episode  21497 :  1279.7351\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21497\n",
            "state:  tf.Tensor([[78.65029  8.53828]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.9909634  0.7508467]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(38018.344, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(4379.6426, shape=(), dtype=float32)\n",
            "Average reward in episode  21498 :  1466.5374755859375\n",
            "Final reward in episode  21498 :  1466.5375\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21498\n",
            "state:  tf.Tensor([[ 5.3790627 40.68051  ]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.6155556  -0.07745977]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-524823.94, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-13274.75, shape=(), dtype=float32)\n",
            "Average reward in episode  21499 :  2780.316650390625\n",
            "Final reward in episode  21499 :  2780.3167\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21499\n",
            "state:  tf.Tensor([[ 4.5803146 86.92157  ]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.03315543 -0.7453443 ]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-377526.1, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-18658.27, shape=(), dtype=float32)\n",
            "Average reward in episode  21500 :  1264.6517333984375\n",
            "Final reward in episode  21500 :  1264.6517\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21500\n",
            "state:  tf.Tensor([[59.60314  24.354885]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.9690865  0.5700228]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-24948.57, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-18658.23, shape=(), dtype=float32)\n",
            "Average reward in episode  21501 :  1161.0791015625\n",
            "Final reward in episode  21501 :  1161.0791\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21501\n",
            "state:  tf.Tensor([[ 5.4831014 38.152077 ]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.6377272  -0.00974068]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-513881.44, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-14694.678, shape=(), dtype=float32)\n",
            "Average reward in episode  21502 :  2823.365478515625\n",
            "Final reward in episode  21502 :  2823.3655\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21502\n",
            "state:  tf.Tensor([[55.598488 66.53565 ]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.8054918  -0.30934373]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-67313.03, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-17574.17, shape=(), dtype=float32)\n",
            "Average reward in episode  21503 :  1167.306396484375\n",
            "Final reward in episode  21503 :  1167.3064\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21503\n",
            "state:  tf.Tensor([[13.732843 14.236146]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.87150574  0.5146922 ]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-209672.34, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-14556.703, shape=(), dtype=float32)\n",
            "Average reward in episode  21504 :  2984.625\n",
            "Final reward in episode  21504 :  2984.625\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21504\n",
            "state:  tf.Tensor([[94.69093 50.43231]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.97765225  0.26355374]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-575183.44, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-15950.057, shape=(), dtype=float32)\n",
            "Average reward in episode  21505 :  2051.41162109375\n",
            "Final reward in episode  21505 :  2051.4116\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21505\n",
            "state:  tf.Tensor([[99.67602  16.617023]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.9930163  0.7511059]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-29902.701, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-6223.807, shape=(), dtype=float32)\n",
            "Average reward in episode  21506 :  2081.340087890625\n",
            "Final reward in episode  21506 :  2081.34\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21506\n",
            "state:  tf.Tensor([[73.669586 84.612236]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.8012716 -0.5551258]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-498562.94, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-14584.416, shape=(), dtype=float32)\n",
            "Average reward in episode  21507 :  1615.42529296875\n",
            "Final reward in episode  21507 :  1615.4253\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21507\n",
            "state:  tf.Tensor([[70.99164 35.48936]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.96793133  0.4228448 ]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-354481.94, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-18713.312, shape=(), dtype=float32)\n",
            "Average reward in episode  21508 :  1294.9979248046875\n",
            "Final reward in episode  21508 :  1294.9979\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21508\n",
            "state:  tf.Tensor([[75.18282  11.855893]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.98822886  0.7297849 ]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(32506.367, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(6507.914, shape=(), dtype=float32)\n",
            "Average reward in episode  21509 :  1357.6473388671875\n",
            "Final reward in episode  21509 :  1357.6473\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21509\n",
            "state:  tf.Tensor([[80.00661 64.13049]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.9295396  -0.15763052]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-556986.3, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-16742.234, shape=(), dtype=float32)\n",
            "Average reward in episode  21510 :  1604.312744140625\n",
            "Final reward in episode  21510 :  1604.3127\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21510\n",
            "state:  tf.Tensor([[62.799694 27.212465]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.9676862  0.5176083]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-58234.57, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-19134.445, shape=(), dtype=float32)\n",
            "Average reward in episode  21511 :  1165.7197265625\n",
            "Final reward in episode  21511 :  1165.7197\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21511\n",
            "state:  tf.Tensor([[96.65821  41.817802]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.9845604   0.40921006]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-421978.38, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-15606.909, shape=(), dtype=float32)\n",
            "Average reward in episode  21512 :  2079.071533203125\n",
            "Final reward in episode  21512 :  2079.0715\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21512\n",
            "state:  tf.Tensor([[53.072968 75.85579 ]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.69365644 -0.5308887 ]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(50227.383, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(4436.8276, shape=(), dtype=float32)\n",
            "Average reward in episode  21513 :  1190.4193115234375\n",
            "Final reward in episode  21513 :  1190.4193\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21513\n",
            "state:  tf.Tensor([[10.36135  34.402462]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.7009882   0.06479716]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-385971.06, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-10878.041, shape=(), dtype=float32)\n",
            "Average reward in episode  21514 :  2722.656494140625\n",
            "Final reward in episode  21514 :  2722.6565\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21514\n",
            "state:  tf.Tensor([[77.45879 87.84019]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.8063738 -0.6311386]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-285116.84, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-10504.84, shape=(), dtype=float32)\n",
            "Average reward in episode  21515 :  1718.7928466796875\n",
            "Final reward in episode  21515 :  1718.7928\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21515\n",
            "state:  tf.Tensor([[64.214645 94.31351 ]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.61959225 -0.73427963]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-260066.14, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-6218.3784, shape=(), dtype=float32)\n",
            "Average reward in episode  21516 :  1610.453125\n",
            "Final reward in episode  21516 :  1610.4531\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21516\n",
            "state:  tf.Tensor([[91.46416 73.10966]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.9386122 -0.3492578]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-295639.66, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-15981.273, shape=(), dtype=float32)\n",
            "Average reward in episode  21517 :  1935.9482421875\n",
            "Final reward in episode  21517 :  1935.9482\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21517\n",
            "state:  tf.Tensor([[ 7.972686 13.77878 ]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.84916687  0.39986113]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-333024.56, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-25974.227, shape=(), dtype=float32)\n",
            "Average reward in episode  21518 :  3358.56591796875\n",
            "Final reward in episode  21518 :  3358.566\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21518\n",
            "state:  tf.Tensor([[51.125103 55.14952 ]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.8504246  -0.18845166]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(296345.8, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(15258.973, shape=(), dtype=float32)\n",
            "Average reward in episode  21519 :  1189.3280029296875\n",
            "Final reward in episode  21519 :  1189.328\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21519\n",
            "state:  tf.Tensor([[48.023087 88.82167 ]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.5002324 -0.7298802]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-32721.9, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-1048.3762, shape=(), dtype=float32)\n",
            "Average reward in episode  21520 :  1273.5694580078125\n",
            "Final reward in episode  21520 :  1273.5695\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21520\n",
            "state:  tf.Tensor([[15.329879 58.82671 ]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.49001637 -0.44424266]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(84981.53, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(1172.5815, shape=(), dtype=float32)\n",
            "Average reward in episode  21521 :  1914.1009521484375\n",
            "Final reward in episode  21521 :  1914.101\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21521\n",
            "state:  tf.Tensor([[98.38921  12.137984]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.99381477  0.7229904 ]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(4518.99, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(2619.5627, shape=(), dtype=float32)\n",
            "Average reward in episode  21522 :  2037.3306884765625\n",
            "Final reward in episode  21522 :  2037.3307\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21522\n",
            "state:  tf.Tensor([[99.85532 18.45777]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.9933087  0.687172 ]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-37945.59, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-7019.734, shape=(), dtype=float32)\n",
            "Average reward in episode  21523 :  2080.204345703125\n",
            "Final reward in episode  21523 :  2080.2043\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21523\n",
            "state:  tf.Tensor([[62.028305 74.8969  ]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.8023162  -0.53119135]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(107726.05, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(7086.4478, shape=(), dtype=float32)\n",
            "Average reward in episode  21524 :  1252.462646484375\n",
            "Final reward in episode  21524 :  1252.4626\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21524\n",
            "state:  tf.Tensor([[88.456924 39.34228 ]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.9829533   0.34462854]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-314692.7, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-16428.387, shape=(), dtype=float32)\n",
            "Average reward in episode  21525 :  1784.596923828125\n",
            "Final reward in episode  21525 :  1784.5969\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21525\n",
            "state:  tf.Tensor([[16.819601   0.5722226]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.93918186  0.6052093 ]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-146518.12, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-8118.5176, shape=(), dtype=float32)\n",
            "Average reward in episode  21526 :  3171.626708984375\n",
            "Final reward in episode  21526 :  3171.6267\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21526\n",
            "state:  tf.Tensor([[45.31433 65.8144 ]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.7459746 -0.4453842]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(384651.62, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(14205.461, shape=(), dtype=float32)\n",
            "Average reward in episode  21527 :  1211.384765625\n",
            "Final reward in episode  21527 :  1211.3848\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21527\n",
            "state:  tf.Tensor([[40.856754  8.672403]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.96683645  0.6348096 ]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(38851.195, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(1744.9614, shape=(), dtype=float32)\n",
            "Average reward in episode  21528 :  1750.70068359375\n",
            "Final reward in episode  21528 :  1750.7007\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21528\n",
            "state:  tf.Tensor([[96.42088  42.837566]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.9860115   0.31763026]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-363435.06, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-15710.039, shape=(), dtype=float32)\n",
            "Average reward in episode  21529 :  2033.6724853515625\n",
            "Final reward in episode  21529 :  2033.6725\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21529\n",
            "state:  tf.Tensor([[83.331604 39.532776]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.97994363  0.3104046 ]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-337484.2, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-17245.969, shape=(), dtype=float32)\n",
            "Average reward in episode  21530 :  1616.0726318359375\n",
            "Final reward in episode  21530 :  1616.0726\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21530\n",
            "state:  tf.Tensor([[34.955482 12.66502 ]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.9512746   0.57531077]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(24527.156, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(1271.1663, shape=(), dtype=float32)\n",
            "Average reward in episode  21531 :  1987.738525390625\n",
            "Final reward in episode  21531 :  1987.7385\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21531\n",
            "state:  tf.Tensor([[11.275231 22.426313]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.8288976   0.26525328]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-276124.94, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-10666.15, shape=(), dtype=float32)\n",
            "Average reward in episode  21532 :  3069.64697265625\n",
            "Final reward in episode  21532 :  3069.647\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21532\n",
            "state:  tf.Tensor([[18.507708 12.008342]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.9108187   0.49473858]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-79885.42, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-3856.646, shape=(), dtype=float32)\n",
            "Average reward in episode  21533 :  2868.55810546875\n",
            "Final reward in episode  21533 :  2868.558\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21533\n",
            "state:  tf.Tensor([[28.652952 71.015076]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.5217916 -0.5822418]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(336568.94, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(7169.1455, shape=(), dtype=float32)\n",
            "Average reward in episode  21534 :  1331.506103515625\n",
            "Final reward in episode  21534 :  1331.5061\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21534\n",
            "state:  tf.Tensor([[ 5.0811515 40.02405  ]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.6397821 -0.1570677]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-405874.66, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-8574.392, shape=(), dtype=float32)\n",
            "Average reward in episode  21535 :  2957.4609375\n",
            "Final reward in episode  21535 :  2957.461\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21535\n",
            "state:  tf.Tensor([[68.55543  62.010876]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.91063476 -0.25671127]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(79966.92, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(9224.83, shape=(), dtype=float32)\n",
            "Average reward in episode  21536 :  1277.7554931640625\n",
            "Final reward in episode  21536 :  1277.7555\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21536\n",
            "state:  tf.Tensor([[57.92244 64.5702 ]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.8493041  -0.35424533]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(156337.12, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(15604.193, shape=(), dtype=float32)\n",
            "Average reward in episode  21537 :  1173.362060546875\n",
            "Final reward in episode  21537 :  1173.362\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21537\n",
            "state:  tf.Tensor([[ 3.3944309 19.405033 ]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.8073931   0.26013225]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-365849.12, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-17819.113, shape=(), dtype=float32)\n",
            "Average reward in episode  21538 :  3530.6728515625\n",
            "Final reward in episode  21538 :  3530.6729\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21538\n",
            "state:  tf.Tensor([[84.56116  48.714367]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.9725787  0.1453822]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-378375.97, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-17248.398, shape=(), dtype=float32)\n",
            "Average reward in episode  21539 :  1677.36962890625\n",
            "Final reward in episode  21539 :  1677.3696\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21539\n",
            "state:  tf.Tensor([[83.2233  17.36762]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.9905613   0.66474915]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(23154.441, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(8237.5625, shape=(), dtype=float32)\n",
            "Average reward in episode  21540 :  1581.88134765625\n",
            "Final reward in episode  21540 :  1581.8813\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21540\n",
            "state:  tf.Tensor([[38.907597 72.31207 ]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.6205958  -0.53640604]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(223474.72, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(10533.619, shape=(), dtype=float32)\n",
            "Average reward in episode  21541 :  1197.798583984375\n",
            "Final reward in episode  21541 :  1197.7986\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21541\n",
            "state:  tf.Tensor([[33.245117 80.731514]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.4489888 -0.6561182]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(55974.855, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(6698.538, shape=(), dtype=float32)\n",
            "Average reward in episode  21542 :  1166.8485107421875\n",
            "Final reward in episode  21542 :  1166.8485\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21542\n",
            "state:  tf.Tensor([[70.74726  23.565002]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.9820557  0.5716207]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-40743.594, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-18662.129, shape=(), dtype=float32)\n",
            "Average reward in episode  21543 :  1249.5467529296875\n",
            "Final reward in episode  21543 :  1249.5468\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21543\n",
            "state:  tf.Tensor([[98.72087  31.649471]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.9908889  0.5740392]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-250314.25, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-13390.905, shape=(), dtype=float32)\n",
            "Average reward in episode  21544 :  2102.567138671875\n",
            "Final reward in episode  21544 :  2102.5671\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21544\n",
            "state:  tf.Tensor([[78.292595 83.748825]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.857215  -0.5593285]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-354183.97, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-13784.82, shape=(), dtype=float32)\n",
            "Average reward in episode  21545 :  1661.69384765625\n",
            "Final reward in episode  21545 :  1661.6938\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21545\n",
            "state:  tf.Tensor([[54.864754 83.10184 ]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.6744796 -0.6204045]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-131302.06, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-6540.191, shape=(), dtype=float32)\n",
            "Average reward in episode  21546 :  1236.792724609375\n",
            "Final reward in episode  21546 :  1236.7927\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21546\n",
            "state:  tf.Tensor([[ 4.2899075 59.75582  ]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.38827562 -0.4759954 ]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-437550.38, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-7161.9272, shape=(), dtype=float32)\n",
            "Average reward in episode  21547 :  2235.559326171875\n",
            "Final reward in episode  21547 :  2235.5593\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21547\n",
            "state:  tf.Tensor([[92.375015 11.506831]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.99357027  0.73300344]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(20947.992, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(3723.3179, shape=(), dtype=float32)\n",
            "Average reward in episode  21548 :  1871.8837890625\n",
            "Final reward in episode  21548 :  1871.8838\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21548\n",
            "state:  tf.Tensor([[54.62461 57.36243]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.87077695 -0.16876705]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(143872.16, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(15544.8125, shape=(), dtype=float32)\n",
            "Average reward in episode  21549 :  1163.0830078125\n",
            "Final reward in episode  21549 :  1163.083\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21549\n",
            "state:  tf.Tensor([[86.97812   9.504505]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.99311095  0.7378532 ]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(38343.094, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(4169.7705, shape=(), dtype=float32)\n",
            "Average reward in episode  21550 :  1716.584228515625\n",
            "Final reward in episode  21550 :  1716.5842\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21550\n",
            "state:  tf.Tensor([[12.357301 17.95395 ]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.8594708   0.42138696]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-255578.27, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-17475.385, shape=(), dtype=float32)\n",
            "Average reward in episode  21551 :  3042.80029296875\n",
            "Final reward in episode  21551 :  3042.8003\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21551\n",
            "state:  tf.Tensor([[46.661922 68.34201 ]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.74161965 -0.40806812]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(174112.92, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(13743.43, shape=(), dtype=float32)\n",
            "Average reward in episode  21552 :  1171.6087646484375\n",
            "Final reward in episode  21552 :  1171.6088\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21552\n",
            "state:  tf.Tensor([[44.38368  18.473516]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.95819634  0.59195215]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(148635.69, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(15368.182, shape=(), dtype=float32)\n",
            "Average reward in episode  21553 :  1464.8114013671875\n",
            "Final reward in episode  21553 :  1464.8114\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21553\n",
            "state:  tf.Tensor([[90.56531   8.799563]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.9937192  0.7600912]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(26267.188, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(3126.348, shape=(), dtype=float32)\n",
            "Average reward in episode  21554 :  1825.7578125\n",
            "Final reward in episode  21554 :  1825.7578\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21554\n",
            "state:  tf.Tensor([[78.3374   19.665981]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.98835117  0.6722127 ]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-47697.23, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-12777.59, shape=(), dtype=float32)\n",
            "Average reward in episode  21555 :  1445.903076171875\n",
            "Final reward in episode  21555 :  1445.9031\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21555\n",
            "state:  tf.Tensor([[96.248795 63.455276]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.96960044 -0.0240325 ]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-594812.0, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-15714.359, shape=(), dtype=float32)\n",
            "Average reward in episode  21556 :  2092.361572265625\n",
            "Final reward in episode  21556 :  2092.3616\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21556\n",
            "state:  tf.Tensor([[46.976307 10.261205]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.9727695  0.7005234]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(86998.61, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(6636.9785, shape=(), dtype=float32)\n",
            "Average reward in episode  21557 :  1413.6307373046875\n",
            "Final reward in episode  21557 :  1413.6307\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21557\n",
            "state:  tf.Tensor([[78.26397 39.86095]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.9754092   0.38954666]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-514452.3, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-17631.201, shape=(), dtype=float32)\n",
            "Average reward in episode  21558 :  1514.9444580078125\n",
            "Final reward in episode  21558 :  1514.9445\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21558\n",
            "state:  tf.Tensor([[99.01979 94.70952]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.90535414 -0.59498733]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-530268.0, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-14693.914, shape=(), dtype=float32)\n",
            "Average reward in episode  21559 :  2280.684326171875\n",
            "Final reward in episode  21559 :  2280.6843\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21559\n",
            "state:  tf.Tensor([[87.291756 45.097958]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.9787894  0.3353703]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-547187.94, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-16641.684, shape=(), dtype=float32)\n",
            "Average reward in episode  21560 :  1816.71923828125\n",
            "Final reward in episode  21560 :  1816.7192\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21560\n",
            "state:  tf.Tensor([[20.22807  78.981346]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.3145098 -0.6215558]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-84311.54, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-3034.0552, shape=(), dtype=float32)\n",
            "Average reward in episode  21561 :  1232.1483154296875\n",
            "Final reward in episode  21561 :  1232.1483\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21561\n",
            "state:  tf.Tensor([[75.6771 38.1321]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.9744544   0.40327647]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-385931.5, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-18024.543, shape=(), dtype=float32)\n",
            "Average reward in episode  21562 :  1427.2037353515625\n",
            "Final reward in episode  21562 :  1427.2037\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21562\n",
            "state:  tf.Tensor([[71.37764 70.33956]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.88905513 -0.3062212 ]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-342145.06, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-16937.492, shape=(), dtype=float32)\n",
            "Average reward in episode  21563 :  1397.453369140625\n",
            "Final reward in episode  21563 :  1397.4534\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21563\n",
            "state:  tf.Tensor([[71.25195 80.25385]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.83674    -0.49428564]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-380473.44, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-14771.238, shape=(), dtype=float32)\n",
            "Average reward in episode  21564 :  1474.7313232421875\n",
            "Final reward in episode  21564 :  1474.7313\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21564\n",
            "state:  tf.Tensor([[92.310005 41.933937]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.9844012   0.39541522]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-443187.9, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-15955.344, shape=(), dtype=float32)\n",
            "Average reward in episode  21565 :  1949.020751953125\n",
            "Final reward in episode  21565 :  1949.0208\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21565\n",
            "state:  tf.Tensor([[31.828299   6.6771884]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.9568996  0.6666618]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-25342.209, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-1656.4958, shape=(), dtype=float32)\n",
            "Average reward in episode  21566 :  2194.31640625\n",
            "Final reward in episode  21566 :  2194.3164\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21566\n",
            "state:  tf.Tensor([[54.442364 99.27438 ]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.47934914 -0.7668917 ]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-212244.45, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-4194.727, shape=(), dtype=float32)\n",
            "Average reward in episode  21567 :  1571.9141845703125\n",
            "Final reward in episode  21567 :  1571.9142\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21567\n",
            "state:  tf.Tensor([[11.346413 88.11389 ]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.10733821 -0.75344956]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-222309.1, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-18694.352, shape=(), dtype=float32)\n",
            "Average reward in episode  21568 :  1203.064697265625\n",
            "Final reward in episode  21568 :  1203.0647\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21568\n",
            "state:  tf.Tensor([[41.8427   38.149582]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.8983515   0.20152996]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(278668.8, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(13014.861, shape=(), dtype=float32)\n",
            "Average reward in episode  21569 :  1445.3067626953125\n",
            "Final reward in episode  21569 :  1445.3068\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21569\n",
            "state:  tf.Tensor([[0.46806914 0.61016333]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.89706     0.53687876]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-310539.62, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-46275.14, shape=(), dtype=float32)\n",
            "Average reward in episode  21570 :  4070.607421875\n",
            "Final reward in episode  21570 :  4070.6074\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21570\n",
            "state:  tf.Tensor([[47.185066 76.35242 ]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.6664287  -0.55477136]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-16063.162, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-6151.0195, shape=(), dtype=float32)\n",
            "Average reward in episode  21571 :  1162.5115966796875\n",
            "Final reward in episode  21571 :  1162.5116\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21571\n",
            "state:  tf.Tensor([[67.58863   9.796348]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.9878619  0.7039068]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(90917.234, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(7068.233, shape=(), dtype=float32)\n",
            "Average reward in episode  21572 :  1221.84326171875\n",
            "Final reward in episode  21572 :  1221.8433\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21572\n",
            "state:  tf.Tensor([[14.421354 36.72314 ]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.7408833   0.06502374]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-238001.19, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-7062.1494, shape=(), dtype=float32)\n",
            "Average reward in episode  21573 :  2565.19921875\n",
            "Final reward in episode  21573 :  2565.1992\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21573\n",
            "state:  tf.Tensor([[86.40702 69.06137]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.9433083 -0.2677225]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-358252.56, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-16542.27, shape=(), dtype=float32)\n",
            "Average reward in episode  21574 :  1779.071533203125\n",
            "Final reward in episode  21574 :  1779.0715\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21574\n",
            "state:  tf.Tensor([[22.577347 58.189873]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.6001389  -0.34489945]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(340724.44, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(5315.133, shape=(), dtype=float32)\n",
            "Average reward in episode  21575 :  1737.3106689453125\n",
            "Final reward in episode  21575 :  1737.3107\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21575\n",
            "state:  tf.Tensor([[21.464638 70.95759 ]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.4302392  -0.56432986]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(136676.5, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(2527.3271, shape=(), dtype=float32)\n",
            "Average reward in episode  21576 :  1393.5645751953125\n",
            "Final reward in episode  21576 :  1393.5646\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21576\n",
            "state:  tf.Tensor([[13.418589 93.911095]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.05111234 -0.7936716 ]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-165244.86, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-19417.771, shape=(), dtype=float32)\n",
            "Average reward in episode  21577 :  1176.1810302734375\n",
            "Final reward in episode  21577 :  1176.181\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21577\n",
            "state:  tf.Tensor([[72.7454   39.310734]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.9694089   0.30326074]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-240227.03, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-18646.719, shape=(), dtype=float32)\n",
            "Average reward in episode  21578 :  1320.5789794921875\n",
            "Final reward in episode  21578 :  1320.579\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21578\n",
            "state:  tf.Tensor([[13.278293 60.693703]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.4575635 -0.4479337]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-62124.176, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-889.50494, shape=(), dtype=float32)\n",
            "Average reward in episode  21579 :  1899.0174560546875\n",
            "Final reward in episode  21579 :  1899.0175\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21579\n",
            "state:  tf.Tensor([[ 7.2959447 64.31853  ]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.33887082 -0.5392533 ]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-332990.88, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-4904.418, shape=(), dtype=float32)\n",
            "Average reward in episode  21580 :  1925.472412109375\n",
            "Final reward in episode  21580 :  1925.4724\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21580\n",
            "state:  tf.Tensor([[45.286114 96.663345]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.36564693 -0.77845824]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-65728.21, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-1520.2925, shape=(), dtype=float32)\n",
            "Average reward in episode  21581 :  1418.557861328125\n",
            "Final reward in episode  21581 :  1418.5579\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21581\n",
            "state:  tf.Tensor([[15.174995  9.084631]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.9042918   0.53619874]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-176336.25, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-11054.419, shape=(), dtype=float32)\n",
            "Average reward in episode  21582 :  3058.89892578125\n",
            "Final reward in episode  21582 :  3058.899\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21582\n",
            "state:  tf.Tensor([[57.162273 43.39701 ]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.92742926  0.13052967]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(63636.977, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(16176.561, shape=(), dtype=float32)\n",
            "Average reward in episode  21583 :  1161.98681640625\n",
            "Final reward in episode  21583 :  1161.9868\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21583\n",
            "state:  tf.Tensor([[91.1093   52.651817]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.9734076  0.1096143]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-448615.88, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-16672.62, shape=(), dtype=float32)\n",
            "Average reward in episode  21584 :  1895.3966064453125\n",
            "Final reward in episode  21584 :  1895.3966\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21584\n",
            "state:  tf.Tensor([[89.17722  52.941113]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.9707911   0.08963605]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-492938.3, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-16879.982, shape=(), dtype=float32)\n",
            "Average reward in episode  21585 :  1835.963623046875\n",
            "Final reward in episode  21585 :  1835.9636\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21585\n",
            "state:  tf.Tensor([[87.97451 83.48476]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.8953814  -0.53930247]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-334941.72, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-15967.261, shape=(), dtype=float32)\n",
            "Average reward in episode  21586 :  1905.09765625\n",
            "Final reward in episode  21586 :  1905.0977\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21586\n",
            "state:  tf.Tensor([[26.509241 54.802345]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.64478683 -0.27629805]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(576157.44, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(8757.547, shape=(), dtype=float32)\n",
            "Average reward in episode  21587 :  1655.3465576171875\n",
            "Final reward in episode  21587 :  1655.3466\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21587\n",
            "state:  tf.Tensor([[57.42959 82.67116]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.67775345 -0.62951237]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-61263.97, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-2494.2656, shape=(), dtype=float32)\n",
            "Average reward in episode  21588 :  1285.658935546875\n",
            "Final reward in episode  21588 :  1285.6589\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21588\n",
            "state:  tf.Tensor([[75.16148  47.473316]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.95802927  0.11468456]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-153383.78, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-18959.283, shape=(), dtype=float32)\n",
            "Average reward in episode  21589 :  1395.8857421875\n",
            "Final reward in episode  21589 :  1395.8857\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21589\n",
            "state:  tf.Tensor([[55.077305 24.859245]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.9613788   0.47342852]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(157762.95, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(16757.611, shape=(), dtype=float32)\n",
            "Average reward in episode  21590 :  1189.9091796875\n",
            "Final reward in episode  21590 :  1189.9092\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21590\n",
            "state:  tf.Tensor([[98.93952  49.082615]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.9825143  0.2089459]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-458966.2, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-15985.262, shape=(), dtype=float32)\n",
            "Average reward in episode  21591 :  2113.562255859375\n",
            "Final reward in episode  21591 :  2113.5623\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21591\n",
            "state:  tf.Tensor([[33.725643 33.622337]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.8690436  0.2089649]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(545080.75, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(16125.695, shape=(), dtype=float32)\n",
            "Average reward in episode  21592 :  1798.9661865234375\n",
            "Final reward in episode  21592 :  1798.9662\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21592\n",
            "state:  tf.Tensor([[ 0.2691831 86.20538  ]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[ 0.02650461 -0.7796048 ]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-407377.8, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-17488.918, shape=(), dtype=float32)\n",
            "Average reward in episode  21593 :  1311.6689453125\n",
            "Final reward in episode  21593 :  1311.669\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21593\n",
            "state:  tf.Tensor([[62.83748  88.886444]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.6707842  -0.69916093]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-170800.9, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-5266.286, shape=(), dtype=float32)\n",
            "Average reward in episode  21594 :  1456.0926513671875\n",
            "Final reward in episode  21594 :  1456.0927\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21594\n",
            "state:  tf.Tensor([[40.955914 69.372444]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.64171654 -0.5122646 ]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(323471.78, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(13319.242, shape=(), dtype=float32)\n",
            "Average reward in episode  21595 :  1201.927490234375\n",
            "Final reward in episode  21595 :  1201.9275\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21595\n",
            "state:  tf.Tensor([[21.624582  6.923404]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.9282701  0.5685467]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-99136.66, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-5111.657, shape=(), dtype=float32)\n",
            "Average reward in episode  21596 :  2768.539794921875\n",
            "Final reward in episode  21596 :  2768.5398\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21596\n",
            "state:  tf.Tensor([[44.480324 88.41177 ]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.44544166 -0.7313363 ]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-4054.1748, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-135.96341, shape=(), dtype=float32)\n",
            "Average reward in episode  21597 :  1252.9058837890625\n",
            "Final reward in episode  21597 :  1252.9059\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21597\n",
            "state:  tf.Tensor([[57.46605 88.38909]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.6150782  -0.70586526]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-97635.5, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-2828.1697, shape=(), dtype=float32)\n",
            "Average reward in episode  21598 :  1373.19677734375\n",
            "Final reward in episode  21598 :  1373.1968\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21598\n",
            "state:  tf.Tensor([[28.031939 78.480446]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.36777952 -0.66787416]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(108534.91, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(6391.4277, shape=(), dtype=float32)\n",
            "Average reward in episode  21599 :  1185.8251953125\n",
            "Final reward in episode  21599 :  1185.8252\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21599\n",
            "state:  tf.Tensor([[28.687347 56.931454]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.6477657 -0.3340166]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(686000.9, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(10234.53, shape=(), dtype=float32)\n",
            "Average reward in episode  21600 :  1578.322265625\n",
            "Final reward in episode  21600 :  1578.3223\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21600\n",
            "state:  tf.Tensor([[ 3.6668265 14.1538725]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.8276667   0.34074315]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-378930.2, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-27519.746, shape=(), dtype=float32)\n",
            "Average reward in episode  21601 :  3599.229736328125\n",
            "Final reward in episode  21601 :  3599.2297\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21601\n",
            "state:  tf.Tensor([[37.07427   5.018493]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.9641593  0.6540045]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-22341.4, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-1006.8878, shape=(), dtype=float32)\n",
            "Average reward in episode  21602 :  1986.8480224609375\n",
            "Final reward in episode  21602 :  1986.848\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21602\n",
            "state:  tf.Tensor([[ 2.2704277 20.340364 ]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.7762486   0.22901466]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-407966.44, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-18321.242, shape=(), dtype=float32)\n",
            "Average reward in episode  21603 :  3518.91748046875\n",
            "Final reward in episode  21603 :  3518.9175\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21603\n",
            "state:  tf.Tensor([[24.839996 61.552727]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.5502359  -0.42051947]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(489787.3, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(6950.3613, shape=(), dtype=float32)\n",
            "Average reward in episode  21604 :  1531.55224609375\n",
            "Final reward in episode  21604 :  1531.5522\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21604\n",
            "state:  tf.Tensor([[59.725075 54.356876]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.8958998  -0.10873837]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(45654.332, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(14733.305, shape=(), dtype=float32)\n",
            "Average reward in episode  21605 :  1167.1055908203125\n",
            "Final reward in episode  21605 :  1167.1056\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21605\n",
            "state:  tf.Tensor([[26.620289 37.248306]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.79992026  0.12840362]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(525155.94, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(12568.039, shape=(), dtype=float32)\n",
            "Average reward in episode  21606 :  1998.254638671875\n",
            "Final reward in episode  21606 :  1998.2546\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21606\n",
            "state:  tf.Tensor([[77.29939 82.65809]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.8430391 -0.5529743]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-336401.1, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-12620.917, shape=(), dtype=float32)\n",
            "Average reward in episode  21607 :  1645.2191162109375\n",
            "Final reward in episode  21607 :  1645.2191\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21607\n",
            "state:  tf.Tensor([[21.948315 60.90745 ]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.51772714 -0.39256233]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(287349.62, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(4315.786, shape=(), dtype=float32)\n",
            "Average reward in episode  21608 :  1573.2197265625\n",
            "Final reward in episode  21608 :  1573.2197\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21608\n",
            "state:  tf.Tensor([[56.30788 40.73749]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.92919385  0.20948668]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-9226.209, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-11504.148, shape=(), dtype=float32)\n",
            "Average reward in episode  21609 :  1162.9920654296875\n",
            "Final reward in episode  21609 :  1162.9921\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21609\n",
            "state:  tf.Tensor([[61.426292 98.52707 ]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.53061783 -0.7524719 ]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-286856.56, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-5858.4224, shape=(), dtype=float32)\n",
            "Average reward in episode  21610 :  1706.9063720703125\n",
            "Final reward in episode  21610 :  1706.9064\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21610\n",
            "state:  tf.Tensor([[66.789795 41.460587]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.9521853   0.25061744]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-253828.78, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-19270.676, shape=(), dtype=float32)\n",
            "Average reward in episode  21611 :  1211.906982421875\n",
            "Final reward in episode  21611 :  1211.907\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21611\n",
            "state:  tf.Tensor([[87.35855  55.033905]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.964436    0.06365176]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-540729.25, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-16963.707, shape=(), dtype=float32)\n",
            "Average reward in episode  21612 :  1797.0404052734375\n",
            "Final reward in episode  21612 :  1797.0404\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21612\n",
            "state:  tf.Tensor([[10.879615   5.0827928]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.89901876  0.56848043]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-234642.97, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-19725.035, shape=(), dtype=float32)\n",
            "Average reward in episode  21613 :  3339.8740234375\n",
            "Final reward in episode  21613 :  3339.874\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21613\n",
            "state:  tf.Tensor([[90.131    57.035576]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.96538514  0.03089393]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-518579.56, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-16679.648, shape=(), dtype=float32)\n",
            "Average reward in episode  21614 :  1884.37646484375\n",
            "Final reward in episode  21614 :  1884.3765\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21614\n",
            "state:  tf.Tensor([[97.977684 70.62794 ]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.95648646 -0.22936936]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-500436.8, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-15736.537, shape=(), dtype=float32)\n",
            "Average reward in episode  21615 :  2122.1953125\n",
            "Final reward in episode  21615 :  2122.1953\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21615\n",
            "state:  tf.Tensor([[96.35501 81.86452]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.92713034 -0.46144947]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-423995.03, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-15619.617, shape=(), dtype=float32)\n",
            "Average reward in episode  21616 :  2116.1640625\n",
            "Final reward in episode  21616 :  2116.164\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21616\n",
            "state:  tf.Tensor([[95.866325 80.92755 ]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.92840546 -0.45455602]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-393914.66, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-15716.004, shape=(), dtype=float32)\n",
            "Average reward in episode  21617 :  2096.574951171875\n",
            "Final reward in episode  21617 :  2096.575\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21617\n",
            "state:  tf.Tensor([[56.785835 23.786314]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.9640434  0.5110689]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(148528.38, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(16658.229, shape=(), dtype=float32)\n",
            "Average reward in episode  21618 :  1173.7298583984375\n",
            "Final reward in episode  21618 :  1173.7299\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21618\n",
            "state:  tf.Tensor([[26.837559 55.537838]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.6280162  -0.28300282]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(578281.1, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(8710.923, shape=(), dtype=float32)\n",
            "Average reward in episode  21619 :  1595.925537109375\n",
            "Final reward in episode  21619 :  1595.9255\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21619\n",
            "state:  tf.Tensor([[51.177803 92.5406  ]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.4680655  -0.73844486]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-125059.74, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-2748.6748, shape=(), dtype=float32)\n",
            "Average reward in episode  21620 :  1419.3355712890625\n",
            "Final reward in episode  21620 :  1419.3356\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21620\n",
            "state:  tf.Tensor([[46.860165 50.60573 ]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.8445399  -0.09380504]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(419498.94, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(15525.262, shape=(), dtype=float32)\n",
            "Average reward in episode  21621 :  1239.0042724609375\n",
            "Final reward in episode  21621 :  1239.0043\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21621\n",
            "state:  tf.Tensor([[29.058325 26.519606]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.8752846  0.3490543]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(467089.1, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(16048.193, shape=(), dtype=float32)\n",
            "Average reward in episode  21622 :  2065.084228515625\n",
            "Final reward in episode  21622 :  2065.0842\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21622\n",
            "state:  tf.Tensor([[97.94595  54.995495]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.9763667  0.0763296]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-461377.6, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-16099.929, shape=(), dtype=float32)\n",
            "Average reward in episode  21623 :  2090.572021484375\n",
            "Final reward in episode  21623 :  2090.572\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21623\n",
            "state:  tf.Tensor([[51.783455 89.32259 ]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.52213806 -0.71397907]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-95790.41, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-2651.2227, shape=(), dtype=float32)\n",
            "Average reward in episode  21624 :  1345.96533203125\n",
            "Final reward in episode  21624 :  1345.9653\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21624\n",
            "state:  tf.Tensor([[11.842461 26.276674]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.77829844  0.2165605 ]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-324635.75, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-10852.151, shape=(), dtype=float32)\n",
            "Average reward in episode  21625 :  2867.166748046875\n",
            "Final reward in episode  21625 :  2867.1667\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21625\n",
            "state:  tf.Tensor([[84.3402  73.02974]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.91737324 -0.3935402 ]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-217222.03, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-14816.086, shape=(), dtype=float32)\n",
            "Average reward in episode  21626 :  1740.730712890625\n",
            "Final reward in episode  21626 :  1740.7307\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21626\n",
            "state:  tf.Tensor([[99.39716 75.32673]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.95122844 -0.37299067]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-352689.56, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-15690.519, shape=(), dtype=float32)\n",
            "Average reward in episode  21627 :  2142.60595703125\n",
            "Final reward in episode  21627 :  2142.606\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21627\n",
            "state:  tf.Tensor([[15.937628 96.0508  ]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[ 0.01016786 -0.81785727]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-36739.234, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-3392.1729, shape=(), dtype=float32)\n",
            "Average reward in episode  21628 :  1190.1075439453125\n",
            "Final reward in episode  21628 :  1190.1075\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21628\n",
            "state:  tf.Tensor([[36.82867 92.23358]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.28945765 -0.773598  ]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(60498.438, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(1926.72, shape=(), dtype=float32)\n",
            "Average reward in episode  21629 :  1261.1451416015625\n",
            "Final reward in episode  21629 :  1261.1451\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21629\n",
            "state:  tf.Tensor([[18.01245   5.535874]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.92252594  0.555882  ]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-134831.22, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-6935.5464, shape=(), dtype=float32)\n",
            "Average reward in episode  21630 :  2999.451416015625\n",
            "Final reward in episode  21630 :  2999.4514\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21630\n",
            "state:  tf.Tensor([[35.506004 57.88396 ]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.70948935 -0.33450478]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(814777.5, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(13704.006, shape=(), dtype=float32)\n",
            "Average reward in episode  21631 :  1414.9959716796875\n",
            "Final reward in episode  21631 :  1414.996\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21631\n",
            "state:  tf.Tensor([[13.674902 13.354717]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.87715095  0.43015885]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-188104.03, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-10586.864, shape=(), dtype=float32)\n",
            "Average reward in episode  21632 :  3086.153076171875\n",
            "Final reward in episode  21632 :  3086.153\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21632\n",
            "state:  tf.Tensor([[52.459763 49.80189 ]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.8868466  -0.08871873]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(323525.62, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(16053.481, shape=(), dtype=float32)\n",
            "Average reward in episode  21633 :  1196.52490234375\n",
            "Final reward in episode  21633 :  1196.5249\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21633\n",
            "state:  tf.Tensor([[80.612114 29.7594  ]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.9835198  0.4579686]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-57914.266, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-18061.186, shape=(), dtype=float32)\n",
            "Average reward in episode  21634 :  1516.1678466796875\n",
            "Final reward in episode  21634 :  1516.1678\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21634\n",
            "state:  tf.Tensor([[32.73998  47.993717]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.775794   -0.13500425]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(796845.8, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(14192.747, shape=(), dtype=float32)\n",
            "Average reward in episode  21635 :  1662.01318359375\n",
            "Final reward in episode  21635 :  1662.0132\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21635\n",
            "state:  tf.Tensor([[88.22541  62.808945]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.95650196 -0.1905971 ]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-257931.05, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-17209.887, shape=(), dtype=float32)\n",
            "Average reward in episode  21636 :  1799.1328125\n",
            "Final reward in episode  21636 :  1799.1328\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21636\n",
            "state:  tf.Tensor([[16.807056 65.106476]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.43090785 -0.539712  ]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(126853.3, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(1805.3728, shape=(), dtype=float32)\n",
            "Average reward in episode  21637 :  1673.865966796875\n",
            "Final reward in episode  21637 :  1673.866\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21637\n",
            "state:  tf.Tensor([[86.64405 58.64103]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.9608849  -0.10900681]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-243486.9, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-17413.621, shape=(), dtype=float32)\n",
            "Average reward in episode  21638 :  1744.0242919921875\n",
            "Final reward in episode  21638 :  1744.0243\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21638\n",
            "state:  tf.Tensor([[ 2.9607184 55.785572 ]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.40284213 -0.47359002]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-403982.78, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-5966.611, shape=(), dtype=float32)\n",
            "Average reward in episode  21639 :  2435.896484375\n",
            "Final reward in episode  21639 :  2435.8965\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21639\n",
            "state:  tf.Tensor([[34.69913  98.961914]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.1977132  -0.82223034]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(1464.1702, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(40.33744, shape=(), dtype=float32)\n",
            "Average reward in episode  21640 :  1359.153076171875\n",
            "Final reward in episode  21640 :  1359.1531\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21640\n",
            "state:  tf.Tensor([[79.45672   5.918369]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.9918926  0.7015035]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(63996.3, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(3733.7197, shape=(), dtype=float32)\n",
            "Average reward in episode  21641 :  1539.6929931640625\n",
            "Final reward in episode  21641 :  1539.693\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21641\n",
            "state:  tf.Tensor([[ 7.282914 17.826813]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.82737815  0.29999092]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-341284.2, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-17979.129, shape=(), dtype=float32)\n",
            "Average reward in episode  21642 :  3353.12451171875\n",
            "Final reward in episode  21642 :  3353.1245\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21642\n",
            "state:  tf.Tensor([[78.53251  14.725912]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.9894954  0.6429661]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(77101.69, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(8327.631, shape=(), dtype=float32)\n",
            "Average reward in episode  21643 :  1458.818115234375\n",
            "Final reward in episode  21643 :  1458.8181\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21643\n",
            "state:  tf.Tensor([[79.51662 62.59671]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.93919116 -0.22627154]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-38181.883, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-5871.6357, shape=(), dtype=float32)\n",
            "Average reward in episode  21644 :  1546.1375732421875\n",
            "Final reward in episode  21644 :  1546.1376\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21644\n",
            "state:  tf.Tensor([[ 8.023293 24.293232]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.78972936  0.20057075]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-324752.62, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-12018.201, shape=(), dtype=float32)\n",
            "Average reward in episode  21645 :  3171.41064453125\n",
            "Final reward in episode  21645 :  3171.4106\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21645\n",
            "state:  tf.Tensor([[88.063736 47.32932 ]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.97675496  0.16651909]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-339226.75, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-17068.805, shape=(), dtype=float32)\n",
            "Average reward in episode  21646 :  1776.34130859375\n",
            "Final reward in episode  21646 :  1776.3413\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21646\n",
            "state:  tf.Tensor([[ 9.62719  84.163246]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.11794572 -0.75635886]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-210791.06, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-7975.808, shape=(), dtype=float32)\n",
            "Average reward in episode  21647 :  1261.4888916015625\n",
            "Final reward in episode  21647 :  1261.4889\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21647\n",
            "state:  tf.Tensor([[76.8256  73.29652]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.89799446 -0.43518105]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-87832.91, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-7600.0723, shape=(), dtype=float32)\n",
            "Average reward in episode  21648 :  1527.1470947265625\n",
            "Final reward in episode  21648 :  1527.1471\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21648\n",
            "state:  tf.Tensor([[62.978962 13.922482]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.9828193   0.62916774]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(154221.84, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(10274.529, shape=(), dtype=float32)\n",
            "Average reward in episode  21649 :  1183.9373779296875\n",
            "Final reward in episode  21649 :  1183.9374\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21649\n",
            "state:  tf.Tensor([[47.560596 85.90834 ]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.5585928 -0.6926285]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-52913.348, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-2680.0334, shape=(), dtype=float32)\n",
            "Average reward in episode  21650 :  1205.8753662109375\n",
            "Final reward in episode  21650 :  1205.8754\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21650\n",
            "state:  tf.Tensor([[11.467012 32.5557  ]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.75212157  0.08797637]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-283348.8, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-7936.942, shape=(), dtype=float32)\n",
            "Average reward in episode  21651 :  2815.28125\n",
            "Final reward in episode  21651 :  2815.2812\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21651\n",
            "state:  tf.Tensor([[16.809494 30.437838]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.80100334  0.19150013]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-208208.48, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-6887.1504, shape=(), dtype=float32)\n",
            "Average reward in episode  21652 :  2598.44775390625\n",
            "Final reward in episode  21652 :  2598.4478\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21652\n",
            "state:  tf.Tensor([[31.519009 86.11784 ]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.35774112 -0.7190894 ]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(32390.2, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(13621.5, shape=(), dtype=float32)\n",
            "Average reward in episode  21653 :  1160.930419921875\n",
            "Final reward in episode  21653 :  1160.9304\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21653\n",
            "state:  tf.Tensor([[97.52374 22.15699]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.99287856  0.6483732 ]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-58337.434, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-8832.9, shape=(), dtype=float32)\n",
            "Average reward in episode  21654 :  2026.320068359375\n",
            "Final reward in episode  21654 :  2026.3201\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21654\n",
            "state:  tf.Tensor([[33.13464  16.294481]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.93898594  0.5463026 ]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(141502.4, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(7291.2393, shape=(), dtype=float32)\n",
            "Average reward in episode  21655 :  2020.297607421875\n",
            "Final reward in episode  21655 :  2020.2976\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21655\n",
            "state:  tf.Tensor([[67.30893  38.403835]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.9643257   0.27931675]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-85474.984, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-20338.754, shape=(), dtype=float32)\n",
            "Average reward in episode  21656 :  1204.16748046875\n",
            "Final reward in episode  21656 :  1204.1675\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21656\n",
            "state:  tf.Tensor([[17.26314 91.85315]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.12833863 -0.7808604 ]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-119718.07, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-18452.674, shape=(), dtype=float32)\n",
            "Average reward in episode  21657 :  1168.0791015625\n",
            "Final reward in episode  21657 :  1168.0791\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21657\n",
            "state:  tf.Tensor([[50.738323 94.120415]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.5121644 -0.7471594]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-195095.12, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-5198.775, shape=(), dtype=float32)\n",
            "Average reward in episode  21658 :  1359.5885009765625\n",
            "Final reward in episode  21658 :  1359.5885\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21658\n",
            "state:  tf.Tensor([[66.900215 13.899027]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.98598796  0.6523246 ]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(123366.84, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(9819.89, shape=(), dtype=float32)\n",
            "Average reward in episode  21659 :  1199.8319091796875\n",
            "Final reward in episode  21659 :  1199.8319\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21659\n",
            "state:  tf.Tensor([[73.10748 56.9627 ]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.9419382  -0.09104735]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-174642.53, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-18320.346, shape=(), dtype=float32)\n",
            "Average reward in episode  21660 :  1357.53759765625\n",
            "Final reward in episode  21660 :  1357.5376\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21660\n",
            "state:  tf.Tensor([[41.84006 64.86342]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.7376777  -0.39577806]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(343462.88, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(12030.34, shape=(), dtype=float32)\n",
            "Average reward in episode  21661 :  1239.751708984375\n",
            "Final reward in episode  21661 :  1239.7517\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21661\n",
            "state:  tf.Tensor([[35.298187 81.23896 ]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.49038988 -0.6538802 ]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(64218.92, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(8287.653, shape=(), dtype=float32)\n",
            "Average reward in episode  21662 :  1164.5269775390625\n",
            "Final reward in episode  21662 :  1164.527\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21662\n",
            "state:  tf.Tensor([[44.39328 55.99723]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.82555366 -0.20399325]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(415625.2, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(14479.5, shape=(), dtype=float32)\n",
            "Average reward in episode  21663 :  1268.7855224609375\n",
            "Final reward in episode  21663 :  1268.7855\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21663\n",
            "state:  tf.Tensor([[89.0109  55.88807]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.9714906   0.02251843]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-480589.75, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-17108.031, shape=(), dtype=float32)\n",
            "Average reward in episode  21664 :  1826.2489013671875\n",
            "Final reward in episode  21664 :  1826.2489\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21664\n",
            "state:  tf.Tensor([[93.16746  26.356354]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.9914426   0.59770966]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-128218.02, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-12759.36, shape=(), dtype=float32)\n",
            "Average reward in episode  21665 :  1908.389404296875\n",
            "Final reward in episode  21665 :  1908.3894\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21665\n",
            "state:  tf.Tensor([[68.20013  56.832436]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.93028086 -0.10791233]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-80064.88, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-13557.194, shape=(), dtype=float32)\n",
            "Average reward in episode  21666 :  1249.291015625\n",
            "Final reward in episode  21666 :  1249.291\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21666\n",
            "state:  tf.Tensor([[68.49255  80.509514]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.8284361 -0.5566322]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-153839.5, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-8087.245, shape=(), dtype=float32)\n",
            "Average reward in episode  21667 :  1387.068359375\n",
            "Final reward in episode  21667 :  1387.0684\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21667\n",
            "state:  tf.Tensor([[96.27782  76.977715]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.95161736 -0.3963776 ]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-350904.28, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-16028.81, shape=(), dtype=float32)\n",
            "Average reward in episode  21668 :  2069.315673828125\n",
            "Final reward in episode  21668 :  2069.3157\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21668\n",
            "state:  tf.Tensor([[50.796272 24.671778]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.96128666  0.46848413]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(219753.9, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(17564.145, shape=(), dtype=float32)\n",
            "Average reward in episode  21669 :  1261.072509765625\n",
            "Final reward in episode  21669 :  1261.0725\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21669\n",
            "state:  tf.Tensor([[26.58952 97.26942]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.18915682 -0.80604416]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-92626.15, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-6267.365, shape=(), dtype=float32)\n",
            "Average reward in episode  21670 :  1217.022705078125\n",
            "Final reward in episode  21670 :  1217.0227\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21670\n",
            "state:  tf.Tensor([[69.83979   4.579961]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.99111706  0.71523094]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(87068.51, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(3859.078, shape=(), dtype=float32)\n",
            "Average reward in episode  21671 :  1317.367919921875\n",
            "Final reward in episode  21671 :  1317.3679\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21671\n",
            "state:  tf.Tensor([[51.286522 72.26615 ]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.7704257  -0.50480103]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(104625.234, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(15032.541, shape=(), dtype=float32)\n",
            "Average reward in episode  21672 :  1162.78955078125\n",
            "Final reward in episode  21672 :  1162.7896\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21672\n",
            "state:  tf.Tensor([[29.046097 90.67303 ]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.31933704 -0.76115537]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-65992.02, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-16176.152, shape=(), dtype=float32)\n",
            "Average reward in episode  21673 :  1162.60009765625\n",
            "Final reward in episode  21673 :  1162.6001\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21673\n",
            "state:  tf.Tensor([[70.17117  13.227632]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.9889168  0.6556069]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(123220.36, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(9124.639, shape=(), dtype=float32)\n",
            "Average reward in episode  21674 :  1251.186279296875\n",
            "Final reward in episode  21674 :  1251.1863\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21674\n",
            "state:  tf.Tensor([[9.056433  6.5382414]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.91079366  0.50943446]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-241138.0, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-23406.922, shape=(), dtype=float32)\n",
            "Average reward in episode  21675 :  3508.883544921875\n",
            "Final reward in episode  21675 :  3508.8835\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21675\n",
            "state:  tf.Tensor([[56.85053  16.927511]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.97924274  0.5939933 ]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(132869.53, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(14106.496, shape=(), dtype=float32)\n",
            "Average reward in episode  21676 :  1194.1666259765625\n",
            "Final reward in episode  21676 :  1194.1666\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21676\n",
            "state:  tf.Tensor([[93.667076 80.89611 ]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.9422448  -0.48041755]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-359278.28, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-16293.996, shape=(), dtype=float32)\n",
            "Average reward in episode  21677 :  2006.1597900390625\n",
            "Final reward in episode  21677 :  2006.1598\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21677\n",
            "state:  tf.Tensor([[94.56968  65.288994]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.9703597 -0.1678876]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-409216.94, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-16460.484, shape=(), dtype=float32)\n",
            "Average reward in episode  21678 :  1989.41943359375\n",
            "Final reward in episode  21678 :  1989.4194\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21678\n",
            "state:  tf.Tensor([[50.996315 51.32525 ]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.8990803  -0.08241548]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(322670.47, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(16010.492, shape=(), dtype=float32)\n",
            "Average reward in episode  21679 :  1205.552734375\n",
            "Final reward in episode  21679 :  1205.5527\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21679\n",
            "state:  tf.Tensor([[19.4282  72.49252]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.46099547 -0.6005314 ]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-11465.463, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-189.60588, shape=(), dtype=float32)\n",
            "Average reward in episode  21680 :  1538.4295654296875\n",
            "Final reward in episode  21680 :  1538.4296\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21680\n",
            "state:  tf.Tensor([[77.04882  45.272243]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.9731267   0.18251859]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-287188.6, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-18620.719, shape=(), dtype=float32)\n",
            "Average reward in episode  21681 :  1435.8123779296875\n",
            "Final reward in episode  21681 :  1435.8124\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21681\n",
            "state:  tf.Tensor([[91.14691 17.87606]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.9936401   0.66895425]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(1037.8276, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(1277.169, shape=(), dtype=float32)\n",
            "Average reward in episode  21682 :  1827.274658203125\n",
            "Final reward in episode  21682 :  1827.2747\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21682\n",
            "state:  tf.Tensor([[22.232933 54.834072]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.68459153 -0.29102802]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(466988.94, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(7750.0127, shape=(), dtype=float32)\n",
            "Average reward in episode  21683 :  1974.5416259765625\n",
            "Final reward in episode  21683 :  1974.5416\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21683\n",
            "state:  tf.Tensor([[26.911184 59.7258  ]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.6818121  -0.36514387]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(494660.97, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(7816.8164, shape=(), dtype=float32)\n",
            "Average reward in episode  21684 :  1712.2210693359375\n",
            "Final reward in episode  21684 :  1712.2211\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21684\n",
            "state:  tf.Tensor([[37.011818  8.951114]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.9672045  0.6381243]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(25119.268, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(1278.5461, shape=(), dtype=float32)\n",
            "Average reward in episode  21685 :  1932.9881591796875\n",
            "Final reward in episode  21685 :  1932.9882\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21685\n",
            "state:  tf.Tensor([[43.135452 26.567152]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.9481106  0.4214841]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(250954.75, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(16988.855, shape=(), dtype=float32)\n",
            "Average reward in episode  21686 :  1499.552978515625\n",
            "Final reward in episode  21686 :  1499.553\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21686\n",
            "state:  tf.Tensor([[63.037205 93.856255]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.70264083 -0.7192113 ]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-317429.6, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-9201.98, shape=(), dtype=float32)\n",
            "Average reward in episode  21687 :  1454.9464111328125\n",
            "Final reward in episode  21687 :  1454.9464\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21687\n",
            "state:  tf.Tensor([[59.741497 87.656006]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.7289063 -0.6625914]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-215465.56, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-9099.672, shape=(), dtype=float32)\n",
            "Average reward in episode  21688 :  1297.0416259765625\n",
            "Final reward in episode  21688 :  1297.0416\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21688\n",
            "state:  tf.Tensor([[2.9667372e-02 9.8357025e+01]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[ 0.00720514 -0.805081  ]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-691516.9, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-24511.29, shape=(), dtype=float32)\n",
            "Average reward in episode  21689 :  1396.9974365234375\n",
            "Final reward in episode  21689 :  1396.9974\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21689\n",
            "state:  tf.Tensor([[80.368225 22.29083 ]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.99006104  0.6137478 ]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-68163.99, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-14167.863, shape=(), dtype=float32)\n",
            "Average reward in episode  21690 :  1500.576171875\n",
            "Final reward in episode  21690 :  1500.5762\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21690\n",
            "state:  tf.Tensor([[49.74434 75.24141]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.7494829  -0.52882516]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(33962.016, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(13953.431, shape=(), dtype=float32)\n",
            "Average reward in episode  21691 :  1160.810302734375\n",
            "Final reward in episode  21691 :  1160.8103\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21691\n",
            "state:  tf.Tensor([[96.72351  26.101381]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.99329096  0.62504464]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-133352.9, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-11483.98, shape=(), dtype=float32)\n",
            "Average reward in episode  21692 :  2018.333251953125\n",
            "Final reward in episode  21692 :  2018.3333\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21692\n",
            "state:  tf.Tensor([[61.343166 59.720253]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.90919465 -0.1917552 ]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(64228.25, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(14980.244, shape=(), dtype=float32)\n",
            "Average reward in episode  21693 :  1170.3729248046875\n",
            "Final reward in episode  21693 :  1170.3729\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21693\n",
            "state:  tf.Tensor([[0.27170882 9.750956  ]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.8737609   0.41859552]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-326790.94, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-28839.316, shape=(), dtype=float32)\n",
            "Average reward in episode  21694 :  3944.360107421875\n",
            "Final reward in episode  21694 :  3944.36\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21694\n",
            "state:  tf.Tensor([[83.61281  67.629524]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.95035344 -0.24632621]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-407934.78, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-17339.781, shape=(), dtype=float32)\n",
            "Average reward in episode  21695 :  1679.638916015625\n",
            "Final reward in episode  21695 :  1679.6389\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21695\n",
            "state:  tf.Tensor([[46.088715 42.219757]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.915334    0.12533523]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(272306.88, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(15433.822, shape=(), dtype=float32)\n",
            "Average reward in episode  21696 :  1319.04052734375\n",
            "Final reward in episode  21696 :  1319.0405\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21696\n",
            "state:  tf.Tensor([[51.56229  76.325714]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.756767   -0.53614783]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(33819.234, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(11765.864, shape=(), dtype=float32)\n",
            "Average reward in episode  21697 :  1161.95166015625\n",
            "Final reward in episode  21697 :  1161.9517\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21697\n",
            "state:  tf.Tensor([[30.106144 46.869465]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.811669   -0.04743799]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(499738.8, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(11461.006, shape=(), dtype=float32)\n",
            "Average reward in episode  21698 :  1832.6512451171875\n",
            "Final reward in episode  21698 :  1832.6512\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21698\n",
            "state:  tf.Tensor([[49.052017 49.401455]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.9009872  -0.01275995]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(273189.3, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(15513.996, shape=(), dtype=float32)\n",
            "Average reward in episode  21699 :  1229.0794677734375\n",
            "Final reward in episode  21699 :  1229.0795\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21699\n",
            "state:  tf.Tensor([[72.01526 83.92032]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.85031915 -0.5701722 ]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-363606.06, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-15054.701, shape=(), dtype=float32)\n",
            "Average reward in episode  21700 :  1477.0579833984375\n",
            "Final reward in episode  21700 :  1477.058\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21700\n",
            "state:  tf.Tensor([[68.05547 45.57041]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.9612646   0.17236473]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-293923.34, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-19486.816, shape=(), dtype=float32)\n",
            "Average reward in episode  21701 :  1226.85400390625\n",
            "Final reward in episode  21701 :  1226.854\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21701\n",
            "state:  tf.Tensor([[56.1421   37.241882]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.9545566  0.2927311]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-60760.562, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-19946.754, shape=(), dtype=float32)\n",
            "Average reward in episode  21702 :  1170.0780029296875\n",
            "Final reward in episode  21702 :  1170.078\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21702\n",
            "state:  tf.Tensor([[66.22275  31.929836]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.9759255  0.430458 ]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-171484.86, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-19695.465, shape=(), dtype=float32)\n",
            "Average reward in episode  21703 :  1186.578369140625\n",
            "Final reward in episode  21703 :  1186.5784\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21703\n",
            "state:  tf.Tensor([[83.21165 91.24355]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.87325966 -0.6365071 ]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-424428.94, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-16172.101, shape=(), dtype=float32)\n",
            "Average reward in episode  21704 :  1829.44921875\n",
            "Final reward in episode  21704 :  1829.4492\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21704\n",
            "state:  tf.Tensor([[76.23042 94.40362]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.814087  -0.6918258]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-460595.8, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-14340.007, shape=(), dtype=float32)\n",
            "Average reward in episode  21705 :  1716.2236328125\n",
            "Final reward in episode  21705 :  1716.2236\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21705\n",
            "state:  tf.Tensor([[38.01994  30.872816]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.925843  0.323957]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(318700.38, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(16216.454, shape=(), dtype=float32)\n",
            "Average reward in episode  21706 :  1694.3843994140625\n",
            "Final reward in episode  21706 :  1694.3844\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21706\n",
            "state:  tf.Tensor([[16.462856 74.580696]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.41601294 -0.6293762 ]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-133961.81, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-2144.2004, shape=(), dtype=float32)\n",
            "Average reward in episode  21707 :  1561.939453125\n",
            "Final reward in episode  21707 :  1561.9395\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21707\n",
            "state:  tf.Tensor([[38.438267 66.20755 ]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.73327774 -0.43276718]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(432542.7, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(11282.361, shape=(), dtype=float32)\n",
            "Average reward in episode  21708 :  1311.7030029296875\n",
            "Final reward in episode  21708 :  1311.703\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21708\n",
            "state:  tf.Tensor([[43.587643   4.6740913]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.979273   0.6840119]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(36430.17, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(1527.8969, shape=(), dtype=float32)\n",
            "Average reward in episode  21709 :  1688.7689208984375\n",
            "Final reward in episode  21709 :  1688.7689\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21709\n",
            "state:  tf.Tensor([[23.820454 80.97474 ]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.41480088 -0.6812357 ]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-42492.99, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-1205.2906, shape=(), dtype=float32)\n",
            "Average reward in episode  21710 :  1265.706298828125\n",
            "Final reward in episode  21710 :  1265.7063\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21710\n",
            "state:  tf.Tensor([[46.661663 29.474709]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.950243   0.3724021]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(203296.3, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(16779.102, shape=(), dtype=float32)\n",
            "Average reward in episode  21711 :  1358.8897705078125\n",
            "Final reward in episode  21711 :  1358.8898\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21711\n",
            "state:  tf.Tensor([[71.36946  58.281593]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.9430754 -0.1287466]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-125917.016, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-17113.223, shape=(), dtype=float32)\n",
            "Average reward in episode  21712 :  1308.72412109375\n",
            "Final reward in episode  21712 :  1308.7241\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21712\n",
            "state:  tf.Tensor([[87.35398  97.878174]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.8587962  -0.71456045]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-393701.88, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-14584.824, shape=(), dtype=float32)\n",
            "Average reward in episode  21713 :  2001.99755859375\n",
            "Final reward in episode  21713 :  2001.9976\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21713\n",
            "state:  tf.Tensor([[ 0.11088115 31.177626  ]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.72889864  0.01229491]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-379830.06, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-11624.067, shape=(), dtype=float32)\n",
            "Average reward in episode  21714 :  3505.100341796875\n",
            "Final reward in episode  21714 :  3505.1003\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21714\n",
            "state:  tf.Tensor([[46.91532    5.0177517]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.9809917  0.6874029]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(96063.484, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(3882.73, shape=(), dtype=float32)\n",
            "Average reward in episode  21715 :  1543.0220947265625\n",
            "Final reward in episode  21715 :  1543.0221\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21715\n",
            "state:  tf.Tensor([[85.19066 71.02395]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.9457636  -0.32924765]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-321785.78, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-17457.422, shape=(), dtype=float32)\n",
            "Average reward in episode  21716 :  1730.580078125\n",
            "Final reward in episode  21716 :  1730.5801\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21716\n",
            "state:  tf.Tensor([[ 2.5747876 85.89079  ]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.12183937 -0.7614599 ]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-646225.8, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-16810.98, shape=(), dtype=float32)\n",
            "Average reward in episode  21717 :  1495.379150390625\n",
            "Final reward in episode  21717 :  1495.3792\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21717\n",
            "state:  tf.Tensor([[22.66672  35.990643]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.8262675   0.13276854]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(539809.9, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(13530.627, shape=(), dtype=float32)\n",
            "Average reward in episode  21718 :  2299.7685546875\n",
            "Final reward in episode  21718 :  2299.7686\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21718\n",
            "state:  tf.Tensor([[54.224415 46.142902]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.9265777  0.0508965]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(262770.7, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(16647.807, shape=(), dtype=float32)\n",
            "Average reward in episode  21719 :  1179.561279296875\n",
            "Final reward in episode  21719 :  1179.5613\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21719\n",
            "state:  tf.Tensor([[18.303558 68.553635]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.4794592  -0.54880893]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(19776.016, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(310.28906, shape=(), dtype=float32)\n",
            "Average reward in episode  21720 :  1653.1641845703125\n",
            "Final reward in episode  21720 :  1653.1642\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21720\n",
            "state:  tf.Tensor([[48.670277 45.56495 ]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.9079614  0.0443821]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(311185.1, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(16093.498, shape=(), dtype=float32)\n",
            "Average reward in episode  21721 :  1249.9398193359375\n",
            "Final reward in episode  21721 :  1249.9398\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21721\n",
            "state:  tf.Tensor([[33.43963 56.43295]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.7510172  -0.25844705]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(619751.94, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(11117.663, shape=(), dtype=float32)\n",
            "Average reward in episode  21722 :  1536.4619140625\n",
            "Final reward in episode  21722 :  1536.4619\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21722\n",
            "state:  tf.Tensor([[11.007323 86.57086 ]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.155957  -0.7503497]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-291869.0, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-12221.662, shape=(), dtype=float32)\n",
            "Average reward in episode  21723 :  1256.450927734375\n",
            "Final reward in episode  21723 :  1256.4509\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21723\n",
            "state:  tf.Tensor([[ 2.4059167 18.825592 ]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.81743735  0.29430178]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-365074.12, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-20283.229, shape=(), dtype=float32)\n",
            "Average reward in episode  21724 :  3597.43115234375\n",
            "Final reward in episode  21724 :  3597.4312\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21724\n",
            "state:  tf.Tensor([[50.044075 54.136005]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.87046814 -0.11629596]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(279169.3, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(15619.909, shape=(), dtype=float32)\n",
            "Average reward in episode  21725 :  1193.865966796875\n",
            "Final reward in episode  21725 :  1193.866\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21725\n",
            "state:  tf.Tensor([[72.95154  59.081554]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.93692887 -0.10371085]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-278291.72, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-19047.285, shape=(), dtype=float32)\n",
            "Average reward in episode  21726 :  1366.32568359375\n",
            "Final reward in episode  21726 :  1366.3257\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21726\n",
            "state:  tf.Tensor([[ 9.118884 56.851936]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.4810435  -0.37755018]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-257830.19, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-3831.6716, shape=(), dtype=float32)\n",
            "Average reward in episode  21727 :  2180.307861328125\n",
            "Final reward in episode  21727 :  2180.3079\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21727\n",
            "state:  tf.Tensor([[38.74005  34.184494]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.9008469  0.2861951]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(238746.1, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(11943.766, shape=(), dtype=float32)\n",
            "Average reward in episode  21728 :  1589.8521728515625\n",
            "Final reward in episode  21728 :  1589.8522\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21728\n",
            "state:  tf.Tensor([[22.685207 28.716488]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.84482646  0.32917532]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(153420.81, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(5209.5586, shape=(), dtype=float32)\n",
            "Average reward in episode  21729 :  2324.841796875\n",
            "Final reward in episode  21729 :  2324.8418\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21729\n",
            "state:  tf.Tensor([[25.885214 52.753696]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.6780487 -0.1706521]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(413240.3, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(7176.0566, shape=(), dtype=float32)\n",
            "Average reward in episode  21730 :  1715.991943359375\n",
            "Final reward in episode  21730 :  1715.992\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21730\n",
            "state:  tf.Tensor([[ 3.6271465 18.983004 ]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.7993373   0.33649623]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-402695.4, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-25778.812, shape=(), dtype=float32)\n",
            "Average reward in episode  21731 :  3433.86083984375\n",
            "Final reward in episode  21731 :  3433.8608\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21731\n",
            "state:  tf.Tensor([[ 2.610489 83.41689 ]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.02440385 -0.71456516]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-398735.06, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-14685.566, shape=(), dtype=float32)\n",
            "Average reward in episode  21732 :  1313.6317138671875\n",
            "Final reward in episode  21732 :  1313.6317\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21732\n",
            "state:  tf.Tensor([[66.49607  41.728863]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.9524558   0.27744123]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-331780.3, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-19749.363, shape=(), dtype=float32)\n",
            "Average reward in episode  21733 :  1217.3857421875\n",
            "Final reward in episode  21733 :  1217.3857\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21733\n",
            "state:  tf.Tensor([[37.03407  18.096163]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.935562   0.5874648]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(182786.25, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(13229.459, shape=(), dtype=float32)\n",
            "Average reward in episode  21734 :  1767.4298095703125\n",
            "Final reward in episode  21734 :  1767.4298\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21734\n",
            "state:  tf.Tensor([[46.705807   8.0740185]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.9703747   0.70401347]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(101359.14, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(5369.4517, shape=(), dtype=float32)\n",
            "Average reward in episode  21735 :  1449.883056640625\n",
            "Final reward in episode  21735 :  1449.883\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21735\n",
            "state:  tf.Tensor([[88.62603  80.827034]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.90153974 -0.4198625 ]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-498966.38, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-16802.646, shape=(), dtype=float32)\n",
            "Average reward in episode  21736 :  1947.747802734375\n",
            "Final reward in episode  21736 :  1947.7478\n",
            "------------------------------------------------------------------------------\n",
            "\n",
            "iteration  21736\n",
            "state:  tf.Tensor([[68.160416 24.18925 ]], shape=(1, 2), dtype=float32)\n",
            "action:  tf.Tensor([[-0.97571534  0.5913215 ]], shape=(1, 2), dtype=float32)\n",
            "gradient:  tf.Tensor(-119291.805, shape=(), dtype=float32)\n",
            "clipped gradient:  tf.Tensor(-18768.914, shape=(), dtype=float32)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-78-c225a2f65787>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;31m# grads = [tf.clip_by_value(grad, -1., 1.) for grad in grads]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"clipped gradient: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0mnetwork_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m         \u001b[0mdone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_experimental/optimizer.py\u001b[0m in \u001b[0;36mapply_gradients\u001b[0;34m(self, grads_and_vars, name, skip_gradients_aggregation, **kwargs)\u001b[0m\n\u001b[1;32m   1138\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mskip_gradients_aggregation\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mexperimental_aggregate_gradients\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m             \u001b[0mgrads_and_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maggregate_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1140\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply_weight_decay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_experimental/optimizer.py\u001b[0m in \u001b[0;36mapply_gradients\u001b[0;34m(self, grads_and_vars, name)\u001b[0m\n\u001b[1;32m    632\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_weight_decay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0mgrads_and_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m         \u001b[0miteration\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_internal_apply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m         \u001b[0;31m# Apply variable constraints after applying gradients.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_experimental/optimizer.py\u001b[0m in \u001b[0;36m_internal_apply_gradients\u001b[0;34m(self, grads_and_vars)\u001b[0m\n\u001b[1;32m   1164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1165\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_internal_apply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1166\u001b[0;31m         return tf.__internal__.distribute.interim.maybe_merge_call(\n\u001b[0m\u001b[1;32m   1167\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_distributed_apply_gradients_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_distribution_strategy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/merge_call_interim.py\u001b[0m in \u001b[0;36mmaybe_merge_call\u001b[0;34m(fn, strategy, *args, **kwargs)\u001b[0m\n\u001b[1;32m     49\u001b[0m   \"\"\"\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mstrategy_supports_no_merge_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     return distribution_strategy_context.get_replica_context().merge_call(\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_experimental/optimizer.py\u001b[0m in \u001b[0;36m_distributed_apply_gradients_fn\u001b[0;34m(self, distribution, grads_and_vars, **kwargs)\u001b[0m\n\u001b[1;32m   1214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m             distribution.extended.update(\n\u001b[0m\u001b[1;32m   1217\u001b[0m                 \u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_grad_to_update_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[1;32m   2635\u001b[0m           fn, autograph_ctx.control_status_ctx(), convert_by_default=False)\n\u001b[1;32m   2636\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2637\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2638\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2639\u001b[0m       return self._replica_ctx_update(\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_update\u001b[0;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[1;32m   3708\u001b[0m     \u001b[0;31m# The implementations of _update() and _update_non_slot() are identical\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3709\u001b[0m     \u001b[0;31m# except _update() passes `var` as the first argument to `fn()`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3710\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_non_slot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3711\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3712\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_update_non_slot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolocate_with\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshould_group\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_update_non_slot\u001b[0;34m(self, colocate_with, fn, args, kwargs, should_group)\u001b[0m\n\u001b[1;32m   3714\u001b[0m     \u001b[0;31m# once that value is used for something.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3715\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mUpdateContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolocate_with\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3716\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3717\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mshould_group\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3718\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    593\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mControlStatusCtx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUNSPECIFIED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 595\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    596\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mismethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_experimental/optimizer.py\u001b[0m in \u001b[0;36mapply_grad_to_update_var\u001b[0;34m(var, grad)\u001b[0m\n\u001b[1;32m   1209\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mapply_grad_to_update_var\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1210\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit_compile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1211\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_step_xla\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_var_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1212\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1213\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    918\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 919\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    920\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mALLOW_DYNAMIC_VARIABLE_CREATION\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    921\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    133\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m    134\u001b[0m     return concrete_function._call_flat(\n\u001b[0;32m--> 135\u001b[0;31m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36mcaptured_inputs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1947\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0mpasses\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1948\u001b[0m     \"\"\"\n\u001b[0;32m-> 1949\u001b[0;31m     return nest.flatten(\n\u001b[0m\u001b[1;32m   1950\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_captured_inputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1951\u001b[0m         expand_composites=True)\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mflatten\u001b[0;34m(structure, expand_composites)\u001b[0m\n\u001b[1;32m    452\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m   \u001b[0mexpand_composites\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpand_composites\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_pywrap_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFlatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstructure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpand_composites\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "env.reset()\n",
        "tf_state = tf.convert_to_tensor([env.current_state], dtype=tf.float32)\n",
        "tf_action = network(tf_state)\n",
        "position_action_list = []\n",
        "action = tf_action.numpy().flatten()\n",
        "print(\"action: \", action)\n",
        "position_action_list.append((tf_state.numpy().flatten(), action))\n",
        "env.render(learnt_policy_visualization = True, position_action_list = position_action_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 638
        },
        "id": "i1_AdCwB4qt-",
        "outputId": "78f85001-0663-4d32-e706-4f36db64e06c"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "action:  [-0.9029289  0.6204005]\n",
            "scaled action:  [-44.24351555  30.39962393]\n",
            "previous state:  [10.561802  2.212719] , new state:  [ 0.         32.61234289]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1440x720 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABJoAAAJDCAYAAABDiH5bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdf3ycZ3nv+e8l27E1iZOAk3gjOTMTKJCTDWCKwWA4rWOyh8BCYxfIJjvQNAWm3YUeds8uqjiz/CoMRytYOGWX9nUGCgSYxhA4VikNpeSHA6cGl9AGGhJYODCjWEpsxz9lj2RZ0nX+eGbESJZsjTQzz8wzn/frNVhzzzPPc80j2a/oy31ft7m7AAAAAAAAgJXqCrsAAAAAAAAARANBEwAAAAAAAOqCoAkAAAAAAAB1QdAEAAAAAACAuiBoAgAAAAAAQF0QNAEAAAAAAKAuCJoAAAAiysw+a2aHzOzRRV43M/ukmf3CzH5sZr/Z7BoBAEC0EDQBAABE1+cl3Xye118j6TnlR1rSXzShJgAAEGEETQAAABHl7t+RdPQ8h9wi6Qse+L6ky83s6uZUBwAAooigCQAAoHP1Snqi6vmB8hgAAMCyrA67AAAAALQ+M0srWF6niy+++MXXXXddyBUBAIBG+eEPf/i0u1+5nPcSNAEAAHSuEUnXVD3fVB47h7vnJOUkacuWLf7www83vjoAABAKMysu970snQPQFGb2+2b2X8Kuo6LV6gGAkHxd0u+Vd597maQT7v5k2EUBAID2RdAEoOWYWdLM3MzunTf+JTP7wBLP4Wb2Gw0pEADahJndLel7kp5nZgfM7K1m9kdm9kflQ+6V9EtJv5D0aUn/a0ilAgCAiGDpHBBhZrba3afa+LpbzWybu++rw7kAoOO4++0XeN0lvaNJ5QAAgA7AjCYgYsysYGZ/YmY/lnTazFab2cvMbJ+ZHTezH5nZ9vKxN5rZv1S999tm9oOq5981s53lr/vN7L+a2ZiZPWZmu6qO+30z+wcz+4SZHZH0ATPbYGZfN7OTZvaPkp69jI8zKCl7ns/6djP7hZkdLV+rpzz+nfIhPzKzU2b2P13oQmb2UTP7L2Z2WWVZnZl9zMyOmdmvzOw1Vcf2lK93tHz9t5fH15nZuJldUX6eMbMpM7u0/PxDZvYfy19/3sw+ZWZ/W76n+81sOfcIAAAAAFoGQRMQTbdL+h8lXS5po6S/lfRhSc+U9H9K+pqZXSnp+5KeY2ZXmNkaSS+Q1GNm682sW9IWSd8tn/O/SvrXki6T9EFJXzKzq6uuuVXB8ouNCsKhT0makHS1pD8oP2aZ2TfMrP8Cn+PPJT3XzG6a/4KZ7ZD0HyTdWr5GUdJuSXL33yof9kJ3v8Tdv7zYBcysy8w+Xf7s/8bdT1R9np9JukJB4PWXZmbl13Yr2AK8R9IbJX3EzHa4+4SkH0j67fJxv12u6xVVzx+quvxtCu7lMxQsW1k0VAMAAACAdkDQBETTJ939CXcfl/RmSfe6+73uPuPu35b0sKTXll//gaTfkvRiST+S9A8KgpGXSfq5ux+RJHe/x91Hy+f4sqSfS3pp1TVH3f3/LS+Zm5T0Bknvc/fT7v6opLuqC3T317n7wAU+x7iC8OXDC7yWkvRZd/8ndz8j6T2SXm5myaXdIknSGkl3KwjgXu/uparXiu7+aXefLtd+taSNZnaNgvvzJ+4+4e6PSPqMpN8rv+8hSb9tZqsVhFefLD9fJ+klkr5TdY097v6P5XuWl7S5htoBAAAAoOUQNAHR9ETV1wlJbyovmztuZsclvVJBcCIFwch2BWHTQ5L2Kph5M2f2jZn9npk9UnWOGxTM9lnomlcq6AFXPbbc7TE/oyDgef288Z7qc7r7KUlHJPXWcO7fkHSLpA+6++S8156qOnclgLqkfN2j7j5WdWyx6rqV+/mbkv5F0rcV3MuXSfpFJbibfw1JpfL5AQAAAKBtETQB0eRVXz8h6YvufnnV4+Kq2UTzg6aHNC9oMrOEgt2I3ilpg7tfLulRSVZ1neprHpY0JemaqrH4sj5IEAB9UNKH5l1vVEGIpnKNF0vaIGmkhtM/LulOSd80s+ct8T2jkp5pZuurxuJV190n6XmSdkl6yN0fK7/+Ws1dNgcAAAAAkUPQBETflyS93sxebWaryg2rt5vZpvLrlWDkpZL+0d1/oiDA2apfL/O6WEGQdFiSzOxOBTOaFlRebvafFTQFj5nZ9ZLuWMFn+KKkdZJurhq7W9KdZrbZzNZK+oik/e5eKL9+UNKzLnRid79b0r+XdN9SmnG7+xMK7tl/KN/LF0h6q4L7XJn99EMFuzhVgqV9kv5IBE0AAAAAIo6gCYi4cjByi4Iw5bCCGU7vVvnvv7uflvRPkn5StXzsewp6FB0qH/OYpP+nPH5Q0vMV9HI6n3cqWAr2lKTPS/pc9Ytm9k0z+/dL/AzTkt6noJdSZew+Se+V9DVJTyrY1e62qrd9QNJd5aV+t17g/HdJ+lNJDyyxx9PtkpIKZjftkfT+cj0VDyno//SPVc/Xa25/JgAAAACIHHP3Cx8FAAAAlG3ZssUffvjhsMsAAAANYmY/dPcty3kvM5oAAAAAAABQFwRNAAAAAAAAqAuCJgAAAAAAANQFQRMAAAAAAADqgqAJAAAAAAAAdbE67AJW4oorrvBkMtmQc58+fVoXX3xxQ86Nc3G/m4973lzc7+bifjdXI+/3D3/4w6fd/cqGnBwAAAB119ZBUzKZVKO21t27d6+2b9/ekHPjXNzv5uOeNxf3u7m4383VyPttZsWGnBgAAAANwdI5AAAAAAAA1AVBEwAAAAAAAOqCoAkAAAAAAAB10dY9mgAA6CRnz57VgQMHNDExEXYpc1x22WV6/PHHV3SOdevWadOmTVqzZk2dqgIAAEAYCJoAAGgTBw4c0Pr165VMJmVmYZcza2xsTOvXr1/2+91dR44c0YEDB3TttdfWsTIAAAA0G0vnAABoExMTE9qwYUNLhUz1YGbasGFDy83UAgAAQO0ImgAAaCNRC5kqovq5AAAAOg1L5wAAwJIVCgW97nWv06OPPjo79pGPfEQbNmzQo48+qoceekiXXXaZJCkWi2nfvn1hlQoAAIAQEDQBAIC6+ehHP6o3vvGNYZcBAACAkLB0DgCAiMrn80omk+rq6lIymVQ+nw+7JAAAAEQcQRMAABGUz+eVTqdVLBbl7ioWi0qn0w0Pm9797ndr8+bN2rx5s1KpVEOvBQAAgNbD0jkAACIok8moVCrNGSuVSspkMisKgBZr2l0ZZ+kcAABAZ2NGEwAAETQ8PFzT+FJt2LBBx44dmzN27NgxXXHFFSs6LwAAAKKBoAkAgAiKx+M1jS/VJZdcoquvvloPPPCAJOno0aO677779MpXvnJF5wUAAEA0EDQBABBB2WxWsVhszlgsFlM2m13xub/whS/oQx/6kDZv3qwdO3aov79fz372syXN7dG0efNmTU5Orvh6AAAAaB/0aAIAIIIqfZgymYyGh4cVj8eVzWbr0qD7+uuv14MPPjj7fGxsTJL0+c9/fsXnBgAAQHsjaAIAIKJSqRQ7vwEAAKCpGrZ0zsw+a2aHzOzRqrFnmtm3zezn5T+fUR43M/ukmf3CzH5sZr/ZqLoAAAAAAADQGI3s0fR5STfPG+uXdL+7P0fS/eXnkvQaSc8pP9KS/qKBdQEAAAAAAKABGhY0uft3JB2dN3yLpLvKX98laWfV+Bc88H1Jl5vZ1Y2qDQAAAAAAAPXX7F3nNrr7k+Wvn5K0sfx1r6Qnqo47UB4DAAAAAABAmwitGbi7u5l5re8zs7SC5XXauHGj9u7dW+/SJEmnTp1q2LlxLu5383HPm4v73VxRvd+XXXbZ7A5vrWR6eroudU1MTETy+wYAANBJmh00HTSzq939yfLSuEPl8RFJ11Qdt6k8dg53z0nKSdKWLVt8+/btDSl07969atS5cS7ud/Nxz5uL+91cUb3fjz/+uNavX1/bmx58ULrzTulzn5NuvHHFNaxatUrPf/7zZ5/fdtttesc73qF169bpve99r772ta9p/fr1Wrt2rd73vvfpNa95zZLPvW7dOr3oRS9acY0AAAAIT7ODpq9LukPSQPnPv64af6eZ7Za0VdKJqiV2AABgOR58UHrd66RSKfjzG99YcdjU3d2tRx55ZM7Y2NiY3vve9+rJJ5/Uo48+qrVr1+rgwYN66KGHVnQtAAAAtJ+GBU1mdrek7ZKuMLMDkt6vIGD6ipm9VVJR0q3lw++V9FpJv5BUknRno+oCAKAjVIdMUl3DpvlKpZI+/elP61e/+pXWrl0rKVjefuutt17gnQAAAIiahgVN7n77Ii+9aoFjXdI7GlULAAAdZX7IVFGHsGl8fFybN2+eff6e97xH8Xhc8Xhcl1566UqqBgAAQASE1gwcAAA0wGIhU8UKw6aFls5973vfW06lAAAAiKCusAsAAAB1dOedi4dMFaVScFydPOtZz9Lw8LBOnjxZt3MCAACgPRE0AQAQJZ/7nBSLnf+YWCw4rk5isZje+ta36l3vepcmJyclSYcPH9Y999xTt2sAAACgPRA0AQAQJTfeGCyLWyxsisXq0qOp8ujv75ckffjDH9aVV16p66+/XjfccINe97rX0bMJAACgA9GjCQCAqKmETfN7Na0wZJKk6enpc8bGxsZ00UUXaXBwUIODg8s+NwAAANofM5oAAIii+TOb6hAyAQAAABdC0AQAQFRVwqZEgpAJAAAATcHSOQAAouzGG6VCIewqAAAA0CGY0QQAAAAAAIC6IGgCAAAAAABAXRA0AQAAAAAAoC4ImgAAwJIVCgXdcMMNc8Y+8pGP6GMf+5gkaWpqSldeeaX6+/tnj9+0aZNmZmbmvGfz5s3av39/c4oGAABA0xA0AQAQMYOD0oMPLv76gw8GxzTCt7/9bT33uc/VPffcI3dXMplUPB7Xd7/73dljfvrTn2psbExbt25tTBEAAAAIDUETAAAR85KXSLfeunDY9OCDwWsveUljrn333XfrXe96l+LxuL73ve9Jkm6//Xbt3r179pjdu3frtttua0wBAAAACBVBEwAAEXPjjdJXvnJu2FQJmb7yleCYepuYmNB9992n17/+9br99tt19913S5JuvfVWDQ0NaWpqSpL05S9/Wbfffnv9CwAAAEDoCJoAAIig+WFTvUImM1t0/Bvf+IZuvPFGdXd36w1veIOGhoY0PT2tjRs36oYbbtD999+vRx55RKtXrz6nzxMAAACigaAJAJrgvvvuUzKZVFdXl5LJpPL5fNgloQNUwqYdO4JHPWYybdiwQceOHZszduzYMV1xxRW6++67Z3/WX/ziF+vIkSN64IEHJP16+dzu3buZzQQAABBhBE0A0GD5fF4f+9jHVCwW5e4qFotKp9OETWhLl1xyia6++urZAOno0aO67777tHnzZn33u9/V8PCwCoWCCoWCPvWpT80un/vd3/1d3Xvvvfryl79MfyYAAIAII2gCgAbLZDI6c+bMnLFSqaRMJhNSRegUleVyDzwQPBZrEF6rL3zhC/rQhz6kzZs3a8eOHerv79cjjzyiHTt2aO3atbPH3XLLLfqbv/kbnTlzRpdffrle/vKXa+PGjXrWs5618iIAAADQklaHXQAARN3w8HBN40A9LNSTqdKzaaVL6K6//no9WJVYjY2Naf369brjjjvmHPfMZz5Thw8fnn0+NDS0/IsCAACgLTCjCQAaLB6P1zQOrNRijb8X240OAAAAqBeCJiwqn8/TvBiog2w2O2c5kSTFYjFls9mQKkLU/eAHi89aqoRNP/hB8+sCAABA9LF0DgvK5/NKp9MqlUqSNNu8WJJSqVSYpQFtJ5VK6fHHH9eXvvQlDQ8PKx6PK5vN8ncJDdPXd/7Xb7xx5bvPAQAAAAthRhMWlMlkZkOmCpoXA8t30003qVAoaGZmRoVCgZAJy+buYZfQEFH9XAAAAJ2GoAkLonkxALSedevW6ciRI5ELZdxdR44c0bp168IuBQAAACvE0jksKB6Pq1gsLjgOAAjHpk2bdODAgTk7ubWCiYmJFYdE69at06ZNm+pUEQAAAMJC0IQFZbPZOT2aJJoXA0DY1qxZo2uvvTbsMs6xd+9evehFLwq7DAAAALQAls5hQalUSrlcTolEQmamRCKhXC5HXxkAAAAAALAoZjRhUalUimAJAAAAAAAsGTOaAAAAAAAAUBcETQAAAAAAAKgLgiYAAAAAAADUBUETAAAAAAAA6oKgCS0jn88rmUyqq6tLyWRS+Xw+7JIAAAAAAEAN2HUOLeG+++7TJz7xCZVKJUlSsVhUOp2WJHa+AwAAAACgTTCjCS3hM5/5zGzIVFEqlZTJZEKqCAAAAAAA1IqgCS3h0KFDC44PDw83uRIAAAAAALBcBE1oCVddddWC4/F4vMmVAED46FkHAACAdkXQhJbwtre9TbFYbM5YLBZTNpsNqSIACEc+n1c6nVaxWJS7z/asI2wCAABAOyBoQku46aablMvllEgkZGZKJBLK5XI0AgfQcTKZDD3rAAAA0LbYdQ4tI5VKESwB6HiL9aajZx0AAADaATOaAABoIYv1pqNnHQAAANoBQRMAAC0km83Ssw4AAABti6AJAIAWkkql6FkHAACAtkWPJgAAWgw96wAAANCumNEEAAAAAACAuiBoAgAAAAAAQF0QNAEAAAAAAKAuCJoAAAAAAABQFwRNAAAAAAAAqAuCJgAAAAAAANQFQRMAAAAAAADqgqAJAAAAAAAAdUHQBAAAAAAAgLogaAIAAAAAAEBdEDQBAAAAAACgLgiaAAAAAAAAUBcETQAAAAAAAKgLgiYAAAAAAADUBUETAABAhJnZzWb2MzP7hZn1L/B63MweNLN/NrMfm9lrw6gTAABEA0ETAABARJnZKkmfkvQaSddLut3Mrp932P8l6Svu/iJJt0n68+ZWCQAAooSgCQAAILpeKukX7v5Ld5+UtFvSLfOOcUmXlr++TNJoE+sDAAARszrsAgAAANAwvZKeqHp+QNLWecd8QNLfm9kfS7pY0k3NKQ0AAEQRM5oAAAA62+2SPu/umyS9VtIXzeyc/0Y0s7SZPWxmDx8+fLjpRQIAgPZA0AQAABBdI5KuqXq+qTxW7a2SviJJ7v49SeskXTH/RO6ec/ct7r7lyiuvbFC5AACg3RE0AQAARNcPJD3HzK41s4sUNPv++rxjhiW9SpLM7F8pCJqYsgQAAJaFoAkAACCi3H1K0jslfUvS4wp2l/uJmf2pmf1O+bD/Q9LbzexHku6W9Pvu7uFUDAAA2h3NwAEAACLM3e+VdO+8sfdVff2YpFc0uy4AABBNzGhqcfl8XslkUl1dXUomk8rn82GXBAAAAAAAsCBmNLWwfD6vdDqtUqkkSSoWi0qn05KkVCoVZmkAAAAAAADnYEZTC8tkMrMhU0WpVFImkwmpIgAAAAAAgMURNLWw4eHhmsYBAAAAAADCRNDUwuLxeE3jAAAAAAAAYSJoamHZbFaxWGzOWCwWUzabbfi1aUIOAAAAAABqRdDUwlKplHK5nBKJhMxMiURCuVyu4Y3AK03Ii8Wi3H22CTlhEwAAAAAAOB+CphaXSqVUKBQ0MzOjQqHQlN3maEIOAAAAAACWg6AJ56AJOQAAAAAAWA6CpjqKSl8jmpADAAAAAIDlIGiqkyj1NQqzCTkAAAAAAGhfBE11EqW+RmE1IQcAAAAAAO2NoKlOotbXKIwm5OcTlWWJAAAAAABEGUFTndDXqHGitCwRAAAAAIAoI2iqE/oaNU6UliUCAAAAABBlBE11Ql+jxonaskQAAAAAAKJqdRgXNbP/XdLbJLmkf5F0p6SrJe2WtEHSDyW9xd0nw6hvuVKpFMFSA8TjcRWLxQXHAQAAAABA62j6jCYz65X0byVtcfcbJK2SdJuk/1vSJ9z9NyQdk/TWZteG1sSyRAAAAAAA2kNYS+dWS+o2s9WSYpKelLRD0lfLr98laWdItaHFsCwRAAAAAID20PSlc+4+YmYfkzQsaVzS3ytYKnfc3afKhx2Q1Nvs2tC6WJYIAAAAAEDra3rQZGbPkHSLpGslHZd0j6Sba3h/WlJakjZu3Ki9e/c2oErp1KlTDTs3zsX9bj7ueXNxv5uL+91c3G8AAABUhNEM/CZJv3L3w5JkZv9Z0iskXW5mq8uzmjZJGlnoze6ek5STpC1btvj27dsbUuTevXvVqHPjXNzv5uOeNxf3u7m4383F/QYAAEBFGD2ahiW9zMxiZmaSXiXpMUkPSnpj+Zg7JP11CLV1lpkZaXq6/JiSpqakqbPS2bPS2cny42wwNjUVHFM5fmZGcg/7EwAAAAAAgBYSRo+m/Wb2VUn/JGlK0j8rmKH0t5J2m9mHy2N/2ezaIsE9eExPSzPT5wZJlfGZmao3mWRLPf/s/wS6uoLHqlXSqtXS6tVS16ry81XB111dki31AgAAAAAAoF2FsXRO7v5+Se+fN/xLSS8NoZz24x6ERmcnpckzCwdI1cHOBWce+ZzsqCYzM8FjakrSmcWvbV3SqkogtUa66KLgsXoNIRQAAAAAABERStCEGswPlSbPBMvZKuHMYiFSmMvaFrq2z0hTVYHUeFX9q1cHQdnpU4RPAAAAAAC0MYKmVlJLqNTu/ZGq65+aCmZjnTj269dWr5YuWlt+ED4BAAAAANAOCJrC5B402h4vSRPj0Q2Vlmp++DQ1FdybymurV0tr10ndsSCAIngCAAAAAKClhLHrXGdzD0KlY0ekJ0ekwwelsZNByFR5vVOCpaWovh9TU8HyuiOHpScPBH+Ol+Y1NgfQ6fL5vG677TZ1dXUpmUwqn8+HXRIAAADQMQiammF6Wiqdlp4+JI0+IR19OnjuM4RKy1EJn2YDuwPSoaekU2PlHlAAOlU+n1c6ndbBgwfl7ioWi0qn020TNuXzeSWTSUIyAAAAtC2CpkaZOiuNnZAOPik9NSIdPyqdmQhe6+BwKb9nSMmt29R1TVLJrduU3zO0shNW7uXZSenkcengqPTUqHTiuDQ52dH3GuhEmUxGpVJpzlipVFImkwmpoqWrhGTFYrEtQzIAAABAokdTfU1OSqVT0vj4ubOVCDyU3zOkdF+/SuPjkqTiyIjSff2SpN7nXbfyC1Tu8fSUdOqkdHoseL4uJl18MX2dgA4wPDxc03grOV9IlkqlQqoKAAAAqA0zmlbKPVgGd3BUevpg0ENoZppgaQGZgcHZkKmiND6uzMBgYy5YWWI3fjro5/TUaNAPi55OQGTF4/GaxltJO4dkAAAAQAVB03JNTUnHjwX9gY4fDZ4TLp3X8OhoTeN15R4EgGMngu/Z0aeDGWgAIiWbzSoWi80Zi8ViymazIVW0dO0ckgEAAAAVBE21qDSgPnwwmMF0eoxd4moQ7+lZcPyZl1+u2978lvr1bTqfyvdqvBTMQDs4Wm7MzvcQiIJUKqVcLqeNGzfKzJRIJJTL5dpi6Vk7h2QAAABABUHTUkxPSydPBE29jz4tTZ4Ju6K2lO3vU6y7e87YRWvW6OSpUzp46FDQ/Lbct6mhYVOFe3lm2tHyzLRjLb1rHbtRAUuTSqW0e/duzczMqFAotEXIJP06JEskEm0XkgEAAAAVNAM/n8kzQU+fiXFJJolZLyuR2rVTUtCraXh0VPGeHp06fVpHjh+fc1ylb1Pl+IarzGY6PRY8Llorrb9UWruuZZqHV3ajqjQKruxGJYlfQoEISaVS/J0GAABAW2NG03zuwbKqqbPS04fKIZNEyFQfqV07Vdi/TzNPFFTYv09HT5xY8Lim9G1azOSZYObaUyPSqbGWWFbXzlu2AwAAAAA6B0FTtTMT0qGnpGNH6L3UJIv1bVpsvGncg93pTh4PdqsLuY8Tu1GFj6WLAAAAAHBhBE2SdHYyaPB95HAwk4mAqWkW6tsU6+5Wtr8vpIrmqexWd/yodOhJaWIilDLYjSpclaWLxWIx6CVWXrpI2AQAAAAAc3V20DQ1FYRLhw4Gy6UImJoutWuncoMD2njVVUHz295e5QYHmtefaakqjcOPHg5mvTW5ITy7UYWLpYsAAAAAsDSd2Qy8sotc6VTYlUBB2NT7vOu0/frrwi7lwtzLM+AOSWvXSpc9Q1qzpuGXrTQHzmQyGh4eVjweVzabpWlwk7B0EQAAAACWprOCppkZaeyEdPoUs5ewQv7rnl7d3dJll0urGvvXid2owhOPx1UsFhccBwAAAAD8WmcsnXOXxk6WdxEjZEI9lXcpfOpJ6fixIMxE5ERx6SLNzQEAAAA0QvSDponxIGAaO1EOmAiZ0AgunR4rh5ljhJkRk0qllMvllEgkgl5iiYRyuVzbzjCjuTkAAACARolu0DQzIx19OnjMzPCLP5rDXTp5PNjFcGoq7GpQR6lUSoVCQTMzMyoUCm0bMkk0NwcAAADQONHs0TQxLh09IjnLmBCCSsPwQ09Kl14uXXyJZBZ2VcAsmpsDAAAAaJRozWiqnsVEyISwMbsJLWqxJuY0NwcAAACwUtEJmibGpadGg8bMLJOLlPyeISW3blPXNUklt25Tfs9Q2CUtXfXsJno3oUVEsbk5AAAAgNbQ/kETs5giLb9nSOm+fhVHRoKmxSMjSvf1t1fYJDG7qcV12g5sUWtuDgAAAKB1tHePJp8JZjERMEVWZmBQpfHxOWOl8XFlBgaV2rUzpKqWid5NLamyA1ulOXZlBzZJkQ5eUqlUpD8fAAAAgHC094ymqSlCpogbHh2tabwtMLuppbADGwAAAADUT3sHTYi8eE9PTeNto3p20+mxsKvpaOzABgAAAAD1Q9CERYXZhLty7eLIiGze8rJYd7ey/X1Nq6Wh3KUTx6VjR2gUHhJ2YAMAAACA+iFowoLCbMJdfW1JcvfZsCnR26vc4ED79Wc6H3epVAqW0k1Ph11Nx2EHNgAAAACoH4ImLOh8TbjDuLa7K9Hbq8L+fdEKmWZVLaU7Oxl2MR2FHdgAAAAAoH7ae9c5NEyYTbgj2QB8qWZmgplNz9ggdccufDzqgh3YAAAAAKA+mNGEBYXZhDuyDcCXyl06ekQ6eYK+TQAAAACAtkLQhAVl+/sU6+6eM9asJtxhXrt1uHTqpHT0cGweM0YAACAASURBVDDLCQAAAACANkDQhAWldu1UbnBAid7eoG9NE5twh3ntluIuTZyRDj8lTU2FXQ0AAAAAABdEj6Zlyu8ZUmZgUMOjo4r39Cjb3xe5ICS1a2donynMa7cWD0KmQ09KG66S1q4NuyAAAAAAABZF0LQM+T1DSvf1z+6MVhwZUbqvX5IIR9AY7tKRQ9Jll0sXrw+7GgAAAAAAFsTSuWXIDAzOhkwVpfFxZQYGQ6oIHcFdOnFcOnk87EoAAAAAAFgQQdMyDI+O1jQO1I27dGpMOnGMHenQ9vL5vJLJpLq6upRMJpXP58MuCQAAAMAKETQtQ7ynp6ZxoK7cpdOnCJvQ1vL5vNLptIrFotxdxWJR6XSasAkAAABocwRNy5Dt71Osu3vOWKy7W9n+vpAqQsdxl0qnpeNHCZvQljKZjEql0pyxUqmkTCYTUkUAAAAA6oGgaRlSu3YqNzigRG+vzEyJ3l7lBgdoBI7mcpfGS9KxI4RNaDvDw8M1jQMAAABoD+w6t0ypXTsJlhA+d2liXDr6tPTMKySzsCsCliQej6tYLC44DgAAAKB9MaOpxeX3DCm5dZu6rkkquXWb8nuGwi4JrcZdmphgZhPaSjabVSwWmzMWi8WUzWZDqggAAABAPRA0tbD8niGl+/pVHBkJmuWOjCjd10/YhAWUZzYdp0E42kMqlVIul1MikQiWICcSyuVySqVSYZcGAAAAYAUImlpYZmBQpfHxOWOl8XFlBgZDqggtzV0aP81udGgbqVRKhUJBMzMzKhQKhEwAAABABBA0tbDh0dGaxoHZ3ehOHg+7EgAAAABAByJoamHxnp6axgFJQdh06hRhEwAAAACg6QiaWli2v0+x7u45Y7HubmX7+0KqCO3DpbGxYHYTAAAAAABNQtDUwlK7dio3OKBEb2/QLLe3V7nBAaV27Qy7NLQFl44flSYnwy4EAAAAANAhCJpaXGrXThX279PMEwUV9u8jZEJt3KUjh6Tp6bArQYfK5/NKJpPq6upSMplUPp8PuyQAAAAADUTQBETdzEwQNrETHZosn88rnU6rWCzK3VUsFpVOpwmbmoigDwAAAM1G0AR0grNnpWNHCJvQVJlMRqVSac5YqVRSJpMJqaLOQtAHAACAMBA0AZ1iYlw6PRZ2Feggw8PDNY2jvgj6AAAAEAaCJqBTuEsnTkhnJsKuBB0iHo/XNI76IugDAABAGAiagI7i0pHD0tTZsAtBB8hms4rFYnPGYrGYstlsSBV1FoI+AAAAhIGgCeg07tLTh8KuAh0glUopl8spkUjIzJRIJJTL5ZRKpcIurSMQ9AEAACAMq8MuAEAIpqelqakgdDILuxpEWCqVIlgKSeW+ZzIZDQ8PKx6PK5vN8v0AAABAQxE0AZ3KXTp5XLrsGWFXAqBBCPoAAADQbCydAzqWS6dOSeOlCx8KAAAAAMASEDQBHc2lY0ekmemwCwEAAAAARABBE9Dp3KVjR8OuAgAAAAAQAQRNAKQzEyyhAwAAAACsGEHTPPk9Q0pu3aYdr75Zya3blN8zFHZJQOM5S+gAAAAAACvHrnNV8nuGlO7rV2l8XJJUHBlRuq9fkpTatTPM0oDGqyyh23Bl2JUAAAAAANoUM5qqZAYGZ0OmitL4uDIDgyFVBDQZS+gAAAAAACtA0FRleHS0pnEgclhCBwAAAABYAYKmKvGenprGgUhiFzo0QD6fVzKZVFdXl5LJpPL5fNglAQAAAGgAgqYq2f4+xbq754zFuruV7e8LqSIgJCyhQx3l83ml02kVi0W5u4rFotLpNGETAAAAEEEETVVSu3YqNzigRG+vzEyJ3l7lBgdoBI7OwxI61FEmk1GpNDe4LJVKymQyIVUEAAAAoFEImuZJ7dqpwv59euBbf6fC/n2ETHWQ3zOk5NZt6romqeTWbcrvGQq7JCwFS+hQJ8PDwzWNAwAAAGhfBE1oqPyeIaX7+lUcGQmWzIyMKN3XT9jULs5MSPN2YgRqFY/HaxoHAAAA0L4ImtBQmYFBleYFFaXxcWUGBkOqCDVxl44fDf4ElimbzSoWi80Zi8ViymazIVUEAAAAoFEImtBQw6OjNY2jBfmMdPpU2FWgjaVSKeVyOSUSiaD/XSKhXC6nVCoVdmkAAAAA6mx12AUg2uI9PSqOjCw4jjbhLp08IV18sWRk01ieVCpFsAQAAAB0AH5rRF3Nb/z92lftUKy7e84xse5uZfv7QqoQy+Iz0thY2FUAAJbBzG42s5+Z2S/MrH+RY241s8fM7Cdm9lfNrhEAAEQHQRPqZqHG33fd81Xd8aY3KtHbGyyZ6e1VbnCA3fza0amT0sxM2FUAAGpgZqskfUrSayRdL+l2M7t+3jHPkfQeSa9w9/9e0v/W9EIBAEBksHRunvyeIWUGBjU8Oqp4T4+y/X2EIku0WOPve+9/QIX9+0KqCnVTWUJ3+TPCrgQAsHQvlfQLd/+lJJnZbkm3SHqs6pi3S/qUux+TJHc/1PQqAQBAZDCjqcpCM3LSff3K7xkKu7S2QOPvDnD6lDQ9FXYVAICl65X0RNXzA+Wxas+V9Fwz+wcz+76Z3dy06gAAQOQQNFVZbEZOZmAwpIray2INvmn8HSUunTgedhEAgPpaLek5krZLul3Sp83s8vkHmVnazB42s4cPHz7c5BIBAEC7IGiqEoUZOfObcTdzNla2v4/G351gfFw6ezbsKgAASzMi6Zqq55vKY9UOSPq6u591919J+v8VBE9zuHvO3be4+5Yrr7yyYQUDAID2RtBUpd1n5IS99C+1a6dygwM0/o48l04cC7sIAMDS/EDSc8zsWjO7SNJtkr4+75ghBbOZZGZXKFhK98tmFgkAAKKDoKlKu8/IaYWlf6ldO1XYv08zTxRU2L+PkCmqJs9Ik5NhVwEAuAB3n5L0TknfkvS4pK+4+0/M7E/N7HfKh31L0hEze0zSg5Le7e5HwqkYAAC0u1B2nSuv+/+MpBskuaQ/kPQzSV+WlJRUkHRrZfeTZqmEIu2661wUlv6hTbhLx49KV/13YVcCALgAd79X0r3zxt5X9bVL+nflBwAAwIqENaPpzyT9nbtfJ+mFCv4ftn5J97v7cyTdX37edJUZOQ986+/abkZOuy/9Q5uZOiudmQi7CgAAAABAC2l60GRml0n6LUl/KUnuPunuxyXdIumu8mF3SWqfhKdG9WzYXX2uU6WS1qxZM+f1dlr6hzbjLp08EXYVAAAAAIAWEsaMpmslHZb0OTP7ZzP7jJldLGmjuz9ZPuYpSRtDqK3h6tmwe/65jhw7JpO04fLLacaN5pg8I01NhV0FAAAAAKBFWLAsv4kXNNsi6fuSXuHu+83szySdlPTH7n551XHH3P0ZC7w/LSktSRs3XvXi3V/8Yl3ru+/+B/SZz31Ohw4f1lVXXqm33XmnbnrVjrqd/7Y3v0UHDx06Z3zjVVdp95dq+yz1PFfYTk1M6JJ168Iuo6PU7Z53rZJWrVr5eSLu1KlTuuSSS8Iuo2Nwv5urkff7xhtv/KG7b2nIybFsW7Zs8YcffjjsMgAAQIOY2bL/GyyMZuAHJB1w9/3l519V0I/poJld7e5PmtnVks5NUCS5e05STpK2vPAFvv366+pWWH7PkD768Y9r8uxZSdLBQ4f00Y9/XP9qU0/dZgUdOnx40fFaP0s9zxW2vY/9tO1qbnd1u+dm0tWbgj+xqL1792r79u1hl9ExuN/Nxf0GAABARdOXzrn7U5KeMLPnlYdeJekxSV+XdEd57A5Jf93s2t71vg/MhkwVk2fP6l3v+0DdrlHPht00/0bLGC+FXQEAAAAAoAWEtevcH0vKm9mPJW2W9BFJA5L+BzP7uaSbys+b6sixYzWNL0e2v0+x7u45Y8tt2F3Pc3WCejZhRxV3aexk2FUAAAAAAFpAGEvn5O6PSFpord+rml1Ls1WW4GUGBjU8Oqp4T4+y/X3LWppXz3NFXaVxeml8XJJmm7BL4n7Vw/SUNDkpXXRR2JUAAAAAAEIU1oymlmSL9JhZbHy5Urt2qrB/n2aeKKiwf9+Kgo56nivKMgODsyFTRWl8XJmBwZAqihh36RSzmhB9+XxeyWRSXV1dSiaTyufzYZcEAAAAtJRQZjS1qsV24Gv2znyov+HR0ZrGsQzjJWlmRuoiv0Y05fN5pdNplUpBT7Jisah0Oi1JSqVSYZYGAAAAtAx+I6yS6O2taRztg8bpTWAmnT4VdhVAw2QymdmQqaJUKimTyYRUEQAAANB6CJqq0Fw7uvjeNoG7dGos+BOIoOHh4ZrGAQAAgE5E0FQltWuncoMDSvT2ysyU6O1VbnCAvkcRENXvbcvtpOcz0uSZcGsAGiQej9c0DgAAAHQiejTNk9q1U6ldO7X3sZ9q+/XXhV0O6qjyvY2KltxJz10aOymtXRfO9YEGymazc3o0SVIsFlM2mw2xKgAAAKC1MKMJaFMtu5PemQlpejrcGoAGSKVSyuVySiQSwczIREK5XI5G4AAAAEAVgiagTbXsTnpm0sT4hY9DzfL5vJLJpLq6upRMJpXP58MuqeOkUikVCgXNzMyoUCgQMgEAAADzEDQBbapld9Jzl0qnw60hgvL5vNLptIrFotxdxWJR6XSasAkAAABASyFoAtpUS++kN3kmaAyOuslkMnN6A0lSqVRSJpMJqSIAAAAAOBdBE9CmWnonPTNpgt3n6ml4eLimcQAAAAAIA7vOAW2sZXfSc5fGT0vzZlxh+eLxuIrF4oLjAAAAANAqmNE0T37PkJJbt2nHq29Wcus25fcMhV1S5OX3DOm2N79FXdckm37PK9/vMK4deRPjQeCEushms4rFYnPGYrGYstlsSBUBAAAAwLmY0VQlv2dI6b7+2S3jiyMjSvf1S1JrzhqJgDDvOd/vJjg7KV20NuwqIqGyu1kmk9Hw8LDi8biy2Sy7ngEAAABoKcxoqpIZGJwNHSpK4+PKDAxKYvZLI1zonkf12h3BXZp3f7EyqVRKhUJBMzMzKhQKhEwAAAAAWg4zmqoMj44uOs7sl8Y43z2P8rU7xvhp6bLLw64CAAAAANAkzGiqEu/pWXSc2S+Ncb57HuVrd4zpaWlqKuwqAAAAAABNQtBUJdvfp9i8XbJi3d3K9vcx+6VBznfPo3ztzmHSRCnsIgAAAAAATULQVCW1a6dygwNK9PbKzJTo7VVucECpXTuXPPuFPk61qdzzjVdddc49b9a1F/p+o15cKhE0AQAAAECnuGCPJjPrkvRCST2SxiU96u6HGl1YWFK7diq1a6f2PvZTbb/+utnxbH/fnB5N0rmzX+jjtDypXTvV+7zr5tzvZl67GbvbZQYGNTw6qnhPj177qh269/4HZp9n+/ui/fNxdlKamZG6yLUBAAAAIOoWDZrM7NmS/kTSTZJ+LumwpHWSnmtmJUn/SdJd7j7TjELDVgkCqgOD+QHB+fo4RTpIwKIWCh//4gtfnH29I8JIM+nMhNQdC7sSAAAAAECDnW9G04cl/YWkP3R3r37BzK6S9D9LeoukuxpXXmu50OwX+jhhvoXCx/kiH0a6EzQBAAAAQIdYdC2Lu9/u7t+ZHzKVXzvk7v/R3TsmZFoKdjHDfEsNGYsjI9Hu7TV5JuwKAAAAAABNcMGmKWa2ysx+x8z+rZn9u8qjGcW1G3Yxw3xLDRnNTMWREbn77HK6SIVNZ88GM5sAAAAAAJG2lO68fyPp9yVtkLS+6oF52MUM8y0UPs5nZpo/cbCynC4yzKTpqbCrAAAAAAA02AV3nZO0yd1f0PBKIqIZu5ihfSzURH7+rnPFkZEF3xu53l6Tk9LqNWFXAQAAAABooKUETd80s3/j7n/f8GqACLpQ+Jjcum3BsClSvb3cgz5NsYvDrgQAAAAA0EBLWTr3fUl7zGzczE6a2ZiZnWx0YUCn6JjeXjQEBwAAAIDIW0rQ9HFJL5cUc/dL3X29u1/a4LqAjtExvb1oCA4AAAAAkbeUoOkJSY/6/G7FOK/8nqFob1e/DNyTxaV27VRh/z7NPFFQYf++6IVMEg3BAQAAAKADLKVH0y8l7TWzb0qaXfvi7h9vWFVtLr9nSOm+fpXGxyVpdrt6SdEMEJaAewJJNAQHAAAAgIhbyoymX0m6X9JFktZXPbCIzMDgbKBSEbnt6mvEPcFsQ3AAAAAAQGRdcEaTu3+wGYVEyWLb0kduu/oacE8giaAJAAAAACJu0RlNZvZpM3v+Iq9dbGZ/YGapxpXWvhbblj5S29XXaLHP3tXVpa5rkrrtzW+hZ1MnoCE4AAAAAETa+ZbOfUrSe83scTO7x8z+3Mw+a2bflbRPwfK5rzalyjbTMdvV12CheyJJ09PTcncdPHRI6b5+wqaooyE4AAAAAETaokvn3P0RSbea2SWStki6WtK4pMfd/WdNqq8tVZpbZwYGNTw6qnhPj7L9fR3d9Hr+Penq6tL09PScYyo9mzr5PnWEs2dpCA4AAAAAEXXBZuDufsrd97r73e4+RMi0NB2xXX2Nqu/JzMzMgsfQs2n58nuGlNy6TV3XJJXcuq01Z4e5S/MCRgAAAABAdCxl1zmg7uhjVV/5PUNK9/WrODIid1dxZKR1lyISNAEAAABAZBE0IRT0saqvzMCgSuPjc8YqSxFbDj2aAAAAACCyagqazKzLzC5tVDHoHKldO5UbHFCit1dmpo1XXaXc4ABLDJdpsSWHLbkUkaAJAAAAACLrgkGTmf2VmV1qZhdLelTSY2b27saXhqir7tm0+0tfJGRagbZaisjSOQAAAACIrKXMaLre3U9K2inpm5KulfSWhlYFoCZttRRxkUbwAAAAAID2t5SgaY2ZrVEQNH3d3c9K8saWBaAW85ciJnp7W3cponvwAAAAAABEzuolHPOfJBUk/UjSd8wsIelkI4sCULvUrp2tGSzNZybNTEurlvLPDwAAAACgnVxwRpO7f9Lde939tR4oSrqxCbWFIr9nSMmt27Tj1TcruXVba24PD7Q7+jQBAAAAQCRdcEqBmV0m6f2Sfqs89JCkP5V0ooF1hSK/Z0jpvv7ZbeKLIyNK9/VLUnvMFAHaBUETAAAAAETSUno0fVbSmKRby4+Tkj7XyKLCkhkYnA2ZKkrj48oMDIZUERBB7sHSOQAAAABA5CylScqz3f0NVc8/aGaPNKqgMA2PjtY0DmCZpgiaAAAAACCKljKjadzMXll5YmavkDR+nuPbVrynp6ZxAMs0PRV2BQAAAACABlhK0PS/SPqUmRXMrCjp/5P0h40tKxzZ/j7FurvnjMW6u5Xt7wuponBUGqJ3XZOkIToagx5NAAAAABBJS9l17hF3f6GkF0h6vru/yN1/3PjSmi+1a6dygwNK9PbKzJTo7VVucKCjGoFXGqIXR0bk7rMN0VcaNhFeYY6ZmbArAAAAAAA0wAWDJjPbYGaflLRX0oNm9mdmtqHhlYUktWunCvv36YFv/Z0K+/c1PWQKO5BpREP0RoVXaGcedgEAAAAAgAZYytK53ZIOS3qDpDeWv/5yI4vqVK0QyDSiITq7+eEcTtAEAAAAAFG0lKDpanf/kLv/qvz4sKSNjS6sE7VCINOIhui1hFdhz+hC+PL5vJLJpLq6upRMJpXP58MuCQAAAACwREsJmv7ezG4zs67y41ZJ32p0YWGpBB07Xn1z04OORswmqlUjGqIvNbxqhRldCFc+n1c6nVaxWAx+BopFpdNpwiYAAAAAaBNLCZreLumvJJ0pP3ZL+kMzGzOzk40srtnCDjoaMZuoVo1oiL7U8KoVZnShSRZZOpfJZFQqleaMlUolZTKZZlQFAAAAAFihpew6t97du9x9TfnRVR5b7+6XNqPIZgk76GjEbKLlqDREn3miUJeG6EsNr1phRhfCNTw8XNM4AAAAAKC1rA67gFYSdtBRCV4yA4MaHh1VvKdH2f6+pu981wipXTsv+DniPT0qjowsOI6IWaQXeDweV7FYXHAcAAAAAND6lrJ0rmO0ytK1es4maietMqMLTWALD2ezWcVisTljsVhM2Wy2CUUBAAAAAFZq0aDJzO41s2TzSgnfa1+1o6Zx1Fcj+kOhvaRSKeVyOSUSieBnIJFQLpdTKpUKuzQAAAAAwBKcb+nc5xTsOHeXpEF3P9ukmkJz7/0P1DSO+lvKEjtEwSJTmhSETQRLAAAAANCeFg2a3P0eM/umpPdKetjMvihppur1jzehvqYKu0cT0DEWz5kAAAAAAG3sQj2aJiWdlrRW0vp5j8hphR5NaC35PUNKbt2mrmuSSm7dpvyeobBLQgfK5/NKJpPq6upSMplUPp8PuyQAAAAAWNCiM5rM7GZJH5f0dUm/6e6lplUVkmx/n9J9/SqNj8+O0Yy6c+X3DM35eSiOjCjd1y9JLO9bMaY0LVU+n1c6nVapFPwTXCwWlU6nJYklhgAAAABazvlmNGUkvcnd+zshZJJoRo25MgODc0JHSSqNjyszMBhSRRFCzrRkmUxmNmSqKJVKymQyIVUEAAAAAItbNGhy93/t7j9pZjFAK6FnVwPZhVbtomJ4eLim8YWw9A4AAABAs/DbXpXKUqniyIjcfXapFH15OhM9uxpo1aqwK2gb8Xi8pvH5KkvvisVi8O9aeekdYRMAAACARiBoqsJSKVTL9vcp1t09Z4yeXXWyetH2cJgnm80qFovNGYvFYspms0t6P0vvAAAAADQTQVOV4shITeOINnp2NdAqgqalSqVSyuVySiQSwc9hIqFcLrfkRuD1WHoHAAAAAEvFb3tVVq1apenp6QXH0ZlSu3YSLNWbGUvnapRKpZa9w1w8HlexWFxwHAAAAADqjRlNVRYKmc43DmCZugiammWlS+8AAAAAoBYETVUSvb01jQNYJmY0Nc1Kl94BAAAAQC0ImqrQ/BlYnvyeISW3blPXNUklt247/06N7gRNTZZKpVQoFDQzM6NCoUDIBAAAAKBhCJqqpHbt1B1veuNsT6ZVq1bpjje9sak9emr6hR1oAfk9Q0r39as4MiJ3V3FkROm+/sV/ds2CBwAAAAAgcgiaquT3DOmue74625Npenpad93z1aaFPTX/wg60gMzAoErj43PGSuPjygwMLvyGLv7ZAQAAAICo4je+KjX/whyx6wPLMTw6WtM4jcAD+XxeyWRSXV1dSiaTyufzYZcEAAAAACtG0FSl5l+YI3Z9YDniPT01jdOfKQiZ0um0isViMHuxWFQ6nSZsAgAAAND2CJqq1PwLc4tenz5PaKaam+ivXt2EqlpbJpNRqVSaM1YqlZTJZEKqCAAAAADqg6CpSti7ztXj+u3Y5ym/Z0i3vfktBGNtKrVrp3KDA0r09srMlPhv7d15fFx3fe//12ckL1KcPU5aK5ZES6Ck7DUEEu5tWPpr4NLEDrQlDG0KuSiUfTUOKt2owDgtUNoQIkiAC1OWQuKGll5uCwn8mhQ/CEspSaDkEsmJDGR1Ymdk2dJ87x8zMpIt2Vpm5szyej4ernW+c3Tm03OOFObt7/dzenoY3rZ1/ib6zmhi586dixqXJEmSpGZh0DTDoj8wN+D7N1ufp+lg7Gf33NM0wZgOl9+0kZEdN1O6a4SRHTfPf89G2KMJ6O3tXdS4JEmSJDUL17AcIr9pI/lNG7nxth9w7pm/ktn7L1Wz9Xk6UjBWr4BPdda5IusKMjc0NMTAwMCs5XPd3d0MDQ1lWJUkSZIkLZ8zmlpM1n2mFqvZgjEtU0qwwqApn88zPDxMX19fefZiXx/Dw8Pk8/msS5MkSZKkZTFoajFZ95larGYLxrRMHZ3l5XMin88zMjJCqVRiZGTEkEmSJElSS8gsaIqIjoj4TkT8Y2X7URGxIyLuiIjPRsTKrGprZln3mVqsZgvGtEwrV2VdgSRJkiSphrKc0fQG4PYZ2+8F3p9SejTwIHBJJlW1gAU3Zm4A08HYaaee2hDBWOG67fSfdbZPwKuFCFhl0CRJkiRJrSyTZuARcTrwP4Ah4M0REcBzgJdWdvkE8KfAlVnUp/rKb9pIz2N/JZPm6zNNPwFvujn59BPwgIYO65rKCicqSpIkSVIry2pG0weAzUCpsn0ysDulNFnZvhvoyaIwNaZ6zDQ60hPwVAU2ApckSZKkllf3GU0R8ULgnpTStyLi3CV8/wAwAHDaaady420/qHKFZXv37avZsXW4I53vf/3KV/nLD3yAiYkJoDzT6JK3bub2u3fxvOc+p2o1HOkJeK14L9T9Ho+AH/24fu/XYPbu3cuNN96YdRltw/NdX55vSZIkTcti6dw5wPkR8QJgNXAc8NfACRHRWZnVdDowNtc3p5SGgWGADU96YqrVcqsbb/tB5ku52smRzvcfvPwVB0OmaRMTE3zqU5/iL1736qrV0LtuHaNjh992vevWteS9UPd7vKsbTjqlfu/XYG688UbOPffcrMtoG57v+vJ8S5IkaVrdl86llC5LKZ2eUuoHXgJ8NaWUB24AXlzZ7WLgH+pdmxrTkWYaVZNPwKuhCFi1OusqJEmSJEk1luVT5w71dsqNwe+g3LPp6ozrUYPoXbduUeNLNf0EvL6enoZ4Al7LsRG4JEmSJLW8TIOmlNKNKaUXVr7+cUrp6SmlR6eUfjulNHG071d7qOdMo/ymjYzsuJnSXSOM7LjZkKlabAQuSZmJiPMi4ocRcUdEbDnCfi+KiBQRG+pZnyRJai2NNKNJmpMzjVpAR2d5+Zwkqa4iogO4Ang+cCZwUUScOcd+xwJvAHbUt0JJktRqsmgGLi1aftNGg6VmttJlc5KUkacDd6SUfgwQEZ8BLgBuO2S/dwHvBd5W3/IkSVKrcUaTpNqyEbgkZakHuGvG9t2VsYMi4qnA+pTSP9WzMEmS1JoMmiTVVkqw2qBJkhpRROSA9wFvWcC+AxFxS0Tccu+999a+OEmS1JQMmiTVVkdn+Y8kKQtjwPoZ26dXxqYdCzweuDEiRoBnANfP1RA8pTScUtqQUtqwdu3aGpYsLQ2z7AAAIABJREFUSZKamUHTIQrXbaf/rLN5zm+eR/9ZZ1O4bnumdeTW92dah7Rs3d1ZVyBJ7eybwBkR8aiIWAm8BLh++sWU0kMppVNSSv0ppX7gG8D5KaVbsilXkiQ1O4OmGQrXbWdg8xZGx8ZIKTE6NsbA5i11D3kapQ5p2SJgtUGTtBSFQoH+/n5yuRz9/f0UCoWsS1ITSilNAq8FvgzcDnwupXRrRPx5RJyfbXWSJKkVGTTNMLh1G8Xx8VljxfFxBrdua8s6pOULWLEi6yKkplMoFBgYGGB0dLT8Dw6jowwMDBg2aUlSSl9KKT0mpfTLKaWhytgfp5Sun2Pfc53NJEmSlsOgaYadu3YtarzV65CWraurPKtJ0qIMDg5SLBZnjRWLRQYHBzOqSJIkSVoYg6YZetetW9R4q9chLUsEdLlsTlqKnTt3LmpckiRJahQGTTMMbdlMd1fXrLHuri6GtmxuyzqkZUkJVq3OugqpKfX29i5qXJIkSWoUBk0z5DdtZHjbVvp6eogI+np6GN62lfymjW1Zh7Qsq1a7bE5aoqGhIboPeWJjd3c3Q0NDGVUkSZIkLUxn1gU0mvymjeQ3beTG237AuWf+SuZ1SE0pArpdNictVT6fB8q9mnbu3Elvby9DQ0MHxyVJkqRGZdAkqfpSglVdR99P0rzy+bzBkiRJkpqOS+ckVV/nCujoyLoKSZIkSVKdGTQ1qMJ12+k/62xy6/vpP+tsCtdtz7okaeFcNidJkiRJbcmlcw2ocN12BjZvoTg+DsDo2BgDm7cA2LdJjS8CVhs0SZIkSVI7ckZTAxrcuu1gyDStOD7O4NZtGVUkLUJHJ6xYkXUVkiRJkqQMGDQ1oJ27di1qPGsu85utrc9HBBx7XNZVSJIkSZIy4tK5BtS7bh2jY2Nzjjcal/nN5vkAulw2J0mSJEntyhlNDWhoy2a6u2Y/Gr67q4uhLZszqmh+LvObre3PR/ea8qwmSZIkSVJbMmhqQPlNGxnetpW+nh4igr6eHoa3bW3IGTHNtsyv1tr+fKw5NusKJEmSJEkZMmhqUPlNGxnZcTOlu0YY2XFzQ4ZMMP9yvkZc5ldN8/VhatfzAcDKVdDpalxJkiRJamcGTVqWZlrmVy3TfZhGx8ZIKR3sw1S4bntbng/AJuCSJEmSJMBm4Fqm6ZlWg1u3sXPXLnrXrWNoy+aGnYFVDUfqwzSy4+aD+7TL+QDKQdOq1VlXIUmSJEnKmEGTli2/aWPrBykzHK0PU7udD4hybyabgEuSJElS23Pp3KF+th2+cTa/fu958I2zy9tHMF+vHrWuVu7DtLT7OZWfNicpE4VCgf7+fnK5HP39/RQKhaxLkiRJUhszaJrpZ9vhv7bAxBhBgomx8vY8YdORevWodbVqH6Yl38+ru6Cjoz5FSpqlUCgwMDDA6Oho+ed2dJSBgQHDJkmSJGXGoGmmO7dBaXbvHUrj5fE5HKlXj1pXftNGhrdtpa+nh4igr6eH4W1bm3653JLuZ5uAS5kaHBykWCzOGisWiwwODmZUkSRJktqdQdNME3P33plv/Gi9ehqdy/6WLr9pIyM7bqZ01wgjO25u+pAJlng/d3TAipU1qkjS0ezcuXNR45IkSVKtGTTNtGqeHjvzjDdzrx6X/elQi76fI2DNcTYBlzLU29u7qHFJkiSp1gyaZnrUZsjN7r1Drqs8Podm7tXjsj8datH3cy4H3cfUoTJJ8xkaGqK7u3vWWHd3N0NDQxlVJEmSpHZn0DTTaRvhMVthVQ8pwci9lLdPm3tZVDP36mn2ZX+qvkXdzxFw/InOZpIyls/nGR4epq+vr/xz29fH8PAw+Xw+69IkSZLUpjqzLqDhnLYRTtvI1279Ac9+2W/yheFVXPiC+XfPb9rYFMHSoXrXrWN0bGzOcbWvBd/PHR3lp81Jylw+nzdYkiRJUsNwRtN8KhM1XjTwqmzrqJFmXvanbCUCTjjJ2UySJEmSpMMYNB3Ble8p97hIKWVcSfU187I/ZScBB+jkkckVWZciSZIkSWpABk1HcOnLyksRPlL4dMaV1EZ+00ZGdtxM6a4RRnbcbMikBXkojufhh0vs21fKuhSp5RQKBfr7+8nlcvT391MoFLIuSZIkSVoUg6YjiMrSoEu3XJZxJVL2EjDBKiajPJvpwQen2L/fsEmqlkKhwMDAAKOjo6SUGB0dZWBgwLBJkiRJTcWg6Si+MPxhACYnJzOuRMrew3HcrO0HHphiaqr1lpZKWRgcHKRYLM4aKxaLDA4OZlSRJEmStHgGTUdx4QueD8DWKz6UcSVSdhIwThdTMftBlSnB/fdPtmQfM6nedu7cuahxSZIkqREZNC3Aiccfzzsv/6usywCgcN12+s86m9z6fvrPOpvCdduzLkltYk8cO+f41FR5GZ1hk7Q8vb29ixqXJEmSGpFB0wJc99FhAIrj45nWUbhuOwObtzA6Nlbu3zE2xsDmLYZNqqkS8AjHUIqOefeZmEg88oj9mqTlGBoaoru7e9ZYd3c3Q0NDGVUkSZIkLZ5B0wL8+jOfAcCWd2/NtI7BrdsOC7uK4+MMbt2WUUVqD8HeWHPUvfbs8Ul00nLk83mGh4fp6+sjIujr62N4eJh8Pp91aZIkSdKCGTQt0GN/+Zf4m499PNMadu7atahxablKBHtZQ4qF/arYvXuKyUmX0ElLlc/nGRkZoVQqMTIyYsgkSZKkpmPQtECfu7LcDPyBB3dnVkPvunWLGpeWIwFTdPBIHLPw76k0By+VDJskSZIkqR0ZNC3QE898HACvHvyjzGoY2rKZ7q6uWWPdXV0MbdmcUUVqdbvjBIhY1PeUSjYHlyRJkqR2ZdC0CM962tP47PVfzOz985s2MrxtK309PeX+HT09DG/bSn7TxsxqUmsqEexhDZOxYknff+CAzcElSZIkqR11Zl1AM/nkB9/Po575LO7atYv1GS1Xy2/aaLCkmvr5krmjNwCf9xip3Bx85cpg5UrzbEmSJElqF34CXIT+9esBuPiNb864Eqm2lrJkbi4PPjhlvyZJkiRJaiMGTYu06bzf5Iab/z3rMqSaWO6SucOOVyo/ic5+TZIkSZLUHgyaFumq974HgFt/+F8ZVyJVVzWWzM1lYiJRLNqvSZIkSZLagUHTIq09+WQAzsv/Hv1nnU1ufT/9Z51N4brtGVcmLd+DcWJVlswd6uGHSxw4kO2spkKhQH9/P7lcjv7+fgqFQqb1SJIkSVIrshn4EjznnLP56k03H9weHRtjYPMWABt1qymVCPayhqmo3a+EBx6YZO3aTnK56gdZR1MoFBgYGKBYLAIwOjrKwMAAAPl8vu71SJIkSVKrckbTEvzozjsPGyuOjzO4dVsG1UjL8/Mlc8fU9H1KJXj44amavsd8BgcHD4ZM04rFIoODg5nUo8bnDDhJkiRpaZzRtAR3/+Snc47v3LWrzpVI1VGrJXOHGh9PdHWVWLWqvhn3zp07FzWu9uYMOEmSJGnpnNG0BL3r1i1qXGpUJWAPx9Z0ydyhdu+eolSqb7+m3t7eRY2rvTkDTpIkSVo6g6YlGNqyme6u1bPGuru6GNqyOaOKpKU5wMqaL5k7VBZL6IaGhuju7p411t3dzdDQUF3rUHNwBpwkSZK0dAZNS5DftJHhbe89uN3X08Pwtq02AlfTKM8nirotmTvU+HhiYqJUt/fL5/MMDw/T19dHRNDX18fw8LDLoDQnZ8BJkiRJS2fQtET5TRv5m3f9GQB3fuMmQyY1lUQwSScpsvsV8OCD9V1Cl8/nGRkZoVQqMTIyYsikeVVrBpwNxSVJktSODJqW4TV/cDEAH/vs5zKuRItVuG47/WedTW59P/1nnU3huu1Zl1Q3iXLz7/p2SZqjjpTdU+ikI6nGDLjphuKjo6OklA42FDdskiRJUqszaFqGqCw5uuSt9mZqJoXrtjOweQujY2PlD4BjYwxs3tIWYVOJ4GGOZX+syroUoP5L6KSFWu4MOBuKS5IkqV0ZNC3TZz70twBMTTkzo1kMbt1GcXx81lhxfJzBrdsyqqg+SsAEqyjWufn30ezePUVKWc+vkqrLhuKSJElqVwZNy/S75/8WAJdfeVXGlWihdu7atajxVpCAKTrZHSdk0vz7SEol2LPHoFatxYbikiRJalcGTVWw5phjuGzre4++oxpC77p1ixpvdoly8+8H4qSGC5mmPfJIYnLSWU1qHdVqKC5JkiQ1G4OmKth+9TAA+/bty7gSLcTQls10d3XNGuvu6mJoS2v22krA/XEypejIupQjeughl9CpdVSjobgkSZLUjAyaquC5z3oWAO94b2v3+GkV+U0bGd62lb6envIHwJ4ehrdtJb9pY9alVV0CHuJ4JmNF1qUc1YEDiYkJgya1juU2FJckSZKakUFTlTyqdz3v/8jVWZehBcpv2sjIjpsp3TXCyI6bWzJkKgGPcAz7ct1H3bcRpOSsJkmSJElqdgZNVfL5q64EYPdDD2VciVQOmfazkj1xbNalLIqNwSVJkiSpuRk0VclTn/AEAF73zj/JuBK1uxJwgBU82MDNv4/ExuCSJEmS1LwMmqrorKc8mU9de13WZaiNlYBJVvBAnNyUIdO0hx5yVpMkSZIkNSODpioq/M0HAdj1059lXInaUQKm6OSBJp3JNNP+/YmJiVLWZUiSJEmSFsmgqYp+ub8PgFe85a0ZV6J2k4BJOrk/TiZFa/xYP/ywjcElSZIkqdm0xifSBvJbv/E8vvy1r2ddhtpIeSZTR0uFTABTU7Bvn0GTJEmSJDWT1vlU2iA+sm0rAD/8v/8340rUDsozmTq4L05pqZAJICVnNUmSJElSs2mtT6YN4LS1awG46DWvy7gStbpy4+9O7m/BkGlaqQTFor2aJEmSJKlZtOan04xd8pLf5TvfvzXrMtTCfh4ytdZyubns2VNyVpMkSZIkNYnW/oSakff/6R8DsOPb38m4ErWiEnCAFS09k2mmlOCRR5zVpNZQKBTo7+8nl8vR399PoVDIuiRJkiSpqlr/U2oGjl2zBoAXDbwq40rUasoh00oeiJMhIuty6mbv3hKlkrOa1NwKhQIDAwOMjo6SUmJ0dJSBgQHDJkmSJLUUg6Ya2fKaVzP205/OGitct53+s84mt76f/rPOpnDd9oyqUzMqEUywmgfipLYKmaA8q2nv3qmsy5CWZXBwkGKxOGusWCwyODiYUUWSJElS9Rk01cifveVNAPzzV28AyiHTwOYtjI6Nlf8le2yMgc1bDJu0IAnYwxp2xwltFzJNKxaTs5rU1Hbu3LmocUmSJKkZGTTVyMqVKwG44JJXAjC4dRvF8fFZ+xTHxxncuq3utalxHG2WW6I8k+mBOIlibk3bhkxgryY1v97e3kWNS5IkSc3IoKmG3vcn7+TAgQOklNi5a9ec+8w3rtZ3tFluCZgix31xCvtjVbbFNohHHvEJdGpeQ0NDdHd3zxrr7u5maGgoo4okSZKk6jNoqqE3XPIKAD75hWvpXbduzn3mG1frO9IstxKwn5XcF2uZis5sCmxAKUGx6KwmNad8Ps/w8DB9fX1EBH19fQwPD5PP57MuTZIkSaqaugdNEbE+Im6IiNsi4taIeENl/KSI+JeI+FHl7xPrXVu15XLl03vxG9/M0JbNdHd1zXq9u6uLoS2bsyhNDeBIs9yKdPNAnEQKs+BD7d3rrCY1r3w+z8jICKVSiZGREUMmSZIktZwsPsVOAm9JKZ0JPAN4TUScCWwBvpJSOgP4SmW76X3yr98PwEvO/y2Gt22lr6en/C/ZPT0Mb9tKftPGjCtUVuabzdaz7nT25I5v635MR1Iqwfi4QZMkSZIkNaK6B00ppZ+klL5d+XoPcDvQA1wAfKKy2yeAlkhg8hduAuADH72a/KaNjOy4mdJdI4zsuNmQqc3NNcutq6uLLZf9RUYVNY+9e6ec1SRJkiRJDSjTdTkR0Q88BdgBnJZS+knlpZ8Cp2VUVlVFBKtWreSt77LZq2bLb9rI8Lat9FZmuZ3es57LL/8wF154UdalNbxSCSYmDJokSZIkqdFEVrMCImIN8DVgKKV0bUTsTimdMOP1B1NKh/VpiogBYADgtNNO/bXPfPKTNalv7759rFm9uirHenjPXn5055089QmPJ1wONadqnu9mk8gxSUfd33ffvr2sXr2m7u9bLRHQ2dk8P0979+5lzZrmPd/NxvNdX7U8389+9rO/lVLaUJODa8k2bNiQbrnllqzLkCRJNRIRS/7fYJk8zioiVgBfAAoppWsrwz+LiF9MKf0kIn4RuGeu700pDQPDABue9MR07pm/UpMa/+hvPsSnPvUpdu7aRe+6dQxt2byspW7xohfx9lf/IVvf0RKtp6ruxtt+QK2uZSNKQCLYHScwEdkEbN///r/x+Mc/K5P3rpZTTulkxYrmCJtuvPFGzj333KzLaBue7/ryfEuSJGlaFk+dC+Bq4PaU0vtmvHQ9cHHl64uBfzjasUrkKh/Yq6tw3Xb+8gMfYHRsjJQSo2NjDGzeQuG67Us+5vp163jvh66sYpVqViVgH6u4J07NLGRqFXv3TmVdgiRJkiRphix6NJ0D/B7wnIj4buXPC4CtwG9ExI+A51W2j2iKDu6Pk5mig1IVCxzcuo2JiYlZY8XxcQa3blvyMb8w/GEAHt6zZ1m1qT4K122n/6yzya3vp/+ss5cVMk5LQIlgd5zI7txJpMi0RVpL2LcvUSrZq0mSJEmSGkXdl86llP4NmG+ty3MXe7wDsZJ7WcuxaQ/H8Agc4eALtXPXrkWNL8TTnvwkAN74p3/GNX/1l0s+jmqvcN12BjZvoTg+DnBwRhuw5OWTJWCCVTwUJxgwVVEEFIsl1qypf48rSZIkSdLhWuMTbwR7csdVbXZT77p1ixpfqKc+4fF87LN/v6xjqPYGt247GDJNW+qMNmcx1VZK8MgjJbJ6qIEkSZIkabaW+tR7IFZyb6ylyDHL6t00tGUzq1atmjXW3dXF0JbNy6rv01f8DQA/vWfOPudqENWa0WYvpvpICfbvN2iSJEmSpEbQUkETUJXZTflNG3nrG99IX08PEUFfTw/D27Yu66lzAI/5pV8C4H++7e3LOo5qa7kz2pzFVF8pwd691ezSJkmSJElaqpb9BLzc2U3Pe+5zGNlxM6W7RhjZcfOyQ6Zp55376/zTV75alWPVomG1yjPauru6Zo0tZEZbOWByFlMW9u9PTE05q0mSJEmSstayQRNwcHbTvbGWCVZSYunL6arlmr+6HIA77hxZ1nGmG1aPjo2RUjrYsNqwafnymzYyvG3roma0lQgm6eSBONlZTBkpFp3VJEmSJElZa4tPw1PRyYO5k3kgTuYAKygt+7l0S/eLp50GwEtf+/plHaeaDat1uPymjQua0VYOmDrYHSdwX5zCgVhZ50o1rVi0KbgkSZIkZa0tgqZpB2Il98fJPBgnMklHZoHT77/4RXzzP/5jWceoVsNqLU0JmCLHw1GZMRerIbILMFXu1XTggEGTJEmSJGWprYImACLYH6u4N9byUBzPFLm6B04f/PM/BeCW//jeko+x3IbVWpoS5VlMeziWe+JUxqPbgKlBpOTyOUmSJEnKWvsFTdMi2Bdd3BOnsodjKRF1C5yOP+44AF586auWfIylNqzW0kw/Se4R1nBPnEoxt8aAqQHt25dcPidJkiRJGWrfoGlaBMXcMfwsTmMvx1QCp9p7y6WvZPTusSV//1IaVmvxpp9YWKSbe2Mte3PH2ui7wU1MGDRJkiRJUlb8xDwtgkdy5eVQRboBaho4/cXb3grA//na15d8jIU2rNbiTQdM+1jNvbGWh3PHU4qOrMvSUbh8TpIkSZKyZdB0iBQ59uSOZ5IV7OXYmvVwWr16NQCb/udA1Y+tpZteQvkIx3BvrGV37kSmojPrsrQIExOJUslZTZIkSZKUBYOmeSTgkVy5H8/uOIEJVh6c5VIt733HZRTHx6t4RC1Fuf8SHKCTh+J4fhansSd3nAFTk4oo92qaVigU6O/vJ5fL0d/fT6FQyLA6SZIkSWptBk1HE8FErOaB3MncG2t55GAfp+XPcnrLpa8E4NPb/2HZx9LilQgSMM5q7o9TuC+3ln3RZZPvJjdz+VyhUGBgYIDR0VFSSoyOjjIwMGDYJEmSJEk1YtC0CFPRyZ7ccfwsTuOhOJ4DdFJi6bOcOjrKPX9e+trXV61GHdn00+OmyLGHNeVrmTuRyViRdWmqogMHysvnBgcHKRaLs14rFosMDg5mVJkkSZIktTaDpqWIYF90cV9uLffHKYyz+mCAsVjX/NXlAJRKNjCupelljxOs4sE4sdz0PbfGJ8i1qIhyr6adO3fO+fp845IkSZKk5fFT9jJNxgoeyp1Y7uvDGg7QebDnz0L8we/8NgB/+7FP1KzGdjU922ySDvZS7rf1YO4k9scql8e1uJRgfLxEb2/vnK/PNy5JrSgizouIH0bEHRGxZY7X3xwRt0XE9yLiKxHRl0WdkiSpNRg0VUmKHMXcGu7LreWeOJWH43j2VRqIT/cCmktEkMvleMOf/Gkdq21d0+d6PyvYw7HcG2u5N3cqe3PHUoqOrMtTHU1MJIaGhuju7p413t3dzdDQUEZVSVJ9RUQHcAXwfOBM4KKIOPOQ3b4DbEgpPRH4PLCtvlVKkqRWYtBUA6XoYDy6eTB3Mj+NX2B3nMA4qw82ET80dPqHaz4KwP79++tfbJObDvJKwD5WHXxq3P25Uyjm1vjkuDYWAS9+8UUMDw/T19dHRNDX18fw8DD5fD7r8iSpXp4O3JFS+nFKaT/wGeCCmTuklG5IKU03tPsGcHqda5QkSS3EoKnWKk+tm15ed3+czF6OYZKOg0vsXvi85wLw5x/460xLbRbT522KHEW6eTBO5GfxCzyYO4l90WXfJQE/Xz6Xz+cZGRmhVCoxMjJiyCSp3fQAd83YvrsyNp9LgH+uaUWSJKml+Ym8niKYjBXszR3HvblTuSdOZU8cx35W8AunrmXog3+7pIbira7Ez5fEHaCTPazh/jilvEQxd7w9lzSvffsSKS31uZCS1F4i4mXABuDyeV4fiIhbIuKWe++9t77FSZKkpmHQlKFSdFCMY7g/dwrDH/k8ALuKOR6hiwMHZzxFW4VPM0OlSToYZzV74jgeiJP4afwC9+XW8kjuWCZjheGSFmRyMusKJClTY8D6GdunV8ZmiYjnAYPA+SmlibkOlFIaTiltSCltWLt2bU2KlSRJzc+gqUFseNozAdjyZ3/Cw7kTuC93Kj+NX+D+OJmH47iWDJ9mhkoQh4VK9+ZOZXfuRIpxDAdipcGSFi0l2Ldvoc+AlKSW9E3gjIh4VESsBF4CXD9zh4h4CnAV5ZDpngxqlCRJLcSgqYE87nFPoFC4+ucDlaV249F9hPCp82BYMzOEKlW2szLdR+nQekrEnDOVDtBpqKSaMGiS1M5SSpPAa4EvA7cDn0sp3RoRfx4R51d2uxxYA/x9RHw3Iq6f53CSJElH5SO5GsiHP/wpfv3Xn8R9993DKaecOvdOEUyygknKAdRBKZGjRI4SHUyV/05TdPDzP7kZ84fSEWdEHRpRHXnfqPzfEjmmyB18x1JU/q6MlcgZIKnuJiehVErkct57ktpTSulLwJcOGfvjGV8/r+5FSZKklmXQ1EDOOONxALztbX/Ixz72hcV9cwQlOijRwSQrKmNz7DcjkJoOnmJGsPTzhWyzA6mZwdT01wZIagYRcOBAYtUq71FJkiRJqjWDpgbzrGc9my9/+Yu1e4MZgZTUDlKCiYkSq1a5UliSJEmSas1PXg3mAx8o92gaHf1xxpVIrWPfviw7lkmSJElS+zBoajDr1p0OwOte9/KMK5Fax9RUuU+TJEmSJKm2DJoa0MaNv8stt/x71mVILSMC9u83aJIkSZKkWjNoakDvfvcHAbj11v/IuBKpNaQE+/eXsi5DkiRJklqeQVMDOuGEEwEYGLgo40qk1mGfJkmSJEmqPYOmBnXJJa/lzjvvyLoMqWXYp0mSJEmSas+gqUG94x1DANx0043ZFiK1iAg4cMCgSZIkSZJqyaCpQXV1dQFwySW/nXElUmso92kyaJIkSZKkWjJoamBvf/uf8fDDD2VdhtQynNEkSZIkSbVl0NTAXvOatwHwxS9+PuNKpNZg0CRJkiRJtWXQ1MA6OzsBuPTSl9btPa+99tM87WmPpqdnFU972qO59tpP1+29pVorlWwILkmSJEm1ZNDU4C6//EoAUqr9h+Nrr/00b3vbHzI2tpOUEmNjO3nb2/7QsEktw4bgkiRJklRbBk0N7qUvfQUAn/jEVTV/r/e8552MjxdnjY2PF3nPe95Z8/eW6sGG4JIkSZJUWwZNDS4iAHjHO15f8/fateuuRY1LzcgZTZIkSZJUOwZNTeDqq/8egAMHDtT0fdatW7+ocakZGTRJkiRJUu0YNDWB5z//AgD++q/fU9P3ueyyd9HV1T1rrKurm8sue1dN31eqJxuCS5IkSVLtGDQ1iRNPPJn3ve8vavoeF154EZdffiU9Pb1EBD09vVx++ZVceOFFNX1fqZ4iYHLSoEmSJEmSaqEz6wK0MNdc8/ds2vQcisVH6O4+pmbvc+GFFxksqeVNTsLKlVlXIUmSJEmtxxlNTeKss54FwLvetSXjSqTmlhJMTpayLkOSJEmSWpJBUxN59KMfyyc+cVXWZUhNb3Iy6wokSZIkqTUZNDWRq676OwAeeOD+jCuRmtvRejQVCgX6+/vJ5XL09/dTKBTqVJkkSZIkNTeDpibyuMc9AYDLLnttxpVIzW1qClKaO2wqFAoMDAwwOjpKSonR0VEGBgYMmyRJkiRpAQyamswznvHf+OIXv5B1GVLTK83TpmlwcJBisThrrFgsMjg4WIeqJEmSJKm5GTQ1mQ9+8BoA7r57Z8aVSM0rYv7lczt3zv2zNd+4JEmSJOnnDJqazOmn9wF8JolyAAATWklEQVTwhje8IuNKpOZVfvLc3EFTb2/vosYlSZIkST9n0NSEXvjCC/n3f/961mVITW2+oGloaIju7u5ZY93d3QwNDdWjLEmSJElqagZNTWjr1isAuP32/8y4Eql5TU3NPZ7P5xkeHqavr4+IoK+vj+HhYfL5fH0LlCRJkqQm1Jl1AVq8k046GYBXvSrP1772vYyrkZrT1NTcM5qgHDYZLEmSJEnS4jmjqUldfPGr+NGPfpB1GVLTmu+pc5IkSZKkpTNoalLvfOd7ANix498yrkRqTgZNkiRJklR9Bk1Nqrv7GABe8YrfzrgSqXmVSvMvn5MkSZIkLZ5BUxN7y1veyYMP3p91GVJTinBWkyRJkiRVm0FTE3v967cA8M//vD3jSqTmdKSG4JIkSZKkxTNoamIrVqwA4JJLfifjSqTm5IwmSZIkSaoug6Ym9+53fxCAlJyZIS1GSs5o0lHccAP095f/liRJkrQgBk1N7uKLLwWgULg640qk5mMzcM3rhhvghS+E0dHy34ZNkiRJ0oIYNDW5iABg8+ZXZ1yJ1HxcOqc5TYdMxWJ5u1g0bJIkSZIWyKCpBVx11d8BMDk5mXElUnMxaNJhDg2Zphk2SZIkSQti0NQCfuu3XgzAhz70lxlXIjUXW5tplvlCpmmGTZIkSdJRGTS1iGOPPY6tW/846zKkpmITfc3y8pfPHzJNKxbL+0mSJEmak0FTi7jmms8DMD4+nnElUvNw6Zxm+djHoLv7yPt0d5f3kyRJkjQng6YWcc455wLwnvf8UbaFSE3ECU2a5dnPhn/8x/nDpu7u8uvPfnZ965IkSZKaiEFTC+nv/2U++tG/yboMqWkYNOkw84VNhkySJEnSghg0tZDh4U8DsHv3gxlXIjUHgybN6dCwyZBJkiRJWjCDphby+Mc/GYB3vOP1GVciNQ8bgmtO02FTX58hkyRJkrQIBk0tZsOGZ7J9+2ezLkOSmt+znw0jI4ZMkiRJ0iIYNLWQK67I8fKXl0OmXbvuPuz1m24KrrjCSy5JkiRJkmrD1KGFPPnJiXe+83TgXZxzThc9PZ087WmdXHttcNNNwaWXdvDkJ7tMSJrJlXNaikKhQH9/P7lcjv7+fgqFQtYlSZIkSQ2hM+sCVD3nnJN42ctKfPCDg0xMBABjY/DmN3ewYgV8/ONTnHOOn6olaTkKhQIDAwMUi0UARkdHGRgYACCfz2dZmiRJkpQ5ZzS1mC98IQfErLH9+4OuLgyZJKkKBgcHD4ZM04rFIoODgxlVJEmSJDUOg6YWs2vX3OP331/fOiSpVe3cuXNR45IkSVI7MWhqMevWLW5ckrQ4vb29ixqXJEmS2olBU4u57LIpVq48dIlc4kUvKmVSjyS1mqGhIbq7u2eNdXd3MzQ0lFFFkiRJUuMwaGoxp50GK1bAKackIhI9PYnXv77Epz6V46ab4ugHkCQdUT6fZ3h4mL6+PiKCvr4+hoeHbQQuSZIk4VPnWspNNwWXXtox59Pl/tt/S1x6aQdXXeWT56SZwvxVS5DP5w2WJEmSpDk4o6mFfPe7MW+QdM45iauumuK73/VTtSRJkiRJqg1nNLWQ17zmyH2YzjknOZtJOkQ4pUmSJEmSqqahZjRFxHkR8cOIuCMitmRdj6TWZsYkSZIkSdXVMEFTRHQAVwDPB84ELoqIM7OtSpIkSZIkSQvVMEET8HTgjpTSj1NK+4HPABdkXJOkFuaMJkmSJEmqrkYKmnqAu2Zs310Zk6SayDXSb0BJkiRJagFN1ww8IgaAAYDTTjuN73//32ryPvv27a3ZsXU4z3f9ec7LM5o6O+szrWnv3r3ceOONdXkveb7rzfMtSZKkaY0UNI0B62dsn14ZmyWlNAwMAzzpSb+WHv/4Z9WkmO9//9+o1bF1OM93/XnOYeXK4OST6/Nr8MYbb+Tcc8+ty3vJ811vnm9JkiRNa6SFI98EzoiIR0XESuAlwPUZ1ySphdmjSZIkSZKqq2FmNKWUJiPitcCXgQ7gmpTSrRmXJamF2aNJkiRJkqqrYYImgJTSl4AvZV2HpPZg0CRJkiRJ1eXHLEltq6PDtXOSJEmSVE0GTZLaUgTkcgZNkiRJklRNBk2S2lZHR9YVSJIkSVJrMWiS1Lac0SRJkiRJ1WXQJKktpeSMJkmSJEmqNoMmSW0pAiKc0SRJkiRJ1WTQJKktmTFJkiRJUvUZNElqSy6bkyRJkqTqM2iS1JZsBC5JkiRJ1WfQJKktdXZmXYEkSZIktR6DJkltJwI6O/31J0mSJEnV5ictSW3JGU2SJEmSVH0GTZLaTkrQ2WmPJkmSJEmqNoMmSW0nwmbgkiRJklQLBk2S2k5HR9YVSJIkSVJrMmiS1HZcNidJkiRJtWHQJKntGDRJkiRJUm0YNElqKxEGTZIkSZJUK039gO/vfe/b961bt3K0Roc/BbivRsfW4Tzf9ec5ry/Pd315vuurlue7r0bHlSRJUg00ddCUUlpbq2NHxC0ppQ21Or5m83zXn+e8vjzf9eX5ri/PtyRJkqa5dE6SJEmSJElVYdAkSZIkSZKkqjBomt9w1gW0Gc93/XnO68vzXV+e7/ryfEuSJAmASCllXYMkSZKayIYNG9Itt9ySdRmSJKlGIuJbS+3B6YwmSZIkSZIkVYVB0xwi4ryI+GFE3BERW7Kup9VExPqIuCEibouIWyPiDZXxkyLiXyLiR5W/T8y61lYSER0R8Z2I+MfK9qMiYkflPv9sRKzMusZWEREnRMTnI+IHEXF7RDzT+7t2IuJNld8l34+IT0fEau/v6oqIayLinoj4/oyxOe/pKPtg5dx/LyKeml3lkiRJqjeDpkNERAdwBfB84Ezgoog4M9uqWs4k8JaU0pnAM4DXVM7xFuArKaUzgK9UtlU9bwBun7H9XuD9KaVHAw8Cl2RSVWv6a+B/p5R+BXgS5fPu/V0DEdEDvB7YkFJ6PNABvATv72r7OHDeIWPz3dPPB86o/BkArqxTjZIkSWoABk2HezpwR0rpxyml/cBngAsyrqmlpJR+klL6duXrPZQ/hPdQPs+fqOz2CWBjNhW2nog4HfgfwEcr2wE8B/h8ZRfPd5VExPHAfweuBkgp7U8p7cb7u5Y6ga6I6AS6gZ/g/V1VKaWvAw8cMjzfPX0B8L9S2TeAEyLiF+tTqSRJkrJm0HS4HuCuGdt3V8ZUAxHRDzwF2AGcllL6SeWlnwKnZVRWK/oAsBkoVbZPBnanlCYr297n1fMo4F7gY5Wlih+NiGPw/q6JlNIY8JfATsoB00PAt/D+rof57mn/OypJktTGDJqUmYhYA3wBeGNK6eGZr6Xy4xB9JGIVRMQLgXtSSt/KupY20Qk8FbgypfQU4BEOWSbn/V09lb5AF1AO+NYBx3D4Ei/VmPe0JEmSphk0HW4MWD9j+/TKmKooIlZQDpkKKaVrK8M/m15eUfn7nqzqazHnAOdHxAjlpaDPodxD6ITKUiPwPq+mu4G7U0o7Ktufpxw8eX/XxvOAO1NK96aUDgDXUr7nvb9rb7572v+OSpIktTGDpsN9Ezij8sSilZSbyl6fcU0tpdIf6Grg9pTS+2a8dD1wceXri4F/qHdtrSildFlK6fSUUj/l+/mrKaU8cAPw4spunu8qSSn9FLgrIh5bGXoucBve37WyE3hGRHRXfrdMn2/v79qb756+Hvj9ytPnngE8NGOJnSRJklqcQdMhKj09Xgt8mXKT6s+llG7NtqqWcw7we8BzIuK7lT8vALYCvxERP6I8S2FrlkW2gbcDb46IOyj3bLo643payeuAQkR8D3gy8G68v2uiMnPs88C3gf+k/N+1Yby/qyoiPg38O/DYiLg7Ii5h/nv6S8CPgTuAjwCvzqBkzRAR50XEDyPijog47ImXEbEqIj5beX1HpX+iJEnSkkS5rYIkSZJaTUR0AP8F/Ablpb3fBC5KKd02Y59XA09MKb0qIl4CbEop/e6Rjrthw4Z0yy231LBySZKUpYj4Vkppw1K+1xlNkiRJrevpwB0ppR+nlPZT7tV3wSH7XAB8ovL154HnVpaiSpIkLZpBkyRJUuvqAe6asX13ZWzOfSotBB6ivORUkiRp0TqPvoskSZLaXUQMAAOVzYmI+H6W9egwpwD3ZV2EDuN1aTxek8bkdWk8jz36LnMzaJIkSWpdY8D6GdunV8bm2ufuiOgEjgfuP/RAKaVhys32iYhbltq3QbXhNWlMXpfG4zVpTF6XxhMRS27G6NI5SZKk1vVN4IyIeFRErAReAlx/yD7XAxdXvn4x8NXk02IkSdISGTRJqqqIWB8Rd0bESZXtEyvb/XV6/40R8ceL/J5/jYgTa1WTJGWl0nPptcCXgduBz6WUbo2IP4+I8yu7XQ2cHBF3AG8GtmRTrSRJagUunZNUVSmluyLiSmAr5V4eW4HhlNJInUrYDJx/1L1m+yTwamCo+uVIUrZSSl8CvnTI2B/P+Hof8NuLPOxwFUpTdXlNGpPXpfF4TRqT16XxLPmahDOjJVVbRKwAvgVcA7wSeHJK6cAh+/QD/7uy31OBW4HfTykVI+K5wF9SDsO/CfxhSmkiIrZSDpEmgf+TUnrrIcd8DHBVSunZle2PA+PAU4BTgVcAvw88E9iRUvqDyn4nAv9/SunxVT0RkiRJktRmXDonqeoqodLbgPcDbzw0ZJrhscCHUkqPAx4GXh0Rq4GPA7+bUnoC5bDpDyPiZGAT8KsppScCfzHH8c4Bvn3I2ImUg6U3Ue5D8n7gV4EnRMSTK/U+CKyqvIckSZIkaYkMmiTVyvOBnwBHmiV0V0rppsrXnwKeRTl8ujOl9F+V8U8A/x14CNgHXB0RFwLFOY73i8C9h4x9sdLU9j+Bn6WU/jOlVKI8g6p/xn73AOsW+P+bJLWFiDgvIn4YEXdExGG9myJiVUR8tvL6jnr142tnC7gmb46I2yLiexHxlYjoy6LOdnK0azJjvxdFRIoIn6xVBwu5LhHxO5Wfl1sj4u/qXWO7WcDvr96IuCEivlP5HfaCLOpsJxFxTUTcExHfn+f1iIgPVq7Z9yLiqQs5rkGTpKqrzBT6DeAZwJsi4hfn2fXQtbvzruWtNLR9OvB54IWUl90dahxYfcjYROXv0oyvp7dn9qlbXfl+SRIQER3AFZT/4eBM4KKIOPOQ3S4BHkwpPZryjNH31rfK9rLAa/IdYENl9u/ngW31rbK9LPCaEBHHAm8AdtS3wva0kOsSEWcAlwHnpJR+FXhj3QttIwv8Wfkjyg+teArlp6R+qL5VtqWPA+cd4fXnA2dU/gwAVy7koAZNkqoqIoLyL6A3ppR2ApdT7rc0l96IeGbl65cC/wb8EOiPiEdXxn8P+FpErAGOrzS1fRPwpDmOdzvw6DnGF1LzLwAji/1eSWphTwfuSCn9OKW0H/gMcMEh+1xAeeYplEON51Z+p6o2jnpNUko3pJSmZ/1+Azi9zjW2m4X8nAC8i3IQu6+exbWxhVyXVwJXVFookFK6p841tpuFXJMEHFf5+nhgVx3ra0sppa8DDxxhlwuA/5XKvgGccIRJBAcZNEmqtlcCO1NK/1LZ/hDwuIj49Tn2/SHwmoi4nXIvpSsrTz96OfD3EfGflGcefRg4FvjHiPge5UDqzXMc7+vAU5bwIefXgG9UZk1Jksp6gLtmbN9dGZtzn8rv0IcA+93VzkKuyUyXAP9c04p01GtSWWqyPqX0T/UsrM0t5GflMcBjIuKmiPhGRBxpVoeWbyHX5E+Bl0XE3ZSflvq6+pSmI1jsf3eA2ctGJGnZUkrDzHgUZkppivJT5eYymVJ62RzH+ArlJ8XN9BPK/xJypPcuRsS/As8F/nX6qXKV10aY0S9q5muUZ005NVeS1DIi4mXABmCuf+hRnUREDngf8AcZl6LDdVJeDnQu5Zl/X4+IJ6SUdmdaVXu7CPh4SumvKqsePhkRj6/0V1UTcUaTpFbzbqB7kd/z/Uq4JUn6uTFg/Yzt0ytjc+4TEZ2UlzrcX5fq2tNCrgkR8TxgEDg/pTRx6OuqqqNdk2Mp/0PXjRExQrl/5fU2BK+5hfys3A1cn1I6kFK6E/gvysGTamMh1+QS4HMAKaV/p9xD9ZS6VKf5LOi/O4cyaJKUiZTSSErpSE+kW+pxf5ZSun6R3/ORatchSS3gm8AZEfGoiFhJuTHrob9frwcurnz9YuCrlSd9qjaOek0i4inAVZRDJnvO1N4Rr0lK6aGU0ikppf6UUj/lvlnnp5RuyabctrGQ31/bKc9mIiJOobyU7sf1LLLNLOSa7KS8MoGIeBzloOnQJ0qrvq4Hfr/y9LlnAA+llH5ytG9y6ZwkSZIOk1KajIjXAl8GOoBrUkq3RsSfA7dUQv2rKS9tuINyM9GXZFdx61vgNbkcWEO51yGU+yaen1nRLW6B10R1tsDr8mXg/4uI24Ap4G0pJWdk1sgCr8lbgI9ExJsoNwb/A//xorYi4tOUA9dTKr2x/gRYAZBS+jDlXlkvAO4AipR76R79uF43SZIkSZIkVYNL5yRJkiRJklQVBk2SJEmSJEmqCoMmSZIkSZIkVYVBkyRJkiRJkqrCoEmSJEmSJElVYdAkSZIkSZKkqjBokiRJkiRJUlUYNEmSJEmSJKkq/h+2vqfH5eML3wAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "iffzAWwBELNL",
        "outputId": "e2e49548-2e67-4ce7-90a2-5c1ce488ef20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[]\n",
            "maxsize:  100000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-70-d7ab8b3d34d0>:22: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  self.done_memory = np.zeros((maxsize,), dtype= np.bool)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sum of gradients:  tf.Tensor(1089.3062, shape=(), dtype=float32)\n",
            "total reward after 0 steps is 56067.1893163841 and avg reward is 56067.1893163841\n",
            "sum of gradients:  tf.Tensor(1132.0, shape=(), dtype=float32)\n",
            "total reward after 1 steps is 86872.11084221276 and avg reward is 71469.65007929843\n",
            "sum of gradients:  tf.Tensor(1132.0, shape=(), dtype=float32)\n",
            "total reward after 2 steps is 64826.00542951083 and avg reward is 69255.10186270256\n",
            "sum of gradients:  tf.Tensor(1340.0, shape=(), dtype=float32)\n",
            "total reward after 3 steps is 190557.19651447097 and avg reward is 99580.62552564466\n",
            "sum of gradients:  tf.Tensor(1340.0, shape=(), dtype=float32)\n",
            "total reward after 4 steps is 112420.16337255116 and avg reward is 102148.53309502595\n",
            "sum of gradients:  tf.Tensor(1372.0, shape=(), dtype=float32)\n",
            "total reward after 5 steps is 132408.58939681342 and avg reward is 107191.87581199054\n",
            "sum of gradients:  tf.Tensor(1372.0, shape=(), dtype=float32)\n",
            "total reward after 6 steps is 154791.61596421184 and avg reward is 113991.8386908793\n",
            "sum of gradients:  tf.Tensor(1372.0, shape=(), dtype=float32)\n",
            "total reward after 7 steps is 106374.29090813291 and avg reward is 113039.64521803599\n",
            "sum of gradients:  tf.Tensor(1396.9877, shape=(), dtype=float32)\n",
            "total reward after 8 steps is 157444.86700954236 and avg reward is 117973.5587504256\n",
            "sum of gradients:  tf.Tensor(1404.0, shape=(), dtype=float32)\n",
            "total reward after 9 steps is 98265.27159648396 and avg reward is 116002.73003503142\n",
            "sum of gradients:  tf.Tensor(1424.0, shape=(), dtype=float32)\n",
            "total reward after 10 steps is 159448.97596587203 and avg reward is 119952.38875601692\n",
            "sum of gradients:  tf.Tensor(1424.0, shape=(), dtype=float32)\n",
            "total reward after 11 steps is 125363.8069756285 and avg reward is 120403.34027431789\n",
            "sum of gradients:  tf.Tensor(1540.0, shape=(), dtype=float32)\n",
            "total reward after 12 steps is 179899.9966123594 and avg reward is 124980.00614647492\n",
            "sum of gradients:  tf.Tensor(1540.0, shape=(), dtype=float32)\n",
            "total reward after 13 steps is 178535.13606060253 and avg reward is 128805.3725689126\n",
            "sum of gradients:  tf.Tensor(1540.0, shape=(), dtype=float32)\n",
            "total reward after 14 steps is 162826.90632950558 and avg reward is 131073.4748196188\n",
            "sum of gradients:  tf.Tensor(1540.0, shape=(), dtype=float32)\n",
            "total reward after 15 steps is 83966.80913899625 and avg reward is 128129.30821457991\n",
            "sum of gradients:  tf.Tensor(1540.0, shape=(), dtype=float32)\n",
            "total reward after 16 steps is 73299.43455636555 and avg reward is 124904.0215288026\n",
            "sum of gradients:  tf.Tensor(1540.0, shape=(), dtype=float32)\n",
            "total reward after 17 steps is 175512.04903038742 and avg reward is 127715.57861222397\n",
            "sum of gradients:  tf.Tensor(1540.0, shape=(), dtype=float32)\n",
            "total reward after 18 steps is 176549.21592554022 and avg reward is 130285.77004976693\n",
            "sum of gradients:  tf.Tensor(1540.0, shape=(), dtype=float32)\n",
            "total reward after 19 steps is 123588.00110460269 and avg reward is 129950.88160250871\n",
            "sum of gradients:  tf.Tensor(1540.0, shape=(), dtype=float32)\n",
            "total reward after 20 steps is 106382.33508491376 and avg reward is 128828.56986357563\n",
            "sum of gradients:  tf.Tensor(1540.0, shape=(), dtype=float32)\n",
            "total reward after 21 steps is 132508.65608859516 and avg reward is 128995.84651016742\n",
            "sum of gradients:  tf.Tensor(1540.0, shape=(), dtype=float32)\n",
            "total reward after 22 steps is 144214.24641665525 and avg reward is 129657.51607131907\n",
            "sum of gradients:  tf.Tensor(1540.0, shape=(), dtype=float32)\n",
            "total reward after 23 steps is 146080.9606032766 and avg reward is 130341.82626015064\n",
            "sum of gradients:  tf.Tensor(1540.0, shape=(), dtype=float32)\n",
            "total reward after 24 steps is 126624.24839382291 and avg reward is 130193.12314549754\n",
            "sum of gradients:  tf.Tensor(1540.0, shape=(), dtype=float32)\n",
            "total reward after 25 steps is 171421.5602808539 and avg reward is 131778.83226608817\n",
            "sum of gradients:  tf.Tensor(1540.0, shape=(), dtype=float32)\n",
            "total reward after 26 steps is 192934.62473903384 and avg reward is 134043.861616938\n",
            "sum of gradients:  tf.Tensor(1540.0, shape=(), dtype=float32)\n",
            "total reward after 27 steps is 216066.38136244623 and avg reward is 136973.23732213472\n",
            "sum of gradients:  tf.Tensor(1540.0, shape=(), dtype=float32)\n",
            "total reward after 28 steps is 159974.59707734827 and avg reward is 137766.3876585214\n",
            "sum of gradients:  tf.Tensor(1540.0, shape=(), dtype=float32)\n",
            "total reward after 29 steps is 126782.40306211248 and avg reward is 137400.2548386411\n",
            "sum of gradients:  tf.Tensor(1540.0, shape=(), dtype=float32)\n",
            "total reward after 30 steps is 72239.20043495609 and avg reward is 135298.28534174804\n",
            "sum of gradients:  tf.Tensor(1540.0, shape=(), dtype=float32)\n",
            "total reward after 31 steps is 46776.60963688735 and avg reward is 132531.98297597113\n",
            "sum of gradients:  tf.Tensor(1540.0, shape=(), dtype=float32)\n",
            "total reward after 32 steps is 112289.2669500529 and avg reward is 131918.5673388221\n",
            "sum of gradients:  tf.Tensor(1540.0, shape=(), dtype=float32)\n",
            "total reward after 33 steps is 194037.24942269025 and avg reward is 133745.58740011233\n",
            "sum of gradients:  tf.Tensor(1540.0, shape=(), dtype=float32)\n",
            "total reward after 34 steps is 106052.63773989261 and avg reward is 132954.3602669632\n",
            "sum of gradients:  tf.Tensor(1540.0, shape=(), dtype=float32)\n",
            "total reward after 35 steps is 204114.29925812993 and avg reward is 134931.02523894006\n",
            "sum of gradients:  tf.Tensor(1540.0, shape=(), dtype=float32)\n",
            "total reward after 36 steps is 165076.34259001544 and avg reward is 135745.76354572587\n",
            "sum of gradients:  tf.Tensor(1540.0, shape=(), dtype=float32)\n",
            "total reward after 37 steps is 89955.59159644989 and avg reward is 134540.7590207449\n",
            "sum of gradients:  tf.Tensor(1540.0, shape=(), dtype=float32)\n",
            "total reward after 38 steps is 184192.1008279329 and avg reward is 135813.87034913438\n",
            "sum of gradients:  tf.Tensor(1540.0, shape=(), dtype=float32)\n",
            "total reward after 39 steps is 128172.14919552044 and avg reward is 135622.82732029402\n",
            "sum of gradients:  tf.Tensor(1540.0, shape=(), dtype=float32)\n",
            "total reward after 40 steps is 86169.1945461816 and avg reward is 134416.64115507176\n",
            "sum of gradients:  tf.Tensor(1540.0, shape=(), dtype=float32)\n",
            "total reward after 41 steps is 160768.8627472495 and avg reward is 135044.07500250457\n",
            "sum of gradients:  tf.Tensor(1540.0, shape=(), dtype=float32)\n",
            "total reward after 42 steps is 101512.36429226646 and avg reward is 134264.26777668507\n",
            "sum of gradients:  tf.Tensor(1540.0, shape=(), dtype=float32)\n",
            "total reward after 43 steps is 144905.319949871 and avg reward is 134506.1098715302\n",
            "sum of gradients:  tf.Tensor(1540.0, shape=(), dtype=float32)\n",
            "total reward after 44 steps is 133486.97408453605 and avg reward is 134483.462409597\n",
            "sum of gradients:  tf.Tensor(1540.0, shape=(), dtype=float32)\n",
            "total reward after 45 steps is 65209.01945463809 and avg reward is 132977.49625840224\n",
            "sum of gradients:  tf.Tensor(1540.0, shape=(), dtype=float32)\n",
            "total reward after 46 steps is 197055.750859409 and avg reward is 134340.8633775726\n",
            "sum of gradients:  tf.Tensor(1540.0, shape=(), dtype=float32)\n",
            "total reward after 47 steps is 47994.1259801435 and avg reward is 132541.97301512616\n",
            "sum of gradients:  tf.Tensor(1540.0, shape=(), dtype=float32)\n",
            "total reward after 48 steps is 185317.67504260363 and avg reward is 133619.02815854404\n",
            "sum of gradients:  tf.Tensor(1540.0, shape=(), dtype=float32)\n",
            "total reward after 49 steps is 114091.57481044381 and avg reward is 133228.47909158203\n",
            "sum of gradients:  tf.Tensor(1540.0, shape=(), dtype=float32)\n",
            "total reward after 50 steps is 75290.92721807909 and avg reward is 132092.4486626898\n",
            "sum of gradients:  tf.Tensor(1540.0, shape=(), dtype=float32)\n",
            "total reward after 51 steps is 122205.80615850116 and avg reward is 131902.32092222464\n",
            "sum of gradients:  tf.Tensor(1540.0, shape=(), dtype=float32)\n",
            "total reward after 52 steps is 152215.74100295463 and avg reward is 132285.59299921955\n",
            "sum of gradients:  tf.Tensor(1540.0, shape=(), dtype=float32)\n",
            "total reward after 53 steps is 162970.53371145725 and avg reward is 132853.83264203876\n",
            "sum of gradients:  tf.Tensor(1540.0, shape=(), dtype=float32)\n",
            "total reward after 54 steps is 153533.50046732964 and avg reward is 133229.8266024986\n",
            "sum of gradients:  tf.Tensor(1540.0, shape=(), dtype=float32)\n",
            "total reward after 55 steps is 148279.4060718968 and avg reward is 133498.5690930236\n",
            "sum of gradients:  tf.Tensor(1540.0, shape=(), dtype=float32)\n",
            "total reward after 56 steps is 166502.0876780889 and avg reward is 134077.5781910072\n",
            "sum of gradients:  tf.Tensor(1540.0, shape=(), dtype=float32)\n",
            "total reward after 57 steps is 126080.854265736 and avg reward is 133939.7036405715\n",
            "sum of gradients:  tf.Tensor(1540.0, shape=(), dtype=float32)\n",
            "total reward after 58 steps is 149265.19360379185 and avg reward is 134199.45770774473\n",
            "sum of gradients:  tf.Tensor(1540.0, shape=(), dtype=float32)\n",
            "total reward after 59 steps is 109776.77939833941 and avg reward is 133792.41306925463\n",
            "sum of gradients:  tf.Tensor(1540.0, shape=(), dtype=float32)\n",
            "total reward after 60 steps is 87713.86414476582 and avg reward is 133037.0270213122\n",
            "sum of gradients:  tf.Tensor(1540.0, shape=(), dtype=float32)\n",
            "total reward after 61 steps is 147851.1777291429 and avg reward is 133275.96493595463\n",
            "sum of gradients:  tf.Tensor(1544.0, shape=(), dtype=float32)\n",
            "total reward after 62 steps is 181147.11387495822 and avg reward is 134035.82444292295\n",
            "sum of gradients:  tf.Tensor(1544.0, shape=(), dtype=float32)\n",
            "total reward after 63 steps is 168979.64110556888 and avg reward is 134581.82157827678\n",
            "sum of gradients:  tf.Tensor(1544.0, shape=(), dtype=float32)\n",
            "total reward after 64 steps is 48405.553959346915 and avg reward is 133256.03284567787\n",
            "sum of gradients:  tf.Tensor(1544.0, shape=(), dtype=float32)\n",
            "total reward after 65 steps is 161359.84795757057 and avg reward is 133681.8482261611\n",
            "sum of gradients:  tf.Tensor(1544.0, shape=(), dtype=float32)\n",
            "total reward after 66 steps is 172219.09223188562 and avg reward is 134257.0309725152\n",
            "sum of gradients:  tf.Tensor(1544.0, shape=(), dtype=float32)\n",
            "total reward after 67 steps is 79716.89736342152 and avg reward is 133454.9701841462\n",
            "sum of gradients:  tf.Tensor(1544.0, shape=(), dtype=float32)\n",
            "total reward after 68 steps is 147106.42123587892 and avg reward is 133652.81730083795\n",
            "sum of gradients:  tf.Tensor(1544.0, shape=(), dtype=float32)\n",
            "total reward after 69 steps is 164687.48825162186 and avg reward is 134096.169742992\n",
            "sum of gradients:  tf.Tensor(1544.0, shape=(), dtype=float32)\n",
            "total reward after 70 steps is 70787.9644519554 and avg reward is 133204.50487973797\n",
            "sum of gradients:  tf.Tensor(1544.0, shape=(), dtype=float32)\n",
            "total reward after 71 steps is 177427.31971549988 and avg reward is 133818.71064134577\n",
            "sum of gradients:  tf.Tensor(1544.0, shape=(), dtype=float32)\n",
            "total reward after 72 steps is 63103.90549021277 and avg reward is 132850.01468037133\n",
            "sum of gradients:  tf.Tensor(1544.0, shape=(), dtype=float32)\n",
            "total reward after 73 steps is 58726.00704031211 and avg reward is 131848.3389014516\n",
            "sum of gradients:  tf.Tensor(1544.0, shape=(), dtype=float32)\n",
            "total reward after 74 steps is 171400.31684518032 and avg reward is 132375.698607368\n",
            "sum of gradients:  tf.Tensor(1544.0, shape=(), dtype=float32)\n",
            "total reward after 75 steps is 133000.44764447302 and avg reward is 132383.91898943516\n",
            "sum of gradients:  tf.Tensor(1544.0, shape=(), dtype=float32)\n",
            "total reward after 76 steps is 179818.17661106284 and avg reward is 132999.94830919654\n",
            "sum of gradients:  tf.Tensor(1544.0, shape=(), dtype=float32)\n",
            "total reward after 77 steps is 188043.8819717781 and avg reward is 133705.63976640912\n",
            "sum of gradients:  tf.Tensor(1544.0, shape=(), dtype=float32)\n",
            "total reward after 78 steps is 61234.7620775061 and avg reward is 132788.28688427113\n",
            "sum of gradients:  tf.Tensor(1544.0, shape=(), dtype=float32)\n",
            "total reward after 79 steps is 121242.26606192043 and avg reward is 132643.96162399175\n",
            "sum of gradients:  tf.Tensor(1544.0, shape=(), dtype=float32)\n",
            "total reward after 80 steps is 158665.25625872004 and avg reward is 132965.21217503777\n",
            "sum of gradients:  tf.Tensor(1544.0, shape=(), dtype=float32)\n",
            "total reward after 81 steps is 72340.33608043763 and avg reward is 132225.88441778655\n",
            "sum of gradients:  tf.Tensor(1544.0, shape=(), dtype=float32)\n",
            "total reward after 82 steps is 127871.7851788817 and avg reward is 132173.42539081178\n",
            "sum of gradients:  tf.Tensor(1544.0, shape=(), dtype=float32)\n",
            "total reward after 83 steps is 166072.25642094712 and avg reward is 132576.98290307532\n",
            "sum of gradients:  tf.Tensor(1544.0, shape=(), dtype=float32)\n",
            "total reward after 84 steps is 168527.3980342799 and avg reward is 132999.92896344242\n",
            "sum of gradients:  tf.Tensor(1544.0, shape=(), dtype=float32)\n",
            "total reward after 85 steps is 183732.45587726374 and avg reward is 133589.84206709152\n",
            "sum of gradients:  tf.Tensor(1544.0, shape=(), dtype=float32)\n",
            "total reward after 86 steps is 128241.47074491644 and avg reward is 133528.3665346527\n",
            "sum of gradients:  tf.Tensor(1544.0, shape=(), dtype=float32)\n",
            "total reward after 87 steps is 131794.41470109738 and avg reward is 133508.66253654414\n",
            "sum of gradients:  tf.Tensor(1544.0, shape=(), dtype=float32)\n",
            "total reward after 88 steps is 203899.83670894915 and avg reward is 134299.574605897\n",
            "sum of gradients:  tf.Tensor(1544.0, shape=(), dtype=float32)\n",
            "total reward after 89 steps is 83391.78485807615 and avg reward is 133733.93249758787\n",
            "sum of gradients:  tf.Tensor(1544.0, shape=(), dtype=float32)\n",
            "total reward after 90 steps is 136990.01477054245 and avg reward is 133769.7136214665\n",
            "sum of gradients:  tf.Tensor(1544.0, shape=(), dtype=float32)\n",
            "total reward after 91 steps is 93307.4968058893 and avg reward is 133329.90691694937\n",
            "sum of gradients:  tf.Tensor(1544.0, shape=(), dtype=float32)\n",
            "total reward after 92 steps is 174993.88335645874 and avg reward is 133777.90666361077\n",
            "sum of gradients:  tf.Tensor(1544.0, shape=(), dtype=float32)\n",
            "total reward after 93 steps is 195022.86279406445 and avg reward is 134429.44875010496\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-70-d7ab8b3d34d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    247\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m             \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m         \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcritic_1_gradient_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m         \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0mtotal_reward\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-70-d7ab8b3d34d0>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, s, gradient_list, done)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m       \u001b[0mgrads1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcritic_loss1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcritic_main\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m       \u001b[0;31m# print(\"grads: \", grads1[0])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m       \u001b[0;31m# print(\"gradient list length: \", type(grads1[0]))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                           for x in output_gradients]\n\u001b[1;32m   1099\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m     flat_grad = imperative_grad.imperative_grad(\n\u001b[0m\u001b[1;32m   1101\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m         \u001b[0mflat_targets\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     65\u001b[0m         \"Unknown value for unconnected_gradients: %r\" % unconnected_gradients)\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m   return pywrap_tfe.TFE_Py_TapeGradient(\n\u001b[0m\u001b[1;32m     68\u001b[0m       \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36m_gradient_function\u001b[0;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0mgradient_name_scope\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mforward_pass_name_scope\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradient_name_scope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/math_grad.py\u001b[0m in \u001b[0;36m_MatMulGrad\u001b[0;34m(op, grad)\u001b[0m\n\u001b[1;32m   1739\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mt_a\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mt_b\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1740\u001b[0m     \u001b[0mgrad_a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmat_mul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspose_b\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1741\u001b[0;31m     \u001b[0mgrad_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmat_mul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspose_a\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1742\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mt_a\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mt_b\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1743\u001b[0m     \u001b[0mgrad_a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmat_mul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mmat_mul\u001b[0;34m(a, b, transpose_a, transpose_b, name)\u001b[0m\n\u001b[1;32m   6011\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6012\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6013\u001b[0;31m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[1;32m   6014\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"MatMul\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"transpose_a\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspose_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"transpose_b\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6015\u001b[0m         transpose_b)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "print(tf.config.list_physical_devices('GPU'))\n",
        "\n",
        "state_low = env.state_space.low\n",
        "state_high = env.state_space.high\n",
        "action_low = env.action_space.low \n",
        "action_high = env.action_space.high\n",
        "# print(state_low)\n",
        "# print(state_high)\n",
        "# print(action_low)\n",
        "# print(action_high)\n",
        "\n",
        "\n",
        "class RBuffer():\n",
        "  def __init__(self, maxsize, statedim, naction):\n",
        "    print(\"maxsize: \", maxsize)\n",
        "    self.cnt = 0\n",
        "    self.maxsize = maxsize\n",
        "    self.state_memory = np.zeros((maxsize, *statedim), dtype=np.float32)\n",
        "    self.action_memory = np.zeros((maxsize, naction), dtype=np.float32)\n",
        "    self.reward_memory = np.zeros((maxsize,), dtype=np.float32)\n",
        "    self.next_state_memory = np.zeros((maxsize, *statedim), dtype=np.float32)\n",
        "    self.done_memory = np.zeros((maxsize,), dtype= np.bool)\n",
        "\n",
        "  def storexp(self, state, next_state, action, done, reward):\n",
        "    index = self.cnt % self.maxsize\n",
        "    self.state_memory[index] = state\n",
        "    self.action_memory[index] = action\n",
        "    self.reward_memory[index] = reward\n",
        "    self.next_state_memory[index] = next_state\n",
        "    self.done_memory[index] = 1- int(done)\n",
        "    self.cnt += 1\n",
        "\n",
        "  def sample(self, batch_size):\n",
        "    max_mem = min(self.cnt, self.maxsize)\n",
        "    batch = np.random.choice(max_mem, batch_size, replace= False)  \n",
        "    states = self.state_memory[batch]\n",
        "    next_states = self.next_state_memory[batch]\n",
        "    rewards = self.reward_memory[batch]\n",
        "    actions = self.action_memory[batch]\n",
        "    dones = self.done_memory[batch]\n",
        "    return states, next_states, rewards, actions, dones\n",
        "\n",
        "\n",
        "class Critic(tf.keras.Model):\n",
        "  def __init__(self):\n",
        "    super(Critic, self).__init__()\n",
        "    self.f1 = tf.keras.layers.Dense(512, activation='relu')\n",
        "    self.f2 = tf.keras.layers.Dense(512, activation='relu')\n",
        "    self.v =  tf.keras.layers.Dense(1, activation=None)\n",
        "\n",
        "  def call(self, inputstate, action):\n",
        "    x = self.f1(tf.concat([inputstate, action], axis=1))\n",
        "    x = self.f2(x)\n",
        "    x = self.v(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "class Actor(tf.keras.Model):\n",
        "  def __init__(self, no_action):\n",
        "    super(Actor, self).__init__()    \n",
        "    self.f1 = tf.keras.layers.Dense(512, activation='relu')\n",
        "    self.f2 = tf.keras.layers.Dense(512, activation='relu')\n",
        "    self.mu =  tf.keras.layers.Dense(no_action, activation='tanh')\n",
        "\n",
        "  def call(self, state):\n",
        "    x = self.f1(state)\n",
        "    x = self.f2(x)\n",
        "    x = self.mu(x)  \n",
        "    return x\n",
        "\n",
        " \n",
        "\n",
        "class Agent():\n",
        "  def __init__(self, n_action= len(env.action_space.high)):\n",
        "    self.actor_main = Actor(n_action)\n",
        "    self.actor_target = Actor(n_action)\n",
        "    self.critic_main = Critic()\n",
        "    self.critic_main2 = Critic()\n",
        "    self.critic_target = Critic()\n",
        "    self.critic_target2 = Critic()\n",
        "    self.batch_size = 64\n",
        "    self.n_actions = len(env.action_space.high)\n",
        "    self.a_opt = tf.keras.optimizers.Adam(0.0001)  # 0.001\n",
        "    # self.actor_target = tf.keras.optimizers.Adam(0.0001)  # 0.001\n",
        "    self.c_opt1 = tf.keras.optimizers.Adam(0.0002)  # 0.002\n",
        "    self.c_opt2 = tf.keras.optimizers.Adam(0.0002)  # 0.002\n",
        "    # self.critic_target = tf.keras.optimizers.Adam(0.0002)  # 0.002\n",
        "    self.memory = RBuffer(1_00_000, env.state_space.shape, len(env.action_space.high))\n",
        "    self.trainstep = 0\n",
        "    #self.replace = 5\n",
        "    self.gamma = 0.99\n",
        "    self.min_action = env.action_space.low\n",
        "    self.max_action = env.action_space.high\n",
        "    self.actor_update_steps = 2\n",
        "    self.warmup = 200\n",
        "    self.actor_target.compile(optimizer=self.a_opt)\n",
        "    self.critic_target.compile(optimizer=self.c_opt1)\n",
        "    self.critic_target2.compile(optimizer=self.c_opt2)\n",
        "    self.tau = 0.005\n",
        "    \n",
        "\n",
        "  def act(self, state, evaluate=False):\n",
        "      if self.trainstep > self.warmup:\n",
        "            evaluate = True\n",
        "      state = tf.convert_to_tensor([state], dtype=tf.float32)\n",
        "      actions = self.actor_main(state)\n",
        "      if not evaluate:\n",
        "          actions += tf.random.normal(shape=[self.n_actions], mean=0.0, stddev=0.1)\n",
        "\n",
        "      actions = self.max_action * (tf.clip_by_value(actions, self.min_action, self.max_action))\n",
        "      # print(\"actions: \", actions)\n",
        "      return actions\n",
        "\n",
        "\n",
        "  def savexp(self,state, next_state, action, done, reward):\n",
        "        self.memory.storexp(state, next_state, action, done, reward)\n",
        "\n",
        "  def update_target(self, tau=None):\n",
        "  \n",
        "    if tau is None:\n",
        "        tau = self.tau\n",
        "\n",
        "    weights1 = []\n",
        "    targets1 = self.actor_target.weights\n",
        "    for i, weight in enumerate(self.actor_main.weights):\n",
        "        weights1.append(weight * tau + targets1[i]*(1-tau))\n",
        "    self.actor_target.set_weights(weights1)\n",
        "\n",
        "    weights2 = []\n",
        "    targets2 = self.critic_target.weights\n",
        "    for i, weight in enumerate(self.critic_main.weights):\n",
        "        weights2.append(weight * tau + targets2[i]*(1-tau))\n",
        "    self.critic_target.set_weights(weights2)\n",
        "\n",
        "\n",
        "    weights3 = []\n",
        "    targets3 = self.critic_target2.weights\n",
        "    for i, weight in enumerate(self.critic_main2.weights):\n",
        "        weights3.append(weight * tau + targets3[i]*(1-tau))\n",
        "    self.critic_target2.set_weights(weights3)\n",
        "\n",
        "  \n",
        "  def train(self, s=0, gradient_list=None, done=False):\n",
        "      if self.memory.cnt < self.batch_size:\n",
        "        return \n",
        "\n",
        "\n",
        "      states, next_states, rewards, actions, dones = self.memory.sample(self.batch_size)\n",
        "  \n",
        "      states = tf.convert_to_tensor(states, dtype= tf.float32)\n",
        "      next_states = tf.convert_to_tensor(next_states, dtype= tf.float32)\n",
        "      rewards = tf.convert_to_tensor(rewards, dtype= tf.float32)\n",
        "      actions = tf.convert_to_tensor(actions, dtype= tf.float32)\n",
        "      #dones = tf.convert_to_tensor(dones, dtype= tf.bool)\n",
        "\n",
        "      with tf.GradientTape() as tape1, tf.GradientTape() as tape2:\n",
        "            \n",
        "          target_actions = self.actor_target(next_states)\n",
        "          target_actions += tf.clip_by_value(tf.random.normal(shape=[*np.shape(target_actions)], mean=0.0, stddev=0.1), -0.2, 0.2)\n",
        "          target_actions = self.max_action * (tf.clip_by_value(target_actions, self.min_action, self.max_action))\n",
        "          \n",
        "          \n",
        "          target_next_state_values = tf.squeeze(self.critic_target(next_states, target_actions), 1)\n",
        "          target_next_state_values2 = tf.squeeze(self.critic_target2(next_states, target_actions), 1)\n",
        "          \n",
        "          critic_value = tf.squeeze(self.critic_main(states, actions), 1)\n",
        "          critic_value2 = tf.squeeze(self.critic_main2(states, actions), 1)\n",
        "          \n",
        "          next_state_target_value = tf.math.minimum(target_next_state_values, target_next_state_values2)\n",
        "          \n",
        "          target_values = rewards + (self.gamma * next_state_target_value * dones)\n",
        "\n",
        "          critic_loss1 = tf.keras.losses.MSE(target_values, critic_value)\n",
        "          critic_loss2 = tf.keras.losses.MSE(target_values, critic_value2)\n",
        "          \n",
        "\n",
        "\n",
        "      \n",
        "      grads1 = tape1.gradient(critic_loss1, self.critic_main.trainable_variables)\n",
        "      # print(\"grads: \", grads1[0])\n",
        "      # print(\"gradient list length: \", type(grads1[0]))\n",
        "      grads1 = [tf.clip_by_value(grad, -1., 1.) for grad in grads1]\n",
        "      # print(\"length of gradients: \", len(grads1[0]))\n",
        "      if(done):\n",
        "          print(\"sum of gradients: \", tf.math.reduce_sum(tf.math.abs(grads1[0])))\n",
        "      # print(\"max gradient value: \", tf.math.reduce_max(grads1[0]))\n",
        "      # print(\"min gradient value: \", tf.math.reduce_min(grads1[0]))\n",
        "      if((s%100) == 0):\n",
        "          gradient_list.append(grads1)\n",
        "      \n",
        "\n",
        "      grads2 = tape2.gradient(critic_loss2, self.critic_main2.trainable_variables)\n",
        "      # print(\"gradient list length: \", len(grads2))\n",
        "      grads2 = [tf.clip_by_value(grad, -1., 1.) for grad in grads2]\n",
        "      # print(\"clipped max gradient: \", tf.math.reduce_max(grads1[0]))\n",
        "      # print(\"clipped min gradient: \", tf.math.reduce_min(grads1[0]))\n",
        "\n",
        "      self.c_opt1.apply_gradients(zip(grads1, self.critic_main.trainable_variables))\n",
        "      self.c_opt2.apply_gradients(zip(grads2, self.critic_main2.trainable_variables))\n",
        "      \n",
        "      \n",
        "      self.trainstep +=1\n",
        "      \n",
        "      if self.trainstep % self.actor_update_steps == 0:\n",
        "                \n",
        "          with tf.GradientTape() as tape3:\n",
        "            \n",
        "              new_policy_actions = self.actor_main(states)\n",
        "              actor_loss = -self.critic_main(states, new_policy_actions)\n",
        "              actor_loss = tf.math.reduce_mean(actor_loss)\n",
        "          \n",
        "          grads3 = tape3.gradient(actor_loss, self.actor_main.trainable_variables)\n",
        "          # print(\"gradient list length: \", len(grads3))\n",
        "          grads3 = [tf.clip_by_value(grad, -1., 1.) for grad in grads3]\n",
        "          self.a_opt.apply_gradients(zip(grads3, self.actor_main.trainable_variables))\n",
        "\n",
        "      #if self.trainstep % self.replace == 0:\n",
        "      self.update_target()\n",
        "           \n",
        "      \n",
        "\n",
        "critic_1_gradient_list = []\n",
        "reward_array = []\n",
        "\n",
        "\n",
        "with tf.device('GPU:0'):\n",
        "    tf.random.set_seed(336699)\n",
        "    agent = Agent()\n",
        "    episods = 20000\n",
        "    ep_reward = []\n",
        "    total_avgr = []\n",
        "    target = False\n",
        "\n",
        "    for s in range(episods):\n",
        "      if target == True:\n",
        "        break\n",
        "      total_reward = 0 \n",
        "      state = env.reset()\n",
        "      done = False\n",
        "\n",
        "      while not done:\n",
        "        #env.render()\n",
        "        action = agent.act(state)\n",
        "        # print(\"action: \", action)\n",
        "        next_state, reward, done, _ = env.step(action)\n",
        "        cnt = 10 if (reward>0) else 1\n",
        "        for i in range(cnt):\n",
        "            agent.savexp(state, next_state, action, done, reward)\n",
        "        agent.train(s, critic_1_gradient_list, done)\n",
        "        state = next_state\n",
        "        total_reward += reward\n",
        "        if done:\n",
        "            reward_array.append(total_reward)\n",
        "            ep_reward.append(total_reward)\n",
        "            avg_reward = np.mean(ep_reward[-100:])\n",
        "            total_avgr.append(avg_reward)\n",
        "            print(\"total reward after {} steps is {} and avg reward is {}\".format(s, total_reward, avg_reward))\n",
        "            # if int(avg_reward) == 200:\n",
        "            #   target = True\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "pbetdlMZCfYb",
        "outputId": "ed494a44-9351-4331-fb3e-15f820f83495"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.plot(np.arange(len(total_avgr)), total_avgr)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_learnt_policy():\n",
        "\n",
        "    n_points = 10\n",
        "    position_action_list = []\n",
        "    for i in range(n_points):\n",
        "        x = np.random.uniform(0, env.boundary_x)\n",
        "        y = np.random.uniform(0, env.boundary_y)\n",
        "        # x = env.boundary_x\n",
        "        # y = env.boundary_y\n",
        "        # print(\"current_state: \", x, y)\n",
        "        action = np.array(agent.act([x, y])).flatten()\n",
        "        print(\"action: \", action)\n",
        "        position_action_list.append(([x, y], action))\n",
        "    env.render(learnt_policy_visualization = True, position_action_list = position_action_list)\n",
        "\n",
        "plot_learnt_policy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 760
        },
        "id": "hmfw6oYIh-lM",
        "outputId": "e24b056b-6169-4be3-fb41-ba88958bfd97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "action:  [-1.  1.]\n",
            "action:  [-1.  1.]\n",
            "action:  [-1.  1.]\n",
            "action:  [-1.  1.]\n",
            "action:  [-1.  1.]\n",
            "action:  [-1.  1.]\n",
            "action:  [-1.  1.]\n",
            "action:  [-1.  1.]\n",
            "action:  [-1.  1.]\n",
            "action:  [-1.  1.]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1440x720 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "50HYFK6TAA7o"
      },
      "outputs": [],
      "source": [
        "\n",
        "bins = [i for i in range(-100, 100, 40)]\n",
        "plt.hist(critic_1_gradient_list[4][2], bins=bins)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "03np-_tnG2yG",
        "outputId": "94a402ec-5a38-4605-cc5f-574ca3706eff"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x7200 with 20 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "bins = [i for i in range(-100, 100, 40)]\n",
        "fig, ax = plt.subplots(20, figsize =(5, 100))\n",
        "for i in range(20):\n",
        "  ax[i].hist(critic_1_gradient_list[i*20][5], bins=bins)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sL0dAs6R19zb"
      },
      "outputs": [],
      "source": [
        "def run_random_episode(agent):\n",
        "    '''\n",
        "    Helper function to visualize training\n",
        "    This function runs an entire episode using the policy output by the actor network, \\\n",
        "    and plots the UAV position graph at 10 equally spaced timesteps. \n",
        "    '''\n",
        "    obs = env.reset()\n",
        "    num_figs = 10\n",
        "    gap_ = 1\n",
        "    done = False\n",
        "    i = 0\n",
        "    fig, axes = plt.subplots(num_figs, 2, figsize=(10, 100))\n",
        "    while not done:\n",
        "        action = agent.act(np.array(obs))\n",
        "        obs, reward, done, _ = env.step(action)\n",
        "        if((i % gap_ == 0) and (i / gap_ < num_figs)):\n",
        "            env.render(fig = fig, ax = axes, i = int(i // gap_), reward = reward)\n",
        "        i += 1\n",
        "    return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "YyXrMufI1rtI",
        "outputId": "f5062c30-df71-44cd-dc5f-52edc4eeddc8"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x7200 with 20 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "run_random_episode(agent)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cFoOf-MYf-Ep"
      },
      "outputs": [],
      "source": [
        "ep = [i  for i in range(len(avg_rewards_list))]\n",
        "plt.plot( range(len(avg_rewards_list)),avg_rewards_list,'b')\n",
        "plt.title(\"Avg Test Aeward Vs Test Episods\")\n",
        "plt.xlabel(\"Test Episods\")\n",
        "plt.ylabel(\"Average Test Reward\")\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BpQyiGbaxOIJ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}